{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_model_ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 is a RNN with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #eng_vocab_size, spa_vocab_size, eng_max_Sentence_length, spa_max_sen, units\n",
    "def define_model_embedding(src_vocab, tar_vocab, src_timesteps, tar_timesteps,n_units,function=\"softmax\"):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    #TODO: Implement\n",
    "    learning_rate = 1e-3\n",
    "    rnn = GRU(n_units)\n",
    "    \n",
    "    embedding = Embedding(src_vocab, n_units, input_length=src_timesteps,mask_zero=True) \n",
    "    logits = TimeDistributed(Dense(tar_vocab, activation=function))\n",
    "    \n",
    "    model = Sequential()\n",
    "    #em can only be used in first layer --> Keras Documentation\n",
    "    model.add(embedding)\n",
    "    model.add(rnn)\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(GRU(n_units,return_sequences=True))\n",
    "    model.add(logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 1 → tarda 35 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English → Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 5, 256)            581632    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 8, 256)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 8, 256)            394752    \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 8, 4510)          1159070   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,530,206\n",
      "Trainable params: 2,530,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.63132, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 25s - loss: 3.4127 - acc: 0.6371 - val_loss: 2.6313 - val_acc: 0.6509 - 25s/epoch - 197ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.63132 to 2.58492, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 2.5070 - acc: 0.6533 - val_loss: 2.5849 - val_acc: 0.6543 - 19s/epoch - 149ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 2.58492 to 2.50882, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 2.4173 - acc: 0.6576 - val_loss: 2.5088 - val_acc: 0.6584 - 18s/epoch - 145ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.50882 to 2.49487, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 2.3391 - acc: 0.6605 - val_loss: 2.4949 - val_acc: 0.6618 - 18s/epoch - 142ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.49487 to 2.43578, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 2.2707 - acc: 0.6643 - val_loss: 2.4358 - val_acc: 0.6665 - 18s/epoch - 144ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.43578 to 2.39237, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 2.1848 - acc: 0.6702 - val_loss: 2.3924 - val_acc: 0.6701 - 18s/epoch - 148ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.39237 to 2.32458, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 2.0858 - acc: 0.6778 - val_loss: 2.3246 - val_acc: 0.6809 - 19s/epoch - 151ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.32458 to 2.25696, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 20s - loss: 1.9739 - acc: 0.6873 - val_loss: 2.2570 - val_acc: 0.6854 - 20s/epoch - 157ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.25696 to 2.20628, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 20s - loss: 1.8606 - acc: 0.6968 - val_loss: 2.2063 - val_acc: 0.6915 - 20s/epoch - 163ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.20628 to 2.17714, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 20s - loss: 1.7537 - acc: 0.7058 - val_loss: 2.1771 - val_acc: 0.6982 - 20s/epoch - 159ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.17714 to 2.12630, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.6544 - acc: 0.7137 - val_loss: 2.1263 - val_acc: 0.7027 - 19s/epoch - 152ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.12630 to 2.09510, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.5575 - acc: 0.7215 - val_loss: 2.0951 - val_acc: 0.7084 - 19s/epoch - 150ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.09510 to 2.06488, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.4640 - acc: 0.7283 - val_loss: 2.0649 - val_acc: 0.7121 - 19s/epoch - 148ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.06488 to 2.03080, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.3691 - acc: 0.7376 - val_loss: 2.0308 - val_acc: 0.7160 - 19s/epoch - 149ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.03080 to 2.00867, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.2777 - acc: 0.7468 - val_loss: 2.0087 - val_acc: 0.7185 - 19s/epoch - 148ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 2.00867 to 1.98213, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 20s - loss: 1.1911 - acc: 0.7547 - val_loss: 1.9821 - val_acc: 0.7200 - 20s/epoch - 163ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 1.98213 to 1.96231, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 1.1077 - acc: 0.7638 - val_loss: 1.9623 - val_acc: 0.7239 - 19s/epoch - 153ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 1.96231 to 1.94188, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 23s - loss: 1.0283 - acc: 0.7733 - val_loss: 1.9419 - val_acc: 0.7238 - 23s/epoch - 183ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 1.94188 to 1.93507, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 19s - loss: 0.9571 - acc: 0.7828 - val_loss: 1.9351 - val_acc: 0.7257 - 19s/epoch - 149ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 1.93507 to 1.91926, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 0.8863 - acc: 0.7945 - val_loss: 1.9193 - val_acc: 0.7293 - 18s/epoch - 145ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 1.91926 to 1.90990, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 0.8208 - acc: 0.8048 - val_loss: 1.9099 - val_acc: 0.7306 - 18s/epoch - 144ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 1.90990 to 1.90632, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 0.7600 - acc: 0.8162 - val_loss: 1.9063 - val_acc: 0.7327 - 18s/epoch - 143ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 1.90632 to 1.90093, saving model to Models100\\cp_model_1_1.h5\n",
      "125/125 - 18s - loss: 0.7054 - acc: 0.8260 - val_loss: 1.9009 - val_acc: 0.7329 - 18s/epoch - 142ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.6568 - acc: 0.8346 - val_loss: 1.9033 - val_acc: 0.7339 - 18s/epoch - 145ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.90093\n",
      "125/125 - 20s - loss: 0.6131 - acc: 0.8434 - val_loss: 1.9043 - val_acc: 0.7320 - 20s/epoch - 157ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.5742 - acc: 0.8509 - val_loss: 1.9065 - val_acc: 0.7361 - 18s/epoch - 147ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.5349 - acc: 0.8587 - val_loss: 1.9155 - val_acc: 0.7333 - 18s/epoch - 141ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.5021 - acc: 0.8655 - val_loss: 1.9125 - val_acc: 0.7326 - 18s/epoch - 141ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.4714 - acc: 0.8714 - val_loss: 1.9222 - val_acc: 0.7329 - 18s/epoch - 142ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.4448 - acc: 0.8748 - val_loss: 1.9272 - val_acc: 0.7323 - 18s/epoch - 146ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.4210 - acc: 0.8800 - val_loss: 1.9310 - val_acc: 0.7333 - 19s/epoch - 154ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.3991 - acc: 0.8838 - val_loss: 1.9498 - val_acc: 0.7343 - 23s/epoch - 184ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.90093\n",
      "125/125 - 20s - loss: 0.3800 - acc: 0.8876 - val_loss: 1.9523 - val_acc: 0.7319 - 20s/epoch - 158ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.3625 - acc: 0.8902 - val_loss: 1.9570 - val_acc: 0.7319 - 19s/epoch - 149ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.90093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 20s - loss: 0.3462 - acc: 0.8927 - val_loss: 1.9647 - val_acc: 0.7314 - 20s/epoch - 163ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.3303 - acc: 0.8952 - val_loss: 1.9776 - val_acc: 0.7351 - 19s/epoch - 150ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.3176 - acc: 0.8973 - val_loss: 1.9801 - val_acc: 0.7317 - 19s/epoch - 149ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.3071 - acc: 0.8978 - val_loss: 1.9930 - val_acc: 0.7327 - 18s/epoch - 148ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2965 - acc: 0.8998 - val_loss: 2.0045 - val_acc: 0.7308 - 18s/epoch - 145ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2870 - acc: 0.9010 - val_loss: 2.0095 - val_acc: 0.7333 - 18s/epoch - 144ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2776 - acc: 0.9023 - val_loss: 2.0213 - val_acc: 0.7308 - 18s/epoch - 143ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2726 - acc: 0.9035 - val_loss: 2.0329 - val_acc: 0.7317 - 18s/epoch - 143ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2663 - acc: 0.9035 - val_loss: 2.0350 - val_acc: 0.7308 - 18s/epoch - 141ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.90093\n",
      "125/125 - 18s - loss: 0.2596 - acc: 0.9035 - val_loss: 2.0460 - val_acc: 0.7322 - 18s/epoch - 144ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.2526 - acc: 0.9050 - val_loss: 2.0594 - val_acc: 0.7301 - 19s/epoch - 156ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.90093\n",
      "125/125 - 19s - loss: 0.2463 - acc: 0.9058 - val_loss: 2.0647 - val_acc: 0.7331 - 19s/epoch - 153ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2414 - acc: 0.9053 - val_loss: 2.0738 - val_acc: 0.7321 - 22s/epoch - 179ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2377 - acc: 0.9052 - val_loss: 2.0784 - val_acc: 0.7314 - 23s/epoch - 186ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2356 - acc: 0.9050 - val_loss: 2.0833 - val_acc: 0.7304 - 22s/epoch - 176ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2331 - acc: 0.9060 - val_loss: 2.0882 - val_acc: 0.7303 - 23s/epoch - 182ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2285 - acc: 0.9065 - val_loss: 2.0940 - val_acc: 0.7314 - 22s/epoch - 179ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2253 - acc: 0.9061 - val_loss: 2.1081 - val_acc: 0.7317 - 22s/epoch - 178ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2231 - acc: 0.9060 - val_loss: 2.1045 - val_acc: 0.7303 - 22s/epoch - 175ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2206 - acc: 0.9068 - val_loss: 2.1185 - val_acc: 0.7309 - 22s/epoch - 175ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2175 - acc: 0.9061 - val_loss: 2.1311 - val_acc: 0.7299 - 23s/epoch - 182ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.2161 - acc: 0.9065 - val_loss: 2.1330 - val_acc: 0.7295 - 24s/epoch - 191ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2148 - acc: 0.9064 - val_loss: 2.1437 - val_acc: 0.7289 - 23s/epoch - 185ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2140 - acc: 0.9056 - val_loss: 2.1481 - val_acc: 0.7326 - 22s/epoch - 180ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2132 - acc: 0.9061 - val_loss: 2.1574 - val_acc: 0.7302 - 22s/epoch - 180ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2103 - acc: 0.9069 - val_loss: 2.1555 - val_acc: 0.7319 - 22s/epoch - 180ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2083 - acc: 0.9066 - val_loss: 2.1635 - val_acc: 0.7317 - 23s/epoch - 183ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.90093\n",
      "125/125 - 26s - loss: 0.2090 - acc: 0.9055 - val_loss: 2.1718 - val_acc: 0.7319 - 26s/epoch - 205ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.2094 - acc: 0.9065 - val_loss: 2.1684 - val_acc: 0.7306 - 24s/epoch - 189ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2068 - acc: 0.9069 - val_loss: 2.1797 - val_acc: 0.7318 - 23s/epoch - 188ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2052 - acc: 0.9062 - val_loss: 2.1840 - val_acc: 0.7309 - 23s/epoch - 186ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.2021 - acc: 0.9078 - val_loss: 2.1889 - val_acc: 0.7326 - 22s/epoch - 178ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.2024 - acc: 0.9065 - val_loss: 2.1953 - val_acc: 0.7289 - 23s/epoch - 180ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.2009 - acc: 0.9065 - val_loss: 2.1977 - val_acc: 0.7298 - 24s/epoch - 193ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1979 - acc: 0.9077 - val_loss: 2.2048 - val_acc: 0.7319 - 23s/epoch - 181ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.1978 - acc: 0.9075 - val_loss: 2.2120 - val_acc: 0.7321 - 22s/epoch - 177ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1973 - acc: 0.9061 - val_loss: 2.2221 - val_acc: 0.7296 - 24s/epoch - 191ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1972 - acc: 0.9079 - val_loss: 2.2160 - val_acc: 0.7296 - 24s/epoch - 192ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1988 - acc: 0.9062 - val_loss: 2.2206 - val_acc: 0.7304 - 24s/epoch - 194ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1964 - acc: 0.9068 - val_loss: 2.2249 - val_acc: 0.7297 - 24s/epoch - 194ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.1958 - acc: 0.9066 - val_loss: 2.2304 - val_acc: 0.7306 - 22s/epoch - 178ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1969 - acc: 0.9073 - val_loss: 2.2290 - val_acc: 0.7327 - 23s/epoch - 180ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1987 - acc: 0.9068 - val_loss: 2.2296 - val_acc: 0.7312 - 24s/epoch - 189ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.2000 - acc: 0.9058 - val_loss: 2.2429 - val_acc: 0.7296 - 24s/epoch - 188ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.1963 - acc: 0.9069 - val_loss: 2.2410 - val_acc: 0.7301 - 22s/epoch - 177ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.90093\n",
      "125/125 - 22s - loss: 0.1926 - acc: 0.9074 - val_loss: 2.2507 - val_acc: 0.7322 - 22s/epoch - 177ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1908 - acc: 0.9077 - val_loss: 2.2584 - val_acc: 0.7307 - 23s/epoch - 185ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1905 - acc: 0.9070 - val_loss: 2.2624 - val_acc: 0.7306 - 23s/epoch - 186ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1908 - acc: 0.9070 - val_loss: 2.2607 - val_acc: 0.7306 - 23s/epoch - 188ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1891 - acc: 0.9076 - val_loss: 2.2754 - val_acc: 0.7296 - 24s/epoch - 189ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1891 - acc: 0.9073 - val_loss: 2.2640 - val_acc: 0.7327 - 25s/epoch - 200ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1887 - acc: 0.9075 - val_loss: 2.2774 - val_acc: 0.7314 - 25s/epoch - 202ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1884 - acc: 0.9074 - val_loss: 2.2831 - val_acc: 0.7330 - 23s/epoch - 187ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1891 - acc: 0.9067 - val_loss: 2.2733 - val_acc: 0.7318 - 23s/epoch - 186ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1896 - acc: 0.9071 - val_loss: 2.2895 - val_acc: 0.7309 - 25s/epoch - 197ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.90093\n",
      "125/125 - 26s - loss: 0.1899 - acc: 0.9062 - val_loss: 2.2862 - val_acc: 0.7324 - 26s/epoch - 204ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.90093\n",
      "125/125 - 26s - loss: 0.1900 - acc: 0.9065 - val_loss: 2.2942 - val_acc: 0.7331 - 26s/epoch - 210ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1902 - acc: 0.9078 - val_loss: 2.2831 - val_acc: 0.7307 - 23s/epoch - 184ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1891 - acc: 0.9070 - val_loss: 2.2944 - val_acc: 0.7319 - 25s/epoch - 198ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1881 - acc: 0.9070 - val_loss: 2.2985 - val_acc: 0.7305 - 25s/epoch - 196ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1871 - acc: 0.9073 - val_loss: 2.3045 - val_acc: 0.7308 - 23s/epoch - 183ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1866 - acc: 0.9072 - val_loss: 2.3055 - val_acc: 0.7316 - 24s/epoch - 192ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1857 - acc: 0.9069 - val_loss: 2.3102 - val_acc: 0.7310 - 24s/epoch - 194ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.90093\n",
      "125/125 - 24s - loss: 0.1858 - acc: 0.9064 - val_loss: 2.3110 - val_acc: 0.7319 - 24s/epoch - 192ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.90093\n",
      "125/125 - 23s - loss: 0.1846 - acc: 0.9072 - val_loss: 2.3109 - val_acc: 0.7272 - 23s/epoch - 187ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.90093\n",
      "125/125 - 25s - loss: 0.1856 - acc: 0.9071 - val_loss: 2.3239 - val_acc: 0.7291 - 25s/epoch - 198ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "learning_rate = 0.001\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_1_1.h5'\n",
    "history_save_file_name=\"cp_history_1_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model1_1 = define_model_embedding(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units)\n",
    "create_model(model1_1,loss_func,learning_rate)\n",
    "plot_model(model1_1, to_file='model_images/cp_model_1_1_m.png', show_shapes=True)\n",
    "#train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model, model_save_file_name, history_save_file_name)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model1_1, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model1_1.history, 'loss_vs_epochs_images_100/cp_model_1_1_le.png', 'Model 1 var 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish → English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 4510 5 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 8, 256)            1154560   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 5, 256)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 5, 256)            394752    \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 5, 2272)          583904    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,527,968\n",
      "Trainable params: 2,527,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.00908, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 15s - loss: 2.3599 - acc: 0.9209 - val_loss: 1.0091 - val_acc: 0.9197 - 15s/epoch - 117ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 1.00908 to 0.57709, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.8020 - acc: 0.9329 - val_loss: 0.5771 - val_acc: 0.9347 - 10s/epoch - 76ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57709 to 0.33495, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.4157 - acc: 0.9368 - val_loss: 0.3349 - val_acc: 0.9344 - 9s/epoch - 75ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.33495 to 0.32255, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.3144 - acc: 0.9367 - val_loss: 0.3226 - val_acc: 0.9336 - 10s/epoch - 76ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.32255 to 0.30214, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.3058 - acc: 0.9359 - val_loss: 0.3021 - val_acc: 0.9342 - 9s/epoch - 74ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.30214 to 0.29363, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2880 - acc: 0.9370 - val_loss: 0.2936 - val_acc: 0.9357 - 10s/epoch - 78ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.29363 to 0.28931, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2803 - acc: 0.9384 - val_loss: 0.2893 - val_acc: 0.9356 - 10s/epoch - 78ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.28931 to 0.28791, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2754 - acc: 0.9386 - val_loss: 0.2879 - val_acc: 0.9356 - 9s/epoch - 73ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.28791 to 0.28535, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2722 - acc: 0.9385 - val_loss: 0.2853 - val_acc: 0.9356 - 9s/epoch - 75ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.28535 to 0.28226, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2700 - acc: 0.9384 - val_loss: 0.2823 - val_acc: 0.9356 - 10s/epoch - 76ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.28226 to 0.28145, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2675 - acc: 0.9386 - val_loss: 0.2814 - val_acc: 0.9355 - 9s/epoch - 71ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.28145 to 0.28019, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 11s - loss: 0.2655 - acc: 0.9387 - val_loss: 0.2802 - val_acc: 0.9356 - 11s/epoch - 86ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.28019 to 0.27748, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 11s - loss: 0.2636 - acc: 0.9390 - val_loss: 0.2775 - val_acc: 0.9365 - 11s/epoch - 86ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.27748 to 0.27551, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 11s - loss: 0.2616 - acc: 0.9394 - val_loss: 0.2755 - val_acc: 0.9365 - 11s/epoch - 91ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.27551 to 0.27467, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 11s - loss: 0.2600 - acc: 0.9395 - val_loss: 0.2747 - val_acc: 0.9368 - 11s/epoch - 86ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.27467 to 0.27277, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 11s - loss: 0.2580 - acc: 0.9399 - val_loss: 0.2728 - val_acc: 0.9363 - 11s/epoch - 86ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.27277 to 0.27117, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2558 - acc: 0.9401 - val_loss: 0.2712 - val_acc: 0.9364 - 10s/epoch - 79ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.27117 to 0.26901, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2537 - acc: 0.9404 - val_loss: 0.2690 - val_acc: 0.9380 - 9s/epoch - 75ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.26901 to 0.26868, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2528 - acc: 0.9406 - val_loss: 0.2687 - val_acc: 0.9377 - 9s/epoch - 72ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.26868 to 0.26807, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2508 - acc: 0.9408 - val_loss: 0.2681 - val_acc: 0.9379 - 9s/epoch - 75ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.26807\n",
      "125/125 - 9s - loss: 0.2494 - acc: 0.9408 - val_loss: 0.2682 - val_acc: 0.9380 - 9s/epoch - 73ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.26807 to 0.26671, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2478 - acc: 0.9409 - val_loss: 0.2667 - val_acc: 0.9381 - 9s/epoch - 75ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.26671 to 0.26611, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2469 - acc: 0.9411 - val_loss: 0.2661 - val_acc: 0.9373 - 9s/epoch - 74ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.26611\n",
      "125/125 - 9s - loss: 0.2459 - acc: 0.9410 - val_loss: 0.2662 - val_acc: 0.9375 - 9s/epoch - 75ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.26611 to 0.26571, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2442 - acc: 0.9413 - val_loss: 0.2657 - val_acc: 0.9380 - 10s/epoch - 76ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.26571 to 0.26402, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2433 - acc: 0.9416 - val_loss: 0.2640 - val_acc: 0.9380 - 9s/epoch - 74ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.26402\n",
      "125/125 - 10s - loss: 0.2425 - acc: 0.9422 - val_loss: 0.2651 - val_acc: 0.9382 - 10s/epoch - 78ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.26402\n",
      "125/125 - 9s - loss: 0.2413 - acc: 0.9420 - val_loss: 0.2647 - val_acc: 0.9384 - 9s/epoch - 74ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.26402\n",
      "125/125 - 10s - loss: 0.2406 - acc: 0.9422 - val_loss: 0.2650 - val_acc: 0.9371 - 10s/epoch - 77ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 0.26402 to 0.26342, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2396 - acc: 0.9425 - val_loss: 0.2634 - val_acc: 0.9387 - 10s/epoch - 78ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 0.26342 to 0.26341, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 9s - loss: 0.2390 - acc: 0.9427 - val_loss: 0.2634 - val_acc: 0.9382 - 9s/epoch - 74ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.26341\n",
      "125/125 - 9s - loss: 0.2381 - acc: 0.9425 - val_loss: 0.2641 - val_acc: 0.9385 - 9s/epoch - 75ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.26341\n",
      "125/125 - 9s - loss: 0.2376 - acc: 0.9429 - val_loss: 0.2646 - val_acc: 0.9383 - 9s/epoch - 74ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.26341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 9s - loss: 0.2365 - acc: 0.9430 - val_loss: 0.2634 - val_acc: 0.9384 - 9s/epoch - 76ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.26341\n",
      "125/125 - 9s - loss: 0.2361 - acc: 0.9430 - val_loss: 0.2635 - val_acc: 0.9383 - 9s/epoch - 75ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.26341 to 0.26263, saving model to Models100\\cp_model_ei_1_1.h5\n",
      "125/125 - 10s - loss: 0.2357 - acc: 0.9434 - val_loss: 0.2626 - val_acc: 0.9385 - 10s/epoch - 77ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2349 - acc: 0.9434 - val_loss: 0.2632 - val_acc: 0.9386 - 10s/epoch - 78ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2347 - acc: 0.9434 - val_loss: 0.2639 - val_acc: 0.9387 - 10s/epoch - 78ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2334 - acc: 0.9438 - val_loss: 0.2642 - val_acc: 0.9386 - 10s/epoch - 80ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2333 - acc: 0.9435 - val_loss: 0.2644 - val_acc: 0.9387 - 11s/epoch - 85ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2333 - acc: 0.9439 - val_loss: 0.2648 - val_acc: 0.9385 - 10s/epoch - 77ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2328 - acc: 0.9439 - val_loss: 0.2641 - val_acc: 0.9385 - 10s/epoch - 77ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.26263\n",
      "125/125 - 9s - loss: 0.2327 - acc: 0.9439 - val_loss: 0.2642 - val_acc: 0.9384 - 9s/epoch - 75ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2321 - acc: 0.9440 - val_loss: 0.2654 - val_acc: 0.9387 - 10s/epoch - 77ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2322 - acc: 0.9441 - val_loss: 0.2632 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.26263\n",
      "125/125 - 12s - loss: 0.2314 - acc: 0.9441 - val_loss: 0.2638 - val_acc: 0.9385 - 12s/epoch - 93ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2312 - acc: 0.9441 - val_loss: 0.2648 - val_acc: 0.9383 - 11s/epoch - 88ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26263\n",
      "125/125 - 12s - loss: 0.2315 - acc: 0.9439 - val_loss: 0.2645 - val_acc: 0.9384 - 12s/epoch - 98ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2312 - acc: 0.9442 - val_loss: 0.2636 - val_acc: 0.9385 - 11s/epoch - 85ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2310 - acc: 0.9439 - val_loss: 0.2654 - val_acc: 0.9387 - 10s/epoch - 79ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2305 - acc: 0.9440 - val_loss: 0.2644 - val_acc: 0.9385 - 11s/epoch - 84ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2308 - acc: 0.9441 - val_loss: 0.2653 - val_acc: 0.9383 - 10s/epoch - 81ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2307 - acc: 0.9438 - val_loss: 0.2660 - val_acc: 0.9385 - 10s/epoch - 81ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2308 - acc: 0.9440 - val_loss: 0.2663 - val_acc: 0.9384 - 10s/epoch - 82ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2305 - acc: 0.9441 - val_loss: 0.2651 - val_acc: 0.9388 - 10s/epoch - 80ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2303 - acc: 0.9439 - val_loss: 0.2668 - val_acc: 0.9379 - 10s/epoch - 79ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2304 - acc: 0.9442 - val_loss: 0.2657 - val_acc: 0.9382 - 10s/epoch - 82ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2301 - acc: 0.9441 - val_loss: 0.2658 - val_acc: 0.9384 - 10s/epoch - 79ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2301 - acc: 0.9440 - val_loss: 0.2640 - val_acc: 0.9386 - 10s/epoch - 80ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2303 - acc: 0.9440 - val_loss: 0.2656 - val_acc: 0.9382 - 10s/epoch - 78ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2298 - acc: 0.9441 - val_loss: 0.2652 - val_acc: 0.9385 - 10s/epoch - 79ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2301 - acc: 0.9440 - val_loss: 0.2658 - val_acc: 0.9382 - 10s/epoch - 80ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2298 - acc: 0.9440 - val_loss: 0.2661 - val_acc: 0.9381 - 10s/epoch - 78ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2299 - acc: 0.9441 - val_loss: 0.2646 - val_acc: 0.9386 - 11s/epoch - 85ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2298 - acc: 0.9441 - val_loss: 0.2656 - val_acc: 0.9383 - 11s/epoch - 85ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2298 - acc: 0.9440 - val_loss: 0.2665 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2292 - acc: 0.9441 - val_loss: 0.2653 - val_acc: 0.9382 - 10s/epoch - 83ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2299 - acc: 0.9441 - val_loss: 0.2651 - val_acc: 0.9381 - 10s/epoch - 82ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2291 - acc: 0.9440 - val_loss: 0.2666 - val_acc: 0.9382 - 10s/epoch - 81ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26263\n",
      "125/125 - 12s - loss: 0.2291 - acc: 0.9441 - val_loss: 0.2675 - val_acc: 0.9383 - 12s/epoch - 97ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26263\n",
      "125/125 - 13s - loss: 0.2295 - acc: 0.9440 - val_loss: 0.2671 - val_acc: 0.9383 - 13s/epoch - 102ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2292 - acc: 0.9441 - val_loss: 0.2659 - val_acc: 0.9384 - 11s/epoch - 89ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2290 - acc: 0.9442 - val_loss: 0.2675 - val_acc: 0.9381 - 11s/epoch - 86ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2289 - acc: 0.9440 - val_loss: 0.2660 - val_acc: 0.9383 - 11s/epoch - 91ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2288 - acc: 0.9441 - val_loss: 0.2662 - val_acc: 0.9384 - 11s/epoch - 85ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2289 - acc: 0.9442 - val_loss: 0.2681 - val_acc: 0.9381 - 10s/epoch - 78ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2289 - acc: 0.9440 - val_loss: 0.2666 - val_acc: 0.9377 - 10s/epoch - 78ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2290 - acc: 0.9441 - val_loss: 0.2673 - val_acc: 0.9378 - 10s/epoch - 76ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2290 - acc: 0.9440 - val_loss: 0.2681 - val_acc: 0.9383 - 10s/epoch - 77ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2288 - acc: 0.9441 - val_loss: 0.2680 - val_acc: 0.9382 - 10s/epoch - 78ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2292 - acc: 0.9439 - val_loss: 0.2698 - val_acc: 0.9381 - 10s/epoch - 77ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2292 - acc: 0.9441 - val_loss: 0.2697 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2291 - acc: 0.9441 - val_loss: 0.2679 - val_acc: 0.9381 - 10s/epoch - 76ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2289 - acc: 0.9441 - val_loss: 0.2680 - val_acc: 0.9384 - 10s/epoch - 77ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2290 - acc: 0.9442 - val_loss: 0.2695 - val_acc: 0.9382 - 10s/epoch - 78ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2292 - acc: 0.9441 - val_loss: 0.2687 - val_acc: 0.9384 - 10s/epoch - 81ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26263\n",
      "125/125 - 13s - loss: 0.2292 - acc: 0.9441 - val_loss: 0.2686 - val_acc: 0.9382 - 13s/epoch - 101ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2290 - acc: 0.9442 - val_loss: 0.2693 - val_acc: 0.9386 - 11s/epoch - 91ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2289 - acc: 0.9442 - val_loss: 0.2690 - val_acc: 0.9383 - 11s/epoch - 88ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2291 - acc: 0.9439 - val_loss: 0.2704 - val_acc: 0.9383 - 11s/epoch - 88ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2287 - acc: 0.9440 - val_loss: 0.2701 - val_acc: 0.9381 - 11s/epoch - 88ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26263\n",
      "125/125 - 12s - loss: 0.2293 - acc: 0.9441 - val_loss: 0.2688 - val_acc: 0.9383 - 12s/epoch - 93ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2287 - acc: 0.9442 - val_loss: 0.2679 - val_acc: 0.9382 - 10s/epoch - 83ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2680 - val_acc: 0.9381 - 11s/epoch - 85ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2673 - val_acc: 0.9385 - 10s/epoch - 82ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26263\n",
      "125/125 - 11s - loss: 0.2284 - acc: 0.9442 - val_loss: 0.2690 - val_acc: 0.9385 - 11s/epoch - 92ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.26263\n",
      "125/125 - 13s - loss: 0.2284 - acc: 0.9441 - val_loss: 0.2689 - val_acc: 0.9384 - 13s/epoch - 100ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2284 - acc: 0.9441 - val_loss: 0.2694 - val_acc: 0.9383 - 10s/epoch - 81ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2284 - acc: 0.9441 - val_loss: 0.2698 - val_acc: 0.9379 - 10s/epoch - 78ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26263\n",
      "125/125 - 10s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2700 - val_acc: 0.9383 - 10s/epoch - 81ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "learning_rate = 0.001\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_ei_1_1.h5'\n",
    "history_save_file_name=\"cp_history_ei_1_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "src_tokenizer,src_vocab_size,src_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "tar_tokenizer,tar_vocab_size,tar_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(src_vocab_size,src_vocab_size,tar_max_sentence_length,tar_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "\n",
    "model_ei1_1 = define_model_embedding(src_vocab_size, tar_vocab_size, src_max_sentence_length, tar_max_sentence_length, units)\n",
    "create_model(model_ei1_1,loss_func,learning_rate)\n",
    "plot_model(model_ei1_1, to_file='model_images/cp_model_ei_1_1_m.png', show_shapes=True)\n",
    "#train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model, model_save_file_name, history_save_file_name)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model_ei1_1, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model_ei1_1.history, 'loss_vs_epochs_images_100/cp_model_ei_1_1_le.png', 'Model 1 var 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English → Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 5, 32)             72704     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 8, 32)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 8, 32)             6336      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 8, 4510)          148830    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234,206\n",
      "Trainable params: 234,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.65723, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 26s - loss: 3.5844 - acc: 0.6357 - val_loss: 2.6572 - val_acc: 0.6417 - 26s/epoch - 207ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.65723 to 2.57520, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 2.5643 - acc: 0.6461 - val_loss: 2.5752 - val_acc: 0.6479 - 13s/epoch - 107ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 2.57520 to 2.51429, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 2.4587 - acc: 0.6519 - val_loss: 2.5143 - val_acc: 0.6567 - 12s/epoch - 97ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.51429 to 2.48117, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 2.3819 - acc: 0.6581 - val_loss: 2.4812 - val_acc: 0.6603 - 12s/epoch - 96ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.48117 to 2.45100, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 2.3169 - acc: 0.6626 - val_loss: 2.4510 - val_acc: 0.6622 - 13s/epoch - 106ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.45100 to 2.40920, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 2.2467 - acc: 0.6653 - val_loss: 2.4092 - val_acc: 0.6672 - 13s/epoch - 106ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.40920 to 2.36551, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 14s - loss: 2.1698 - acc: 0.6710 - val_loss: 2.3655 - val_acc: 0.6738 - 14s/epoch - 108ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.36551 to 2.32830, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 14s - loss: 2.0920 - acc: 0.6762 - val_loss: 2.3283 - val_acc: 0.6731 - 14s/epoch - 108ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.32830 to 2.28364, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 2.0068 - acc: 0.6837 - val_loss: 2.2836 - val_acc: 0.6817 - 13s/epoch - 103ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.28364 to 2.25018, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.9236 - acc: 0.6891 - val_loss: 2.2502 - val_acc: 0.6823 - 13s/epoch - 108ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.25018 to 2.22373, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.8431 - acc: 0.6948 - val_loss: 2.2237 - val_acc: 0.6879 - 13s/epoch - 106ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.22373 to 2.19489, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.7642 - acc: 0.7043 - val_loss: 2.1949 - val_acc: 0.6922 - 13s/epoch - 105ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.19489 to 2.17571, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.6904 - acc: 0.7102 - val_loss: 2.1757 - val_acc: 0.6936 - 13s/epoch - 103ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.17571 to 2.16737, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.6281 - acc: 0.7151 - val_loss: 2.1674 - val_acc: 0.6942 - 13s/epoch - 103ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.16737 to 2.15120, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.5623 - acc: 0.7210 - val_loss: 2.1512 - val_acc: 0.6999 - 13s/epoch - 103ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 2.15120 to 2.13736, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.5064 - acc: 0.7256 - val_loss: 2.1374 - val_acc: 0.6989 - 13s/epoch - 105ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 2.13736 to 2.12447, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 1.4516 - acc: 0.7303 - val_loss: 2.1245 - val_acc: 0.7026 - 12s/epoch - 100ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 2.12447 to 2.12258, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 13s - loss: 1.4013 - acc: 0.7356 - val_loss: 2.1226 - val_acc: 0.7019 - 13s/epoch - 102ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 2.12258 to 2.11509, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 1.3500 - acc: 0.7402 - val_loss: 2.1151 - val_acc: 0.7024 - 12s/epoch - 99ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 2.11509\n",
      "125/125 - 12s - loss: 1.3043 - acc: 0.7444 - val_loss: 2.1184 - val_acc: 0.7067 - 12s/epoch - 95ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 2.11509 to 2.10900, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 1.2602 - acc: 0.7476 - val_loss: 2.1090 - val_acc: 0.7066 - 12s/epoch - 95ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 2.10900 to 2.10497, saving model to Models100\\cp_model_1_2.h5\n",
      "125/125 - 12s - loss: 1.2170 - acc: 0.7530 - val_loss: 2.1050 - val_acc: 0.7060 - 12s/epoch - 100ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 1.1778 - acc: 0.7575 - val_loss: 2.1078 - val_acc: 0.7096 - 13s/epoch - 101ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 1.1411 - acc: 0.7618 - val_loss: 2.1152 - val_acc: 0.7062 - 12s/epoch - 99ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 1.1066 - acc: 0.7656 - val_loss: 2.1143 - val_acc: 0.7096 - 12s/epoch - 94ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 1.0694 - acc: 0.7711 - val_loss: 2.1192 - val_acc: 0.7081 - 12s/epoch - 95ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 1.0385 - acc: 0.7747 - val_loss: 2.1192 - val_acc: 0.7098 - 12s/epoch - 99ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 1.0072 - acc: 0.7786 - val_loss: 2.1141 - val_acc: 0.7085 - 12s/epoch - 95ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.9793 - acc: 0.7828 - val_loss: 2.1245 - val_acc: 0.7086 - 12s/epoch - 96ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.9525 - acc: 0.7864 - val_loss: 2.1340 - val_acc: 0.7119 - 13s/epoch - 104ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.9282 - acc: 0.7903 - val_loss: 2.1451 - val_acc: 0.7068 - 13s/epoch - 105ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.9092 - acc: 0.7938 - val_loss: 2.1406 - val_acc: 0.7094 - 12s/epoch - 98ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.8842 - acc: 0.7973 - val_loss: 2.1369 - val_acc: 0.7123 - 13s/epoch - 103ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 2.10497\n",
      "125/125 - 14s - loss: 0.8604 - acc: 0.8004 - val_loss: 2.1656 - val_acc: 0.7074 - 14s/epoch - 112ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.8405 - acc: 0.8042 - val_loss: 2.1599 - val_acc: 0.7096 - 13s/epoch - 100ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.8231 - acc: 0.8072 - val_loss: 2.1621 - val_acc: 0.7114 - 12s/epoch - 99ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.8048 - acc: 0.8102 - val_loss: 2.1688 - val_acc: 0.7155 - 13s/epoch - 107ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 2.10497\n",
      "125/125 - 14s - loss: 0.7895 - acc: 0.8123 - val_loss: 2.1729 - val_acc: 0.7124 - 14s/epoch - 109ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.7762 - acc: 0.8138 - val_loss: 2.1853 - val_acc: 0.7124 - 13s/epoch - 107ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.7608 - acc: 0.8175 - val_loss: 2.1863 - val_acc: 0.7107 - 13s/epoch - 101ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.7456 - acc: 0.8195 - val_loss: 2.2003 - val_acc: 0.7147 - 12s/epoch - 98ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.7311 - acc: 0.8230 - val_loss: 2.1967 - val_acc: 0.7121 - 12s/epoch - 98ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.7169 - acc: 0.8244 - val_loss: 2.2049 - val_acc: 0.7101 - 13s/epoch - 102ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.7085 - acc: 0.8250 - val_loss: 2.2050 - val_acc: 0.7124 - 13s/epoch - 108ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.6961 - acc: 0.8292 - val_loss: 2.2230 - val_acc: 0.7132 - 13s/epoch - 108ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.6859 - acc: 0.8289 - val_loss: 2.2226 - val_acc: 0.7118 - 13s/epoch - 107ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.6790 - acc: 0.8312 - val_loss: 2.2283 - val_acc: 0.7142 - 13s/epoch - 102ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.6649 - acc: 0.8344 - val_loss: 2.2355 - val_acc: 0.7149 - 13s/epoch - 101ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6544 - acc: 0.8351 - val_loss: 2.2350 - val_acc: 0.7130 - 12s/epoch - 99ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 2.10497\n",
      "125/125 - 14s - loss: 0.6493 - acc: 0.8362 - val_loss: 2.2470 - val_acc: 0.7106 - 14s/epoch - 111ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6355 - acc: 0.8385 - val_loss: 2.2491 - val_acc: 0.7114 - 12s/epoch - 98ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.6299 - acc: 0.8396 - val_loss: 2.2556 - val_acc: 0.7143 - 13s/epoch - 101ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6252 - acc: 0.8389 - val_loss: 2.2649 - val_acc: 0.7122 - 12s/epoch - 97ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6170 - acc: 0.8419 - val_loss: 2.2672 - val_acc: 0.7103 - 12s/epoch - 99ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6108 - acc: 0.8430 - val_loss: 2.2690 - val_acc: 0.7117 - 12s/epoch - 95ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.6018 - acc: 0.8433 - val_loss: 2.2766 - val_acc: 0.7106 - 12s/epoch - 97ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5957 - acc: 0.8462 - val_loss: 2.2776 - val_acc: 0.7127 - 13s/epoch - 103ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5882 - acc: 0.8466 - val_loss: 2.2893 - val_acc: 0.7096 - 12s/epoch - 100ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5806 - acc: 0.8487 - val_loss: 2.2864 - val_acc: 0.7110 - 13s/epoch - 103ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5743 - acc: 0.8497 - val_loss: 2.2997 - val_acc: 0.7120 - 12s/epoch - 98ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5643 - acc: 0.8518 - val_loss: 2.3206 - val_acc: 0.7078 - 12s/epoch - 98ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5627 - acc: 0.8503 - val_loss: 2.3144 - val_acc: 0.7096 - 12s/epoch - 98ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5545 - acc: 0.8518 - val_loss: 2.3254 - val_acc: 0.7096 - 12s/epoch - 96ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5553 - acc: 0.8518 - val_loss: 2.3374 - val_acc: 0.7072 - 12s/epoch - 97ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5487 - acc: 0.8533 - val_loss: 2.3383 - val_acc: 0.7126 - 13s/epoch - 102ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5431 - acc: 0.8550 - val_loss: 2.3326 - val_acc: 0.7101 - 13s/epoch - 101ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5369 - acc: 0.8549 - val_loss: 2.3423 - val_acc: 0.7115 - 12s/epoch - 97ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5373 - acc: 0.8555 - val_loss: 2.3459 - val_acc: 0.7099 - 12s/epoch - 98ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5335 - acc: 0.8549 - val_loss: 2.3482 - val_acc: 0.7098 - 12s/epoch - 96ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5274 - acc: 0.8568 - val_loss: 2.3575 - val_acc: 0.7082 - 13s/epoch - 104ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5228 - acc: 0.8569 - val_loss: 2.3583 - val_acc: 0.7073 - 12s/epoch - 96ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5162 - acc: 0.8590 - val_loss: 2.3712 - val_acc: 0.7075 - 12s/epoch - 98ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5104 - acc: 0.8601 - val_loss: 2.3768 - val_acc: 0.7136 - 12s/epoch - 97ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.5101 - acc: 0.8600 - val_loss: 2.3751 - val_acc: 0.7069 - 12s/epoch - 97ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5048 - acc: 0.8611 - val_loss: 2.3832 - val_acc: 0.7100 - 13s/epoch - 103ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5074 - acc: 0.8601 - val_loss: 2.3817 - val_acc: 0.7080 - 13s/epoch - 104ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.5017 - acc: 0.8601 - val_loss: 2.3901 - val_acc: 0.7104 - 13s/epoch - 108ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4960 - acc: 0.8622 - val_loss: 2.4022 - val_acc: 0.7088 - 12s/epoch - 95ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4926 - acc: 0.8617 - val_loss: 2.4025 - val_acc: 0.7078 - 12s/epoch - 95ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4924 - acc: 0.8620 - val_loss: 2.4040 - val_acc: 0.7084 - 12s/epoch - 98ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4871 - acc: 0.8631 - val_loss: 2.4062 - val_acc: 0.7096 - 12s/epoch - 98ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4798 - acc: 0.8654 - val_loss: 2.4143 - val_acc: 0.7091 - 12s/epoch - 98ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4778 - acc: 0.8651 - val_loss: 2.4247 - val_acc: 0.7063 - 12s/epoch - 99ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4767 - acc: 0.8653 - val_loss: 2.4205 - val_acc: 0.7097 - 12s/epoch - 97ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.10497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 12s - loss: 0.4736 - acc: 0.8648 - val_loss: 2.4242 - val_acc: 0.7119 - 12s/epoch - 98ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.4724 - acc: 0.8659 - val_loss: 2.4372 - val_acc: 0.7082 - 13s/epoch - 101ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4707 - acc: 0.8649 - val_loss: 2.4294 - val_acc: 0.7092 - 12s/epoch - 98ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4661 - acc: 0.8666 - val_loss: 2.4536 - val_acc: 0.7110 - 12s/epoch - 97ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4673 - acc: 0.8650 - val_loss: 2.4536 - val_acc: 0.7081 - 12s/epoch - 99ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 2.10497\n",
      "125/125 - 14s - loss: 0.4662 - acc: 0.8657 - val_loss: 2.4498 - val_acc: 0.7081 - 14s/epoch - 109ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.10497\n",
      "125/125 - 15s - loss: 0.4671 - acc: 0.8660 - val_loss: 2.4571 - val_acc: 0.7088 - 15s/epoch - 124ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 2.10497\n",
      "125/125 - 14s - loss: 0.4582 - acc: 0.8673 - val_loss: 2.4532 - val_acc: 0.7087 - 14s/epoch - 115ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.4556 - acc: 0.8677 - val_loss: 2.4681 - val_acc: 0.7065 - 13s/epoch - 108ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.4579 - acc: 0.8674 - val_loss: 2.4753 - val_acc: 0.7071 - 13s/epoch - 102ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4539 - acc: 0.8693 - val_loss: 2.4842 - val_acc: 0.7081 - 12s/epoch - 100ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4487 - acc: 0.8678 - val_loss: 2.4770 - val_acc: 0.7096 - 12s/epoch - 100ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4453 - acc: 0.8701 - val_loss: 2.4798 - val_acc: 0.7098 - 12s/epoch - 99ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 2.10497\n",
      "125/125 - 12s - loss: 0.4421 - acc: 0.8712 - val_loss: 2.4909 - val_acc: 0.7088 - 12s/epoch - 99ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.4459 - acc: 0.8690 - val_loss: 2.4835 - val_acc: 0.7070 - 13s/epoch - 105ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.10497\n",
      "125/125 - 13s - loss: 0.4440 - acc: 0.8695 - val_loss: 2.4891 - val_acc: 0.7085 - 13s/epoch - 105ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 32\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_1_2.h5'\n",
    "history_save_file_name=\"cp_history_1_2.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model1_2 = define_model_embedding(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,\"softmax\")\n",
    "create_model(model1_2,loss_func,learning_rate)\n",
    "plot_model(model1_2, to_file='model_images/cp_model_1_2_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model1_2, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model1_2.history, 'loss_vs_epochs_images_100/cp_model_1_2_le.png', 'Model 1 var 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish → English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 2272 8 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 8, 32)             144320    \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 5, 32)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 5, 32)             6336      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 5, 2272)          74976     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231,968\n",
      "Trainable params: 231,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46171, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 10s - loss: 1.9164 - acc: 0.9197 - val_loss: 0.4617 - val_acc: 0.9197 - 10s/epoch - 77ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.46171 to 0.31798, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 3s - loss: 0.3542 - acc: 0.9269 - val_loss: 0.3180 - val_acc: 0.9339 - 3s/epoch - 27ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.31798 to 0.30683, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.3049 - acc: 0.9366 - val_loss: 0.3068 - val_acc: 0.9341 - 4s/epoch - 30ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.30683 to 0.30005, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2960 - acc: 0.9367 - val_loss: 0.3001 - val_acc: 0.9341 - 4s/epoch - 31ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.30005 to 0.29685, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2902 - acc: 0.9366 - val_loss: 0.2969 - val_acc: 0.9340 - 4s/epoch - 34ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.29685 to 0.29147, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2842 - acc: 0.9367 - val_loss: 0.2915 - val_acc: 0.9340 - 4s/epoch - 31ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.29147 to 0.28814, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2785 - acc: 0.9368 - val_loss: 0.2881 - val_acc: 0.9336 - 4s/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.28814 to 0.28394, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2740 - acc: 0.9370 - val_loss: 0.2839 - val_acc: 0.9341 - 4s/epoch - 29ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.28394 to 0.28184, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2703 - acc: 0.9368 - val_loss: 0.2818 - val_acc: 0.9337 - 4s/epoch - 28ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.28184 to 0.28159, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2666 - acc: 0.9372 - val_loss: 0.2816 - val_acc: 0.9338 - 4s/epoch - 30ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.28159 to 0.27869, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2636 - acc: 0.9375 - val_loss: 0.2787 - val_acc: 0.9341 - 4s/epoch - 33ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.27869 to 0.27818, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2616 - acc: 0.9385 - val_loss: 0.2782 - val_acc: 0.9361 - 4s/epoch - 34ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.27818 to 0.27733, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2591 - acc: 0.9396 - val_loss: 0.2773 - val_acc: 0.9353 - 4s/epoch - 33ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.27733\n",
      "125/125 - 4s - loss: 0.2570 - acc: 0.9398 - val_loss: 0.2795 - val_acc: 0.9370 - 4s/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.27733 to 0.27315, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2581 - acc: 0.9398 - val_loss: 0.2732 - val_acc: 0.9363 - 4s/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.27315\n",
      "125/125 - 4s - loss: 0.2533 - acc: 0.9405 - val_loss: 0.2734 - val_acc: 0.9366 - 4s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.27315 to 0.27041, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2515 - acc: 0.9407 - val_loss: 0.2704 - val_acc: 0.9374 - 4s/epoch - 30ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.27041 to 0.26948, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2497 - acc: 0.9407 - val_loss: 0.2695 - val_acc: 0.9377 - 4s/epoch - 30ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.26948\n",
      "125/125 - 4s - loss: 0.2475 - acc: 0.9409 - val_loss: 0.2708 - val_acc: 0.9378 - 4s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.26948 to 0.26846, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2467 - acc: 0.9410 - val_loss: 0.2685 - val_acc: 0.9375 - 4s/epoch - 30ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.26846 to 0.26734, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2452 - acc: 0.9412 - val_loss: 0.2673 - val_acc: 0.9376 - 4s/epoch - 29ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.26734\n",
      "125/125 - 4s - loss: 0.2443 - acc: 0.9412 - val_loss: 0.2676 - val_acc: 0.9375 - 4s/epoch - 29ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.26734 to 0.26705, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2430 - acc: 0.9417 - val_loss: 0.2670 - val_acc: 0.9379 - 4s/epoch - 30ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.26705\n",
      "125/125 - 4s - loss: 0.2422 - acc: 0.9417 - val_loss: 0.2675 - val_acc: 0.9379 - 4s/epoch - 34ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.26705\n",
      "125/125 - 4s - loss: 0.2410 - acc: 0.9417 - val_loss: 0.2675 - val_acc: 0.9380 - 4s/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.26705 to 0.26587, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2402 - acc: 0.9420 - val_loss: 0.2659 - val_acc: 0.9377 - 4s/epoch - 34ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.26587\n",
      "125/125 - 4s - loss: 0.2391 - acc: 0.9420 - val_loss: 0.2680 - val_acc: 0.9380 - 4s/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.26587\n",
      "125/125 - 4s - loss: 0.2382 - acc: 0.9424 - val_loss: 0.2684 - val_acc: 0.9382 - 4s/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.26587\n",
      "125/125 - 4s - loss: 0.2372 - acc: 0.9423 - val_loss: 0.2676 - val_acc: 0.9374 - 4s/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.26587\n",
      "125/125 - 4s - loss: 0.2366 - acc: 0.9423 - val_loss: 0.2685 - val_acc: 0.9383 - 4s/epoch - 29ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.26587\n",
      "125/125 - 4s - loss: 0.2362 - acc: 0.9426 - val_loss: 0.2673 - val_acc: 0.9382 - 4s/epoch - 34ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 0.26587 to 0.26578, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2348 - acc: 0.9429 - val_loss: 0.2658 - val_acc: 0.9380 - 4s/epoch - 31ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.26578 to 0.26569, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2343 - acc: 0.9430 - val_loss: 0.2657 - val_acc: 0.9381 - 4s/epoch - 30ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 0.26569 to 0.26498, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2345 - acc: 0.9431 - val_loss: 0.2650 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.26498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 4s - loss: 0.2330 - acc: 0.9431 - val_loss: 0.2657 - val_acc: 0.9383 - 4s/epoch - 30ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.26498 to 0.26451, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2327 - acc: 0.9431 - val_loss: 0.2645 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.26451\n",
      "125/125 - 4s - loss: 0.2322 - acc: 0.9432 - val_loss: 0.2651 - val_acc: 0.9382 - 4s/epoch - 31ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.26451\n",
      "125/125 - 4s - loss: 0.2314 - acc: 0.9434 - val_loss: 0.2651 - val_acc: 0.9385 - 4s/epoch - 29ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.26451\n",
      "125/125 - 4s - loss: 0.2311 - acc: 0.9431 - val_loss: 0.2648 - val_acc: 0.9380 - 4s/epoch - 31ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.26451 to 0.26343, saving model to Models100\\cp_model_ei_1_2.h5\n",
      "125/125 - 4s - loss: 0.2310 - acc: 0.9432 - val_loss: 0.2634 - val_acc: 0.9385 - 4s/epoch - 33ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2304 - acc: 0.9434 - val_loss: 0.2636 - val_acc: 0.9385 - 4s/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2304 - acc: 0.9436 - val_loss: 0.2644 - val_acc: 0.9384 - 4s/epoch - 31ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2296 - acc: 0.9435 - val_loss: 0.2657 - val_acc: 0.9383 - 4s/epoch - 33ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2296 - acc: 0.9436 - val_loss: 0.2645 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2291 - acc: 0.9438 - val_loss: 0.2634 - val_acc: 0.9383 - 4s/epoch - 29ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2287 - acc: 0.9437 - val_loss: 0.2653 - val_acc: 0.9373 - 4s/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2284 - acc: 0.9437 - val_loss: 0.2659 - val_acc: 0.9381 - 4s/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2286 - acc: 0.9440 - val_loss: 0.2651 - val_acc: 0.9385 - 4s/epoch - 33ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2276 - acc: 0.9440 - val_loss: 0.2651 - val_acc: 0.9382 - 4s/epoch - 29ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2642 - val_acc: 0.9383 - 4s/epoch - 29ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2668 - val_acc: 0.9383 - 4s/epoch - 28ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2278 - acc: 0.9441 - val_loss: 0.2648 - val_acc: 0.9385 - 4s/epoch - 30ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2272 - acc: 0.9440 - val_loss: 0.2662 - val_acc: 0.9383 - 4s/epoch - 28ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2271 - acc: 0.9442 - val_loss: 0.2651 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2277 - acc: 0.9439 - val_loss: 0.2656 - val_acc: 0.9375 - 4s/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2271 - acc: 0.9439 - val_loss: 0.2643 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2271 - acc: 0.9439 - val_loss: 0.2659 - val_acc: 0.9380 - 4s/epoch - 36ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2270 - acc: 0.9442 - val_loss: 0.2651 - val_acc: 0.9383 - 4s/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2264 - acc: 0.9442 - val_loss: 0.2653 - val_acc: 0.9384 - 4s/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2260 - acc: 0.9442 - val_loss: 0.2662 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2266 - acc: 0.9441 - val_loss: 0.2659 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2260 - acc: 0.9443 - val_loss: 0.2666 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2259 - acc: 0.9442 - val_loss: 0.2666 - val_acc: 0.9384 - 4s/epoch - 28ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2259 - acc: 0.9442 - val_loss: 0.2672 - val_acc: 0.9386 - 4s/epoch - 29ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2255 - acc: 0.9444 - val_loss: 0.2667 - val_acc: 0.9375 - 4s/epoch - 30ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2257 - acc: 0.9443 - val_loss: 0.2683 - val_acc: 0.9382 - 4s/epoch - 29ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2257 - acc: 0.9443 - val_loss: 0.2665 - val_acc: 0.9386 - 4s/epoch - 28ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2255 - acc: 0.9444 - val_loss: 0.2674 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2254 - acc: 0.9442 - val_loss: 0.2664 - val_acc: 0.9384 - 4s/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2254 - acc: 0.9443 - val_loss: 0.2668 - val_acc: 0.9383 - 4s/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2252 - acc: 0.9443 - val_loss: 0.2675 - val_acc: 0.9384 - 4s/epoch - 31ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2253 - acc: 0.9443 - val_loss: 0.2676 - val_acc: 0.9384 - 4s/epoch - 30ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2250 - acc: 0.9442 - val_loss: 0.2677 - val_acc: 0.9383 - 4s/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2251 - acc: 0.9443 - val_loss: 0.2666 - val_acc: 0.9382 - 4s/epoch - 29ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2248 - acc: 0.9443 - val_loss: 0.2665 - val_acc: 0.9385 - 4s/epoch - 30ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2249 - acc: 0.9443 - val_loss: 0.2673 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2247 - acc: 0.9444 - val_loss: 0.2670 - val_acc: 0.9384 - 4s/epoch - 30ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2248 - acc: 0.9444 - val_loss: 0.2713 - val_acc: 0.9382 - 4s/epoch - 30ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2253 - acc: 0.9443 - val_loss: 0.2672 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2249 - acc: 0.9444 - val_loss: 0.2696 - val_acc: 0.9376 - 4s/epoch - 29ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2257 - acc: 0.9440 - val_loss: 0.2690 - val_acc: 0.9385 - 4s/epoch - 29ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2268 - acc: 0.9438 - val_loss: 0.2664 - val_acc: 0.9384 - 4s/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2267 - acc: 0.9439 - val_loss: 0.2679 - val_acc: 0.9381 - 4s/epoch - 29ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2257 - acc: 0.9441 - val_loss: 0.2677 - val_acc: 0.9386 - 4s/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2253 - acc: 0.9443 - val_loss: 0.2683 - val_acc: 0.9387 - 4s/epoch - 31ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2251 - acc: 0.9443 - val_loss: 0.2671 - val_acc: 0.9386 - 4s/epoch - 31ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2247 - acc: 0.9442 - val_loss: 0.2672 - val_acc: 0.9387 - 4s/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2247 - acc: 0.9441 - val_loss: 0.2671 - val_acc: 0.9386 - 4s/epoch - 30ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2244 - acc: 0.9443 - val_loss: 0.2668 - val_acc: 0.9387 - 4s/epoch - 29ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2245 - acc: 0.9444 - val_loss: 0.2672 - val_acc: 0.9386 - 4s/epoch - 31ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2243 - acc: 0.9444 - val_loss: 0.2684 - val_acc: 0.9383 - 4s/epoch - 30ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2245 - acc: 0.9443 - val_loss: 0.2683 - val_acc: 0.9385 - 4s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2242 - acc: 0.9443 - val_loss: 0.2671 - val_acc: 0.9387 - 4s/epoch - 29ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2240 - acc: 0.9442 - val_loss: 0.2676 - val_acc: 0.9387 - 4s/epoch - 30ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2244 - acc: 0.9445 - val_loss: 0.2688 - val_acc: 0.9386 - 4s/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2246 - acc: 0.9443 - val_loss: 0.2677 - val_acc: 0.9384 - 4s/epoch - 29ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2246 - acc: 0.9443 - val_loss: 0.2679 - val_acc: 0.9381 - 4s/epoch - 29ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2242 - acc: 0.9444 - val_loss: 0.2676 - val_acc: 0.9385 - 4s/epoch - 29ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2244 - acc: 0.9444 - val_loss: 0.2694 - val_acc: 0.9387 - 4s/epoch - 31ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26343\n",
      "125/125 - 4s - loss: 0.2245 - acc: 0.9444 - val_loss: 0.2681 - val_acc: 0.9383 - 4s/epoch - 30ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 32\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_ei_1_2.h5'\n",
    "history_save_file_name=\"cp_history_ei_1_2.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "src_tokenizer,src_vocab_size,src_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "tar_tokenizer,tar_vocab_size,tar_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(src_vocab_size,tar_vocab_size,src_max_sentence_length,tar_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "modelei1_2 = define_model_embedding(src_vocab_size, tar_vocab_size, src_max_sentence_length, tar_max_sentence_length, units,\"softmax\")\n",
    "create_model(modelei1_2,loss_func,learning_rate)\n",
    "plot_model(modelei1_2, to_file='model_images/cp_model_ei_1_2_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, modelei1_2, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(modelei1_2.history, 'loss_vs_epochs_images_100/cp_model_ei_1_2_le.png', 'Model 1 var 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English → Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 5, 64)             145408    \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 8, 64)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 8, 64)             24960     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 8, 4510)          293150    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 488,478\n",
      "Trainable params: 488,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 4.23800, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 27s - loss: 5.5525 - acc: 0.6307 - val_loss: 4.2380 - val_acc: 0.6414 - 27s/epoch - 430ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 4.23800 to 2.82870, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 3.3913 - acc: 0.6407 - val_loss: 2.8287 - val_acc: 0.6413 - 14s/epoch - 219ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 2.82870 to 2.66094, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.6816 - acc: 0.6408 - val_loss: 2.6609 - val_acc: 0.6417 - 13s/epoch - 211ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.66094 to 2.57948, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.5412 - acc: 0.6411 - val_loss: 2.5795 - val_acc: 0.6417 - 13s/epoch - 209ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.57948 to 2.54538, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.4646 - acc: 0.6411 - val_loss: 2.5454 - val_acc: 0.6417 - 13s/epoch - 203ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.54538 to 2.52966, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.4151 - acc: 0.6421 - val_loss: 2.5297 - val_acc: 0.6479 - 13s/epoch - 214ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.52966 to 2.50214, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.3714 - acc: 0.6535 - val_loss: 2.5021 - val_acc: 0.6524 - 13s/epoch - 201ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.50214 to 2.49217, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.3241 - acc: 0.6566 - val_loss: 2.4922 - val_acc: 0.6547 - 13s/epoch - 201ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.49217 to 2.47177, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.2848 - acc: 0.6560 - val_loss: 2.4718 - val_acc: 0.6626 - 13s/epoch - 200ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.47177 to 2.46640, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.2514 - acc: 0.6619 - val_loss: 2.4664 - val_acc: 0.6619 - 13s/epoch - 199ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.46640 to 2.44558, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.2194 - acc: 0.6633 - val_loss: 2.4456 - val_acc: 0.6624 - 13s/epoch - 199ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.44558 to 2.43496, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.1827 - acc: 0.6637 - val_loss: 2.4350 - val_acc: 0.6621 - 13s/epoch - 202ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.43496 to 2.41257, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 2.1462 - acc: 0.6646 - val_loss: 2.4126 - val_acc: 0.6632 - 14s/epoch - 215ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.41257 to 2.39654, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 2.1003 - acc: 0.6665 - val_loss: 2.3965 - val_acc: 0.6639 - 14s/epoch - 215ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.39654 to 2.36574, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 2.0522 - acc: 0.6686 - val_loss: 2.3657 - val_acc: 0.6637 - 13s/epoch - 205ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 2.36574 to 2.33517, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.9975 - acc: 0.6725 - val_loss: 2.3352 - val_acc: 0.6719 - 12s/epoch - 197ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 2.33517 to 2.31215, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.9435 - acc: 0.6778 - val_loss: 2.3121 - val_acc: 0.6737 - 12s/epoch - 196ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 2.31215 to 2.28043, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.8880 - acc: 0.6825 - val_loss: 2.2804 - val_acc: 0.6772 - 13s/epoch - 199ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 2.28043 to 2.24397, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.8314 - acc: 0.6882 - val_loss: 2.2440 - val_acc: 0.6848 - 13s/epoch - 208ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 2.24397 to 2.22368, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 16s - loss: 1.7778 - acc: 0.6939 - val_loss: 2.2237 - val_acc: 0.6849 - 16s/epoch - 246ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 2.22368 to 2.19228, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.7241 - acc: 0.6985 - val_loss: 2.1923 - val_acc: 0.6899 - 13s/epoch - 213ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 2.19228 to 2.17345, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 1.6669 - acc: 0.7043 - val_loss: 2.1734 - val_acc: 0.6904 - 14s/epoch - 222ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 2.17345 to 2.15100, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.6117 - acc: 0.7104 - val_loss: 2.1510 - val_acc: 0.6959 - 13s/epoch - 203ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 2.15100 to 2.12698, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 1.5570 - acc: 0.7154 - val_loss: 2.1270 - val_acc: 0.6997 - 14s/epoch - 224ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 2.12698 to 2.11034, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.5030 - acc: 0.7217 - val_loss: 2.1103 - val_acc: 0.7017 - 13s/epoch - 214ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 2.11034 to 2.09374, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 14s - loss: 1.4513 - acc: 0.7260 - val_loss: 2.0937 - val_acc: 0.7041 - 14s/epoch - 225ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 2.09374 to 2.07864, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.4023 - acc: 0.7305 - val_loss: 2.0786 - val_acc: 0.7046 - 13s/epoch - 204ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 2.07864 to 2.06371, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.3559 - acc: 0.7356 - val_loss: 2.0637 - val_acc: 0.7065 - 13s/epoch - 202ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 2.06371 to 2.05454, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.3084 - acc: 0.7402 - val_loss: 2.0545 - val_acc: 0.7058 - 12s/epoch - 197ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 2.05454 to 2.04694, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.2664 - acc: 0.7446 - val_loss: 2.0469 - val_acc: 0.7075 - 12s/epoch - 197ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 2.04694 to 2.03656, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.2287 - acc: 0.7485 - val_loss: 2.0366 - val_acc: 0.7100 - 12s/epoch - 198ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 2.03656 to 2.03496, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.1892 - acc: 0.7525 - val_loss: 2.0350 - val_acc: 0.7079 - 12s/epoch - 198ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 2.03496 to 2.01720, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.1526 - acc: 0.7571 - val_loss: 2.0172 - val_acc: 0.7126 - 12s/epoch - 198ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 2.01720\n",
      "63/63 - 12s - loss: 1.1112 - acc: 0.7613 - val_loss: 2.0180 - val_acc: 0.7122 - 12s/epoch - 196ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss improved from 2.01720 to 2.01638, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 1.0779 - acc: 0.7665 - val_loss: 2.0164 - val_acc: 0.7124 - 12s/epoch - 198ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 2.01638 to 2.01312, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.0460 - acc: 0.7699 - val_loss: 2.0131 - val_acc: 0.7138 - 13s/epoch - 199ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss improved from 2.01312 to 2.01058, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 1.0121 - acc: 0.7749 - val_loss: 2.0106 - val_acc: 0.7129 - 13s/epoch - 202ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss improved from 2.01058 to 2.00797, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 12s - loss: 0.9838 - acc: 0.7781 - val_loss: 2.0080 - val_acc: 0.7147 - 12s/epoch - 196ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 2.00797\n",
      "63/63 - 12s - loss: 0.9517 - acc: 0.7843 - val_loss: 2.0137 - val_acc: 0.7113 - 12s/epoch - 196ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 2.00797\n",
      "63/63 - 12s - loss: 0.9240 - acc: 0.7874 - val_loss: 2.0118 - val_acc: 0.7147 - 12s/epoch - 197ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 2.00797 to 2.00458, saving model to Models100\\cp_model_1_3.h5\n",
      "63/63 - 13s - loss: 0.8963 - acc: 0.7923 - val_loss: 2.0046 - val_acc: 0.7154 - 13s/epoch - 208ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.8730 - acc: 0.7964 - val_loss: 2.0099 - val_acc: 0.7178 - 13s/epoch - 204ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.8508 - acc: 0.7992 - val_loss: 2.0069 - val_acc: 0.7143 - 13s/epoch - 203ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.8250 - acc: 0.8049 - val_loss: 2.0136 - val_acc: 0.7160 - 13s/epoch - 201ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.8023 - acc: 0.8079 - val_loss: 2.0150 - val_acc: 0.7142 - 13s/epoch - 201ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.7965 - acc: 0.8081 - val_loss: 2.0169 - val_acc: 0.7144 - 13s/epoch - 201ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.7700 - acc: 0.8129 - val_loss: 2.0170 - val_acc: 0.7184 - 12s/epoch - 190ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.7477 - acc: 0.8158 - val_loss: 2.0125 - val_acc: 0.7167 - 13s/epoch - 199ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.7235 - acc: 0.8207 - val_loss: 2.0113 - val_acc: 0.7188 - 12s/epoch - 192ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.7041 - acc: 0.8246 - val_loss: 2.0119 - val_acc: 0.7161 - 13s/epoch - 199ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.6879 - acc: 0.8275 - val_loss: 2.0179 - val_acc: 0.7159 - 13s/epoch - 207ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.6721 - acc: 0.8309 - val_loss: 2.0271 - val_acc: 0.7209 - 12s/epoch - 197ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.6570 - acc: 0.8328 - val_loss: 2.0280 - val_acc: 0.7179 - 12s/epoch - 196ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.6430 - acc: 0.8365 - val_loss: 2.0310 - val_acc: 0.7156 - 12s/epoch - 198ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.6283 - acc: 0.8391 - val_loss: 2.0276 - val_acc: 0.7180 - 12s/epoch - 196ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.6187 - acc: 0.8411 - val_loss: 2.0321 - val_acc: 0.7154 - 13s/epoch - 204ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.6045 - acc: 0.8445 - val_loss: 2.0387 - val_acc: 0.7169 - 13s/epoch - 209ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5914 - acc: 0.8452 - val_loss: 2.0433 - val_acc: 0.7186 - 12s/epoch - 197ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5801 - acc: 0.8486 - val_loss: 2.0454 - val_acc: 0.7184 - 12s/epoch - 198ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5673 - acc: 0.8504 - val_loss: 2.0533 - val_acc: 0.7188 - 12s/epoch - 197ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5599 - acc: 0.8512 - val_loss: 2.0547 - val_acc: 0.7179 - 12s/epoch - 196ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5493 - acc: 0.8529 - val_loss: 2.0682 - val_acc: 0.7143 - 12s/epoch - 196ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.5373 - acc: 0.8560 - val_loss: 2.0583 - val_acc: 0.7169 - 13s/epoch - 204ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.5281 - acc: 0.8584 - val_loss: 2.0688 - val_acc: 0.7174 - 13s/epoch - 202ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5169 - acc: 0.8595 - val_loss: 2.0674 - val_acc: 0.7182 - 12s/epoch - 197ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.5079 - acc: 0.8617 - val_loss: 2.0772 - val_acc: 0.7172 - 12s/epoch - 196ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4998 - acc: 0.8626 - val_loss: 2.0840 - val_acc: 0.7174 - 12s/epoch - 197ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4913 - acc: 0.8641 - val_loss: 2.0793 - val_acc: 0.7195 - 12s/epoch - 198ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4874 - acc: 0.8651 - val_loss: 2.0859 - val_acc: 0.7171 - 13s/epoch - 199ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4810 - acc: 0.8654 - val_loss: 2.0939 - val_acc: 0.7182 - 12s/epoch - 195ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4754 - acc: 0.8682 - val_loss: 2.0954 - val_acc: 0.7171 - 13s/epoch - 201ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4706 - acc: 0.8677 - val_loss: 2.0937 - val_acc: 0.7179 - 13s/epoch - 204ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4593 - acc: 0.8691 - val_loss: 2.0982 - val_acc: 0.7188 - 12s/epoch - 197ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4508 - acc: 0.8712 - val_loss: 2.1059 - val_acc: 0.7162 - 13s/epoch - 200ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4446 - acc: 0.8722 - val_loss: 2.1149 - val_acc: 0.7169 - 13s/epoch - 203ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4390 - acc: 0.8735 - val_loss: 2.1219 - val_acc: 0.7174 - 13s/epoch - 205ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4275 - acc: 0.8769 - val_loss: 2.1212 - val_acc: 0.7202 - 12s/epoch - 198ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4249 - acc: 0.8760 - val_loss: 2.1284 - val_acc: 0.7150 - 13s/epoch - 203ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4199 - acc: 0.8767 - val_loss: 2.1421 - val_acc: 0.7190 - 12s/epoch - 196ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4150 - acc: 0.8771 - val_loss: 2.1414 - val_acc: 0.7175 - 13s/epoch - 200ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.4086 - acc: 0.8782 - val_loss: 2.1402 - val_acc: 0.7192 - 13s/epoch - 202ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4096 - acc: 0.8787 - val_loss: 2.1446 - val_acc: 0.7166 - 12s/epoch - 197ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4061 - acc: 0.8784 - val_loss: 2.1475 - val_acc: 0.7167 - 12s/epoch - 195ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.4003 - acc: 0.8797 - val_loss: 2.1566 - val_acc: 0.7185 - 12s/epoch - 194ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.3900 - acc: 0.8823 - val_loss: 2.1563 - val_acc: 0.7181 - 12s/epoch - 195ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3843 - acc: 0.8826 - val_loss: 2.1628 - val_acc: 0.7169 - 13s/epoch - 206ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.3833 - acc: 0.8820 - val_loss: 2.1769 - val_acc: 0.7153 - 12s/epoch - 197ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3825 - acc: 0.8832 - val_loss: 2.1841 - val_acc: 0.7146 - 13s/epoch - 204ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3821 - acc: 0.8834 - val_loss: 2.1845 - val_acc: 0.7169 - 13s/epoch - 205ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.3795 - acc: 0.8829 - val_loss: 2.1953 - val_acc: 0.7135 - 12s/epoch - 188ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3723 - acc: 0.8836 - val_loss: 2.1939 - val_acc: 0.7142 - 13s/epoch - 202ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.3662 - acc: 0.8860 - val_loss: 2.1909 - val_acc: 0.7160 - 12s/epoch - 197ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.00458\n",
      "63/63 - 12s - loss: 0.3626 - acc: 0.8865 - val_loss: 2.1907 - val_acc: 0.7136 - 12s/epoch - 196ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3588 - acc: 0.8871 - val_loss: 2.1985 - val_acc: 0.7149 - 13s/epoch - 202ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3588 - acc: 0.8866 - val_loss: 2.1976 - val_acc: 0.7161 - 13s/epoch - 205ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3541 - acc: 0.8877 - val_loss: 2.2162 - val_acc: 0.7166 - 13s/epoch - 202ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 2.00458\n",
      "63/63 - 14s - loss: 0.3505 - acc: 0.8872 - val_loss: 2.2077 - val_acc: 0.7170 - 14s/epoch - 215ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 2.00458\n",
      "63/63 - 13s - loss: 0.3475 - acc: 0.8889 - val_loss: 2.2232 - val_acc: 0.7163 - 13s/epoch - 205ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 2.00458\n",
      "63/63 - 15s - loss: 0.3439 - acc: 0.8898 - val_loss: 2.2147 - val_acc: 0.7176 - 15s/epoch - 235ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.00458\n",
      "63/63 - 20s - loss: 0.3440 - acc: 0.8887 - val_loss: 2.2288 - val_acc: 0.7159 - 20s/epoch - 323ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 64\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "model_save_file_name='Models100/cp_model_1_3.h5'\n",
    "history_save_file_name=\"cp_history_1_3.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model1_3 = define_model_embedding(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,\"sigmoid\")\n",
    "create_model(model1_3,loss_func,learning_rate)\n",
    "plot_model(model1_3, to_file='model_images/cp_model_1_3_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model1_3, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model1_3.history, 'loss_vs_epochs_images_100/cp_model_1_3_le.png', 'Model 1 var 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish → English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 2272 8 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 8, 64)             288640    \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 64)                24960     \n",
      "                                                                 \n",
      " repeat_vector_5 (RepeatVect  (None, 5, 64)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, 5, 64)             24960     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 5, 2272)          147680    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 486,240\n",
      "Trainable params: 486,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.12388, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 11s - loss: 3.8367 - acc: 0.6338 - val_loss: 2.1239 - val_acc: 0.0131 - 11s/epoch - 176ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.12388 to 1.64359, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 1.8319 - acc: 0.0140 - val_loss: 1.6436 - val_acc: 0.0142 - 5s/epoch - 75ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 1.64359 to 1.57766, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 1.5976 - acc: 0.0142 - val_loss: 1.5777 - val_acc: 0.0140 - 4s/epoch - 66ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 1.57766 to 1.29724, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 1.3884 - acc: 0.0143 - val_loss: 1.2972 - val_acc: 0.0131 - 4s/epoch - 70ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 1.29724 to 1.27511, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 1.2770 - acc: 0.0141 - val_loss: 1.2751 - val_acc: 0.0131 - 4s/epoch - 66ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 1.27511 to 0.92853, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 1.0320 - acc: 0.0141 - val_loss: 0.9285 - val_acc: 0.0131 - 4s/epoch - 66ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.92853 to 0.91772, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.9101 - acc: 0.5136 - val_loss: 0.9177 - val_acc: 0.9197 - 4s/epoch - 64ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.91772 to 0.31746, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.4437 - acc: 0.9222 - val_loss: 0.3175 - val_acc: 0.9197 - 4s/epoch - 68ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.31746 to 0.30803, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.3014 - acc: 0.9222 - val_loss: 0.3080 - val_acc: 0.9197 - 4s/epoch - 68ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.30803 to 0.30444, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2949 - acc: 0.9222 - val_loss: 0.3044 - val_acc: 0.9197 - 4s/epoch - 66ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.30444 to 0.29856, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2892 - acc: 0.9222 - val_loss: 0.2986 - val_acc: 0.9197 - 4s/epoch - 65ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.29856 to 0.29450, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 0.2848 - acc: 0.9222 - val_loss: 0.2945 - val_acc: 0.9197 - 5s/epoch - 76ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.29450 to 0.29222, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2798 - acc: 0.9222 - val_loss: 0.2922 - val_acc: 0.9197 - 4s/epoch - 68ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.29222 to 0.29027, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2770 - acc: 0.9222 - val_loss: 0.2903 - val_acc: 0.9196 - 4s/epoch - 66ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.29027 to 0.28917, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 0.2736 - acc: 0.9222 - val_loss: 0.2892 - val_acc: 0.9197 - 5s/epoch - 72ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.28917 to 0.28760, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 0.2708 - acc: 0.9222 - val_loss: 0.2876 - val_acc: 0.9196 - 5s/epoch - 73ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.28760 to 0.28643, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2687 - acc: 0.9222 - val_loss: 0.2864 - val_acc: 0.9195 - 4s/epoch - 66ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.28643 to 0.28398, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2667 - acc: 0.9222 - val_loss: 0.2840 - val_acc: 0.9196 - 4s/epoch - 65ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.28398 to 0.28140, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2644 - acc: 0.9222 - val_loss: 0.2814 - val_acc: 0.9196 - 4s/epoch - 67ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.28140\n",
      "63/63 - 4s - loss: 0.2629 - acc: 0.9222 - val_loss: 0.2816 - val_acc: 0.9197 - 4s/epoch - 65ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.28140 to 0.28099, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2617 - acc: 0.9222 - val_loss: 0.2810 - val_acc: 0.9197 - 4s/epoch - 62ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.28099 to 0.27948, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2597 - acc: 0.9222 - val_loss: 0.2795 - val_acc: 0.9197 - 4s/epoch - 63ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.27948\n",
      "63/63 - 4s - loss: 0.2586 - acc: 0.9222 - val_loss: 0.2795 - val_acc: 0.9197 - 4s/epoch - 70ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.27948 to 0.27848, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2574 - acc: 0.9222 - val_loss: 0.2785 - val_acc: 0.9197 - 4s/epoch - 67ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.27848\n",
      "63/63 - 4s - loss: 0.2563 - acc: 0.9222 - val_loss: 0.2789 - val_acc: 0.9197 - 4s/epoch - 65ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.27848 to 0.27680, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2554 - acc: 0.9222 - val_loss: 0.2768 - val_acc: 0.9197 - 4s/epoch - 65ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.27680 to 0.27668, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2540 - acc: 0.9222 - val_loss: 0.2767 - val_acc: 0.9197 - 4s/epoch - 67ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.27668 to 0.27641, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2536 - acc: 0.9222 - val_loss: 0.2764 - val_acc: 0.9197 - 4s/epoch - 65ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 0.27641 to 0.27610, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2530 - acc: 0.9227 - val_loss: 0.2761 - val_acc: 0.9207 - 4s/epoch - 62ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 0.27610 to 0.27510, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2518 - acc: 0.9229 - val_loss: 0.2751 - val_acc: 0.9207 - 4s/epoch - 64ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.27510\n",
      "63/63 - 4s - loss: 0.2511 - acc: 0.9229 - val_loss: 0.2757 - val_acc: 0.9205 - 4s/epoch - 66ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.27510\n",
      "63/63 - 4s - loss: 0.2507 - acc: 0.9240 - val_loss: 0.2755 - val_acc: 0.9333 - 4s/epoch - 62ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.27510 to 0.27479, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2501 - acc: 0.9333 - val_loss: 0.2748 - val_acc: 0.9327 - 4s/epoch - 64ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.27479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 4s - loss: 0.2495 - acc: 0.9354 - val_loss: 0.2752 - val_acc: 0.9332 - 4s/epoch - 61ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss improved from 0.27479 to 0.27343, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2488 - acc: 0.9362 - val_loss: 0.2734 - val_acc: 0.9342 - 4s/epoch - 68ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.27343 to 0.26582, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2434 - acc: 0.9379 - val_loss: 0.2658 - val_acc: 0.9360 - 4s/epoch - 63ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.26582\n",
      "63/63 - 4s - loss: 0.2400 - acc: 0.9391 - val_loss: 0.2667 - val_acc: 0.9367 - 4s/epoch - 68ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.26582\n",
      "63/63 - 4s - loss: 0.2390 - acc: 0.9391 - val_loss: 0.2668 - val_acc: 0.9369 - 4s/epoch - 67ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss improved from 0.26582 to 0.26497, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2392 - acc: 0.9391 - val_loss: 0.2650 - val_acc: 0.9369 - 4s/epoch - 71ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.26497\n",
      "63/63 - 4s - loss: 0.2384 - acc: 0.9392 - val_loss: 0.2662 - val_acc: 0.9371 - 4s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.26497\n",
      "63/63 - 4s - loss: 0.2381 - acc: 0.9396 - val_loss: 0.2653 - val_acc: 0.9363 - 4s/epoch - 68ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.26497 to 0.26479, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 0.2371 - acc: 0.9399 - val_loss: 0.2648 - val_acc: 0.9371 - 5s/epoch - 73ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss improved from 0.26479 to 0.26376, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 5s - loss: 0.2364 - acc: 0.9400 - val_loss: 0.2638 - val_acc: 0.9370 - 5s/epoch - 78ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss improved from 0.26376 to 0.26372, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2358 - acc: 0.9401 - val_loss: 0.2637 - val_acc: 0.9369 - 4s/epoch - 71ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.26372\n",
      "63/63 - 4s - loss: 0.2350 - acc: 0.9404 - val_loss: 0.2639 - val_acc: 0.9370 - 4s/epoch - 66ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss improved from 0.26372 to 0.26323, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2354 - acc: 0.9406 - val_loss: 0.2632 - val_acc: 0.9371 - 4s/epoch - 67ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26323\n",
      "63/63 - 4s - loss: 0.2342 - acc: 0.9407 - val_loss: 0.2639 - val_acc: 0.9374 - 4s/epoch - 70ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26323\n",
      "63/63 - 4s - loss: 0.2333 - acc: 0.9410 - val_loss: 0.2639 - val_acc: 0.9376 - 4s/epoch - 65ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss improved from 0.26323 to 0.26307, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2324 - acc: 0.9413 - val_loss: 0.2631 - val_acc: 0.9375 - 4s/epoch - 65ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss improved from 0.26307 to 0.26271, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2323 - acc: 0.9416 - val_loss: 0.2627 - val_acc: 0.9377 - 4s/epoch - 66ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss improved from 0.26271 to 0.26215, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2318 - acc: 0.9417 - val_loss: 0.2622 - val_acc: 0.9377 - 4s/epoch - 64ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26215\n",
      "63/63 - 4s - loss: 0.2315 - acc: 0.9418 - val_loss: 0.2658 - val_acc: 0.9377 - 4s/epoch - 63ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss improved from 0.26215 to 0.26150, saving model to Models100\\cp_model_ei_1_3.h5\n",
      "63/63 - 4s - loss: 0.2312 - acc: 0.9421 - val_loss: 0.2615 - val_acc: 0.9379 - 4s/epoch - 63ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2304 - acc: 0.9423 - val_loss: 0.2637 - val_acc: 0.9379 - 4s/epoch - 65ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2297 - acc: 0.9424 - val_loss: 0.2618 - val_acc: 0.9380 - 4s/epoch - 67ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2299 - acc: 0.9426 - val_loss: 0.2629 - val_acc: 0.9380 - 4s/epoch - 62ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2297 - acc: 0.9426 - val_loss: 0.2631 - val_acc: 0.9372 - 4s/epoch - 63ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2293 - acc: 0.9427 - val_loss: 0.2625 - val_acc: 0.9380 - 4s/epoch - 65ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2293 - acc: 0.9427 - val_loss: 0.2658 - val_acc: 0.9375 - 4s/epoch - 63ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2290 - acc: 0.9427 - val_loss: 0.2625 - val_acc: 0.9379 - 4s/epoch - 63ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2285 - acc: 0.9430 - val_loss: 0.2633 - val_acc: 0.9382 - 4s/epoch - 63ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2283 - acc: 0.9428 - val_loss: 0.2655 - val_acc: 0.9377 - 4s/epoch - 71ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2283 - acc: 0.9428 - val_loss: 0.2627 - val_acc: 0.9381 - 4s/epoch - 67ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2278 - acc: 0.9430 - val_loss: 0.2617 - val_acc: 0.9381 - 4s/epoch - 63ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2271 - acc: 0.9430 - val_loss: 0.2636 - val_acc: 0.9380 - 4s/epoch - 65ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2274 - acc: 0.9429 - val_loss: 0.2626 - val_acc: 0.9380 - 4s/epoch - 66ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2271 - acc: 0.9433 - val_loss: 0.2635 - val_acc: 0.9378 - 4s/epoch - 63ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2269 - acc: 0.9430 - val_loss: 0.2625 - val_acc: 0.9379 - 4s/epoch - 62ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2263 - acc: 0.9432 - val_loss: 0.2652 - val_acc: 0.9378 - 4s/epoch - 62ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2264 - acc: 0.9434 - val_loss: 0.2637 - val_acc: 0.9382 - 4s/epoch - 64ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2261 - acc: 0.9434 - val_loss: 0.2630 - val_acc: 0.9381 - 4s/epoch - 61ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2256 - acc: 0.9433 - val_loss: 0.2645 - val_acc: 0.9380 - 4s/epoch - 67ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2274 - acc: 0.9431 - val_loss: 0.2638 - val_acc: 0.9382 - 4s/epoch - 70ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26150\n",
      "63/63 - 5s - loss: 0.2265 - acc: 0.9430 - val_loss: 0.2643 - val_acc: 0.9380 - 5s/epoch - 74ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26150\n",
      "63/63 - 5s - loss: 0.2260 - acc: 0.9433 - val_loss: 0.2635 - val_acc: 0.9382 - 5s/epoch - 75ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2255 - acc: 0.9434 - val_loss: 0.2645 - val_acc: 0.9381 - 4s/epoch - 68ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26150\n",
      "63/63 - 5s - loss: 0.2258 - acc: 0.9435 - val_loss: 0.2644 - val_acc: 0.9380 - 5s/epoch - 73ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2257 - acc: 0.9435 - val_loss: 0.2666 - val_acc: 0.9381 - 4s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2250 - acc: 0.9435 - val_loss: 0.2642 - val_acc: 0.9380 - 4s/epoch - 65ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2251 - acc: 0.9434 - val_loss: 0.2641 - val_acc: 0.9377 - 4s/epoch - 71ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2249 - acc: 0.9437 - val_loss: 0.2650 - val_acc: 0.9385 - 4s/epoch - 68ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2251 - acc: 0.9438 - val_loss: 0.2651 - val_acc: 0.9382 - 4s/epoch - 64ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2244 - acc: 0.9436 - val_loss: 0.2648 - val_acc: 0.9386 - 4s/epoch - 65ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2247 - acc: 0.9437 - val_loss: 0.2648 - val_acc: 0.9385 - 4s/epoch - 67ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2244 - acc: 0.9437 - val_loss: 0.2642 - val_acc: 0.9385 - 4s/epoch - 67ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2244 - acc: 0.9438 - val_loss: 0.2659 - val_acc: 0.9385 - 4s/epoch - 68ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26150\n",
      "63/63 - 5s - loss: 0.2240 - acc: 0.9437 - val_loss: 0.2647 - val_acc: 0.9383 - 5s/epoch - 73ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2240 - acc: 0.9438 - val_loss: 0.2647 - val_acc: 0.9385 - 4s/epoch - 71ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2241 - acc: 0.9439 - val_loss: 0.2648 - val_acc: 0.9385 - 4s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2245 - acc: 0.9439 - val_loss: 0.2638 - val_acc: 0.9384 - 4s/epoch - 65ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2238 - acc: 0.9440 - val_loss: 0.2646 - val_acc: 0.9385 - 4s/epoch - 63ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2238 - acc: 0.9439 - val_loss: 0.2650 - val_acc: 0.9382 - 4s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2239 - acc: 0.9438 - val_loss: 0.2653 - val_acc: 0.9385 - 4s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2233 - acc: 0.9438 - val_loss: 0.2639 - val_acc: 0.9385 - 4s/epoch - 67ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2236 - acc: 0.9439 - val_loss: 0.2654 - val_acc: 0.9385 - 4s/epoch - 64ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2234 - acc: 0.9439 - val_loss: 0.2652 - val_acc: 0.9385 - 4s/epoch - 70ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2233 - acc: 0.9441 - val_loss: 0.2651 - val_acc: 0.9384 - 4s/epoch - 68ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2227 - acc: 0.9440 - val_loss: 0.2655 - val_acc: 0.9381 - 4s/epoch - 64ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2226 - acc: 0.9442 - val_loss: 0.2639 - val_acc: 0.9385 - 4s/epoch - 64ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26150\n",
      "63/63 - 4s - loss: 0.2225 - acc: 0.9442 - val_loss: 0.2644 - val_acc: 0.9384 - 4s/epoch - 68ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 64\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "model_save_file_name='Models100/cp_model_ei_1_3.h5'\n",
    "history_save_file_name=\"cp_history_ei_1_3.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "src_tokenizer,src_vocab_size,src_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "tar_tokenizer,tar_vocab_size,tar_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(src_vocab_size,tar_vocab_size,src_max_sentence_length,tar_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "modelei1_3 = define_model_embedding(src_vocab_size, tar_vocab_size, src_max_sentence_length, tar_max_sentence_length, units,\"sigmoid\")\n",
    "create_model(modelei1_3,loss_func,learning_rate)\n",
    "plot_model(modelei1_3, to_file='model_images/cp_model_ei_1_3_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, modelei1_3, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(modelei1_3.history, 'loss_vs_epochs_images_100/cp_model_ei_1_3_le.png', 'Model 1 var 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'LOSS')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEJCAYAAAB11IfBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4nElEQVR4nO3dd5xU1f3/8deZPrO9UZYFAUGaLMWVoCgKiC2CjRhUEGMLRoN+v/pVE80vxsRETWIvWDEiwUpRLKgoVkRZQemItF1Y2Mb22ann98edXRZcYMvMlpnP8/GYx+7M3Lnn3B1433PPPfdcpbVGCCFEdDO1dwWEEEJEnoS9EELEAAl7IYSIARL2QggRAyTshRAiBljauwKHk56ernv37t3e1RBCiE4jNze3WGud0dh7HTbse/fuzapVq9q7GkII0WkopXYe7j3pxhFCiBggYS+EEDFAwl4IIWJAh+2zF0JEH5/PR35+PrW1te1dlU7N4XCQlZWF1Wpt8mck7IUQbSY/P5+EhAR69+6NUqq9q9Mpaa0pKSkhPz+fPn36NPlz0o0jhGgztbW1pKWlSdC3glKKtLS0Zh8dSdgLIdqUBH3rteRvGHVhP/v72Xy5+8v2roYQQnQoURf2c9bN4as9X7V3NYQQHVR8fPxBz1988UVuvPFGAGbPns1LL7102M8uX76cr75qfr689dZb3HfffU1e/s4776Rnz54/q2trRN0JWofFQa1fzvQLIZpv5syZR3x/+fLlxMfHc/LJJzd5nX6/n8mTJzN58uQmf2bSpEnceOON9O/fv8mfOZqoC3unxUltQMJeCNF8d999N/Hx8dx66608+uijzJ49G4vFwuDBg7nvvvuYPXs2ZrOZl19+mccee4yePXty1VVXUVxcTEZGBnPmzKFXr15ceeWVOBwOVq9ezZgxY8jOzmbVqlU8/vjj7Nu3j5kzZ7Jt2zYAnnrqqZ/tPEaPHh32bYu6sHeYpWUvRGfwl7fXs2FPRVjXOTgzkT9PGnLEZdxuN8OHD69/Xlpa2mir+7777mP79u3Y7XbKyspITk5m5syZ9TsDMFrgM2bMYMaMGbzwwgvMmjWLRYsWAcYw06+++gqz2cyLL75Yv95Zs2Zx2mmnsXDhQgKBAFVVVa3e7qaIuj57h8UhLXshxGE5nU7WrFlT/7jnnnsaXS47O5vLL7+cl19+GYul8XbxihUruOyyywCYPn06X3zxRf17v/rVrzCbzT/7zMcff8z1118PgNlsJikpqbWb1CTR17KXPnshOoWjtcDb2zvvvMNnn33G22+/zb333svatWub9fm4uLgI1axloq9lL904QohWCgaD5OXlMW7cOO6//37Ky8upqqoiISGBysrK+uVOPvlkXnnlFQDmzZvHqaeeetR1T5gwgaeeegqAQCBAeXl5ZDbiENEX9hYH7oC7vashhOjEAoEA06ZNY+jQoYwYMYJZs2aRnJzMpEmTWLhwIcOHD+fzzz/nscceY86cOWRnZzN37lweeeSRo677kUce4ZNPPmHo0KGccMIJbNiw4WfL3HbbbWRlZVFTU0NWVhZ33313q7dJaa1bvZJIyMnJ0S25eckdn9/BD0U/8O5F70agVkKI1ti4cSODBg1q72pEhcb+lkqpXK11TmPLR1/LXrpxhBDiZ6Iu7J0Wp4S9EEIcIurCXvrshRDi56Iv7M0O/EE//qC/vasihBAdRvSFvcUBgCfgaeeaCCFExxF1Ye+0OAFw+6UrRwgh6kRd2NvNdgA5SSuEaFRHn+K4pqaGX/7ylwwcOJAhQ4Zwxx13NLu8xkTldAkgYS+EaL6OMsXxrbfeyrhx4/B6vUyYMIH33nuPc845p8mfb0ybhb1SagdQCQQA/+EG/rdWXTeOTIYmhGiujjDFscvlYty4cQDYbDZGjhxJfn5+q7etrVv247TWxZEswGE2WvbSZy9EB/feHbC3eZOLHVW3oXDOkbtLOtMUx2VlZbz99tvcdNNNTf8bHEbU9dlLN44Q4kg6yxTHfr+fSy+9lFmzZtG3b99mbWNj2rJlr4EPlFIaeFpr/UwkCqkPe+nGEaJjO0oLvL219xTH1113Hf379+fmm29u1XrqtGXL/hSt9UjgHOAGpdTYQxdQSl2nlFqllFpVVFTUokKc5lCfvbTshRAt1N5THN91112Ul5fz8MMPh2eDaMOw11rvDv0sBBYCoxpZ5hmtdY7WOicjI6NF5dS17KXPXgjRUu05xXF+fj733nsvGzZsYOTIkQwfPpznnnuu1dvUJlMcK6XiAJPWujL0+4fAPVrr9w/3mZZOcVzpreTk+Sdz24m3MX3w9JZXWggRdjLFcfg0d4rjtuqz7wosVErVlfnfIwV9a8gJWiGE+Lk2CXut9TZgWFuUZTVZMSuzdOMIIUQDUTf0EkI3HZfROEIIUS86w17uViWEEAeJzrC3SNgLIURDURn2TotTunGEEKKBqAx7h9khJ2iFEI3q6FMcA5x99tkMGzaMIUOGMHPmTAKBQLPLPFTUTXEM0o0jhGiZjjLF8WuvvUZiYiJaa6ZMmcLrr7/O1KlTm/z5xkRny17CXgjRAnfffTf/+te/AHj00UcZPHgw2dnZTJ06lR07djB79mweeuih+itod+zYwfjx48nOzmbChAns2rULgCuvvJKZM2fyi1/8gttuu+2go4d9+/Zx4YUXMmzYMIYNG9bokUJiYiJg7Ci8Xi+ha5RaJSpb9k6Lk72Bve1dDSHEEdz/zf1sKt0U1nUOTB3I7aNuP+IynWWK47POOotvvvmGc845hylTpjTvD9GIqGzZ2812adkLIRrVWaY4Xrp0KQUFBXg8Hj7++ONmbWNjorJlLxdVCdHxHa0F3t7ae4pjAIfDwfnnn8/ixYuZOHFiq9YVlS17uahKCNEa7TnFcVVVFQUFBYDRZ//OO+8wcODAVm9TVIa90+KUsBdCtFh7TnFcXV3N5MmTyc7OZvjw4XTp0uWoo4Saok2mOG6Jlk5xDPDMD8/w2OrH+G76d1hN1jDXTAjRUjLFcfg0d4rjqGzZ1910XFr3QghhiM6wlznthRDiIFEZ9k6L3IdWiI6qo3YddyYt+RtGZdjX34c2IPPjCNGROBwOSkpKJPBbQWtNSUkJDoejWZ+LynH2drMdAI/f0841EUI0lJWVRX5+PkVFRe1dlU7N4XCQlZXVrM9EZdjXd+PIhVVCdChWq5U+ffq0dzViUnR244RG48g0x0IIYYjOsJfROEIIcZDoDnvpxhFCCCBKw16GXgohxMGiMuylz14IIQ4WlWFvtxhDL6VlL4QQhqgMe6vJisVkkT57IYQIicqwB3CaZZpjIYSoE7Vhb7fYpWUvhBAhbRr2SimzUmq1UmpJpMuSu1UJIcQBbd2yvwnY2BYFOSwS9kIIUafNwl4plQX8EniuLcpzWpwy66UQQoS0Zcv+YeA2IHi4BZRS1ymlVimlVrV2Vjxp2QshxAFtEvZKqfOAQq117pGW01o/o7XO0VrnZGRktKpM6bMXQogD2qplPwaYrJTaAbwCjFdKvRzJAqVlL4QQB7RJ2Gut/6C1ztJa9wamAh9rradFskynxSlDL4UQIiRqx9k7zA6ZG0cIIULa/E5VWuvlwPJIl2O32KUbRwghQqK6Ze8JeOTGxkIIQRSHvdPiJKAD+IP+9q6KEEK0u6gN+7q7VcmFVUIIEQNhL/32QggRzWFvlrAXQog6URv2dfehleGXQggRxWFf340jF1YJIUQUh7104wghRL02v6gq4gI+CPrlBK0QQjQQXS17reHvmfDp/fUtexl6KYQQ0Rb2SoEzFaqL61v2Hr+nnSslhBDtL7rCHiAuHWpKpBtHCCEaiL6wd6VBdXH90EsZjSOEENEY9nHpUFOM3WwHZJy9EEJANIa9Kx2qS7CYLFhNVunGEUIIoizstdYs/tEDnnLwe41bE0o3jhBCRFfYK6VYV2Y1ntSU4DQ7pRtHCCGIsrAHCDjTjF9qikl1plLsLm7fCgkhRAcQdWGPKxT21cV0i+tGQXVB+9ZHCCE6gKgLe0tChvFLTQnd47qzt2pv+1ZICCE6gKgLe0diFwB0dRHd47pT6auk0lvZzrUSQoj2FXVhH5eSQVArfBVG2APsrZbWvRAitkVd2KcnuNhPPJ7yQrrFdQOQfnshRMyLwrC3U6oT8VVJy14IIeocNeyVUkOUUgMaPE9WSr2olFqjlHpUKWWPbBWbJyPeTikJUF1MujMdi7JIy14IEfOa0rJ/BBjc4PnDwDjgI+CXwN1hr1UrZCTYKdGJmNwlmE1musZ1lbAXQsS8poT98cAyAKWUDZgCTNda3xr6/eLIVa/5UuNs7CcBu6cUgO5x3SmokrAXQsS2poS9S2tdEfp9OBAAPgfQWq8Gukamai1jNilqLCnY/RUQDBhhLy17IUSMa0rYlyqlskK/jwZWaa01gFIqDiP8j0gp5VBKfaOU+l4ptV4p9ZeWV/nofI5UTGhw76dbXDcKawrxB/2RLFIIITq0poT9AmCuUmom8L/Amw3eGwlsb8I6PMB4rfUwjKODs5VSo5tZ1ybTDaZM6B7fnYAOyBw5QoiY1pSwvxPYAvwOWAI83eC9CcAbR1uBNlSFnlpDD928qjadKa5uyoTi+uGX0pUjhIhllqMtoLV2A789zHt3N7UgpZQZyAX6AU9orVc2ssx1wHUAvXr1auqqf8aaaIS9ri6me4+hABRUFTCiy4gWr1MIITqzFl1UpZQ6XSl1s1Iqp6mf0VoHtNbDgSxglFLq+EaWeUZrnaO1zsnIyGhJ1QBwJhvnjGvL98lVtEIIQdMuqnpWKXVtg+fXAh8DdwErlFIXNKdArXUZ8AlwdrNq2gzxKUbY1+wvJM4aR6ItUcJeCBHTmtKyr7uAqs5dwO1a63RgFnDr0VaglMpQSiWHfncCE4FNza5tE6UnxVOuXfgqCgFjrL1MmSCEiGVNCfsMrfV2AKVUXyATmB167wVgwOE+2EB34BOl1A/At8CHWuslLahvk9RdRRuoKjIKl7H2QogYd9QTtIBHKWXXWnuAHGCz1rpugngfcNS5cbTWPwBtdnY0Pd7ONhLJdJcA0C2uG7mFuW1VvBBCdDhNadmvAn6vlHIAVwAfNnivL1AUiYq1RrLTyn4SsdSGpkyI706lt5Iqb9VRPimEENGpKWH/R+B2oBrjIqoHG7x3CbAiAvVqFZNJUW1JxuE1wj4zLhOQETlCiNh11LDXWq8BegMnAsdprfMavP0mcFtEatZKXnsKLn85aC3DL4UQMa9J4+y11tVa6+8An1Kqe90c9lrrzVrrPRGtYQsFHGlYCEBtmdzERAgR85oU9kqp45VSHwCVQD5QqZT6QCmVHdHatYYr3fhZXSI3MRFCxLymXFQ1CPgKY+TOTIwbllwPmIEvQu93OJYEI+yDVUX1NzHJq8w7yqeEECI6NaVl/1dgrtZ6vNb6Ba31+1rr57XWE4D/AH+LbBVbxpbYBYCasn0AnJR5Est2LmNb+bb2rJYQQrSLpoT9acA9h3nv3tD7HU5caMqE6v1GP/2Nw2/EaXHyj5X/IDQdvxBCxIwm3akKKDnMeyWAI3zVCZ+ENOOkbG25MWVCmjONG0bcwNcFX7Ns17L2rJoQQrS5poT9dg7feh8L7AxfdcInLTmJam3HX3ngmq9fD/g1/VP688C3D+D2u9uxdkII0baaEvYvAHOUUqc0fFEpNQZ4PvTocDIS7Pyoe9A9712oNLpyLCYLfxz1RwqqC3hyzZPtXEMhhGg7TQn7hzCmJP5MKbVTKfWVUmon8BnwBTA/khVsqUSHhbuCM7H4q+C1GeD3ApDTLYeL+1/Mi+tf5JHvHpH+eyFETGjKFbRaaz0Do8vmZWBd6OfpwDUY4+47HKUUvrRB/M30O8j7Gj64s/69P43+E1OOm8Jza5/jLyv+QiB41HumCyFEp9aUWS8B0Fp/gdGSrxe6klaFu1Lh8u9LhnHpM26Ot13AJd88A92yYeR0zCYz/2/0/yPFnsKza59lX80+/jT6T2TGZ7Z3lYUQIiJadFvCQ3TYfpDjeyTx/JUncrf7V6y2jkC/9Xv45lnAaPnPGjmLO39xJ6v2ruL8Recz+/vZeAKedq61EEKEXzjCvkMb1SeVJ6aNYlr1zayyjYJ3b4Xl90Oor37qwKm8dcFbjM0ayxNrnmDywsks3rpYunaEEFFFHe0EpVLqj0d42wL8WWttDmutgJycHL1q1aqwre/9dQXcPH8Vj8XNYaJ3GeRcBWffDxZb/TIrC1byYO6DbCjZQN+kvtw44kbO6HUGSnXYniohhKinlMrVWuc0+l4Twv6ToxWgtR7XwrodVrjDHuDTLUVcP/db7nK8zmW+BZA1Ci75DyQe6KvXWvPRro94bPVjbC/fzsguI7ntxNsYkj4krHURQohwa1XYt5dIhD1A7s5SrpzzLZPMX/NXNRuzPQ6mzIE+px60nD/oZ+HWhTy++nFKa0uZ1HcS12ZfS5+kPmGvkxBChIOE/SE2763kmpe+Jb5iG68lP0FC9U745b+Mrp1DVHmreHbts8zbOA9vwMsZx5zB1cdfLS19IUSHI2HfiNJqL7+bl8v6bfks7vo8fctXwOjfwZl/A9PPT0GUuEuYt3Eer2x6hUpfJUPThzLluCmc3ftsXFZXxOophBBNJWF/GL5AkP+3eD2vfbOdV3svIWfvq9D/LPjVi2BrPMCrvFUs/mkxr29+nZ/KfyLOGsfZvc/mwv4Xkp2eLSdzhRDtRsL+CLTW3LVoHfNW7uL5wd8zYfs/IetEuPQVcKUe8XNritbwxpY3+HDnh7j9bo5NOpapA6cy+djJ0toXQrQ5CfujCAY1t7/5A6/n5jP7hHzO3nQXpPWDaQsgsftRP1/lrWLpjqW8vuV11pesJ8GWwJTjpnDZwMvqb3YuhBCRJmHfBIGg5n9fW8PiNXt4eXwtp6yaZbTspy+CtGObtI661v7cDXNZtmsZCsXEYyZy+aDLGd5leETrL4QQEvZN5PUHmfb8StbsKmPxhQ4GLbsKzFajhd/t+Gata0/VHuZvms+bW96k0lfJ6O6juSXnFgamDoxQ7YUQsU7Cvhn2V3u54Mkvqar1s2RqOt3fugx81XD5G9BzVLPXV+Or4Y0tb/DM2meo8FQw6dhJ/H7E76V7RwgRdkcK+6ifG6e5UuJsPD/jRHyBIFcuqcQ9/R1wpcFLF8DOr5q9PpfVxRVDruDdi97lyuOv5P3t7zNp4SSe+v4puVuWEKLNtEnYK6V6KqU+UUptUEqtV0rd1BbltlS/LvE8cflIthRW8qdPK+E37xtTKsz7FeR906J1JtoS+d8T/pe3LjQmXXtyzZNMXjSZZTvlfrhCiMhrq5a9H7hFaz0YGA3coJQa3EZlt8ip/TP4/bh+vJGbz5tbfDDjbYjvAnMvgvzcFq+3R3wP/n36v5lz1hySbEncvPxmbll+CyXuw93TXQghWq9Nwl5rXaC1/i70eyWwEejRFmW3xqwJ/RnVJ5W7Fq1ja228EfiuVJh7Iez+rlXrzumWw/zz5nPTyJv4JO8TLlh8AUu2LZHbJAohIqLN++yVUr2BEcDKRt67Tim1Sim1qqioqK2r9jMWs4lHp47AaTNzw7zVuJ3d4col4Ewy+vB3t7yFD2A1Wblm6DW8MekNeiX24g+f/4Eblt3A3uq94dkAIYQIadOwV0rFA28CN2utKw59X2v9jNY6R2udk5GR0ZZVO6xuSQ4e+vVwNu+r5K/vbIDkXnDlO+BMhpcubHXgA/RN7stLZ7/E7Sfezqp9xl2zXt30KkEdbP0GCCEEbRj2SikrRtDP01ovaKtyw+G04zL47Wl9+e/KXbzzQ8HPAz/v21aXYTaZmTZ4GgsmL2BYxjD+tvJvXPvBteRXdsj7uQshOpm2Go2jgOeBjVrrB9uizHC79cwBDO+ZzB1v/kBeaQ0k9zQC35UKcy+AHV+GpZyshCyenvg0d590N+tL1nPRWxcxf9N8aeULIVqlrVr2Y4DpwHil1JrQ49w2KjssrGYTj106AhTcOH81Xn/QCPzfvGcMy3z5YvjpqDf1ahKlFBcfdzGLzl/EyK4j+fvKv3PdB9exp2pPWNYvhIg9bTUa5wuttdJaZ2uth4ce77ZF2eHUM9XFAxdn831eGX9/d6PxYmJ3uPJdY/6c//4aNr8XtvK6xXXjqQlPcfdJd7O2eC0XvXURb255U0bsCCGaTa6gbaZzhnbnmlP68OJXO1i4OtSfHp9hDMvsOgRenQZr3whbeXWt/AXnL2Bw2mDuXnE3135wLXkVeWErQwgR/STsW+D2cwYyqk8qf1iwlo0FoUFFrlSY8Rb0HA1vXgO5L4a1zB7xPXjuzOf40+g/1fflz1k3B3/QH9ZyhBDRScK+BaxmE49fNoJEh5WZL+dSXuMz3rAnwOWvQ78z4O2b4PMHIYxdLiZl4pIBl7Do/EWclHkSD+Y+yGXvXMam0k1hK0MIEZ0k7FuoS4KDJy8fyZ4yN7/7by6+QGi0jM0FU/8Lx0+BZX+Bd26BYCCsZXeN68oj4x7h36f9m8KaQqYumcoj3z2CN+ANazlCiOghYd8KOb1T+fuFQ/lyawl/fmv9gROnFhtc9CyMuQlWPW/043urw1q2Uooze5/J4gsWM+nYSTy39jmmvjNVWvlCiEZJ2LfSr3J61l9wNefLHQfeMJlg4j1wzj+NETrPToDC8Adxkj2Jv475K09MeIKy2jIufedSnvnhGenLF0IcRMI+DG4/ayBnDu7K397ZwMeb9h385i+ug2lvQnURPDsO1syPSB3GZo1lweQFTOw1kcdWP8bl717Olv1bIlKWEKLzkbAPA5NJ8fDU4QzOTOTG/65m/Z7ygxfoNwFmfgE9ToBFM2HxjeCrDXs9kh3JPHDaA/z7tH+zt3ovv17ya2Z/Pxtf0Bf2soQQnYuEfZi4bBaen3EiyU4rV734LQXlh9yFKrE7XLEYxv4frJ4Lc86GssiMlT+z95ksOn8RE4+ZyBNrnuDSJZeyoWRDRMoSQnQOEvZh1DXRwQu/OZFqT4DfzPmWKs8h/eYmM4y/C6bOh5Kf4Omx8OOHEalLiiOFB8Y+wCPjHqG0tpTL3rmMR757BE/AE5HyhBAdm4R9mA3slsgTl4/kx8Iqrn8515hD52cLnQvXfgIJ3WDeFKNbp7b858uFwfhe41l4/kImHzuZ59Y+x5S3pvDdvtbdeEUI0flI2EfAacdl8I+LhvL5j8Xc8eYPjc9lk97PCPwxN8OaefDkybA1MvejTbIncc+Ye3h64tP4gj5mvD+De7++lypvVUTKE0J0PBL2EXJJTk9umXgcC1bv5p9LNze+kNUBE/8CV39oXIz18kWw+AZwl0WkTidnnsyCyQuYNmgar25+lfMXnc8HOz6QidWEiAES9hF04/h+XPaLXjy5/Cfmrthx+AWzcuC3n8Mp/2MMzXxyNGxcEtapFuq4rC5uH3U7886dR6ozlVs+vYUblt1AXqVMrCZENFMdtVWXk5OjV61a1d7VaLVAUPPbubl8vGkfs6edwJlDuh35A7u/M/rwC9dD/7PgnPsgtW9E6uYP+pm/aT6Pr34cf9DPjCEzuGboNbisroiUJ4SILKVUrtY6p9H3JOwjz+0NMPXZr9m8t4L5145mRK+UI38g4IOVT8Pyfxi/n/I/xsPqiEj9CmsKeSj3IZZsW0JXV1duPuFmzu1zLiYlB35CdCYS9h1AcZWHi578iiqPnwXXn0zv9Lijf6iiAD64E9a9abTuz/2XcYFWhKwuXM0/Vv6DjaUbGZw2mFtzbuXEbidGrDwhRHgdKeyl6dZG0uPt/OeqUWitueKFbyisaMIVtIndYcoLMH0RoIwTuK/NgNLtEanjiC4jeOW8V/j7KX+nxF3CVUuv4qaPb2JXxa6IlCeEaDvSsm9ja/LKuOzZr+mV6uLV355EktPatA/6auHLR+DLh42unVHXGlfjulIjUs9afy1zN8zlubXP4Q16uXzg5Vw37DoSbYkRKU8I0XrSjdPBfP5jEVe9+C0jeqbw0tWjcFjNTf9wRQEs/zusfhls8XDyLBh9PdjjI1LXopoiHlv9GIu2LiLeFs/0wdOZNmgaCbaEiJQnhGg5CfsO6O3v9zDrldWMG9CF2dNOwGZpZo/avg3w8V9h87sQl2G08k+4Eiz2iNR3c+lmnljzBJ/kfUKCLYFpg6YxdeBUUh2RObIQQjSfhH0HNW/lTu5cuI5zju/GY5eOwGJuwSmUvG9g2T2w43NI6gmn3QbDLgVzE7uHmmlDyQae+v4pluctx262M/nYyVwx+Ap6J/WOSHlCiKaTsO/Anv9iO39dsoELhmfy70uGYzap5q9Ea9i23Gjp786FlD5wys1G6Eeopb+tbBsvbXiJt396G1/QxxnHnME1Q69hcNrgiJQnhDg6CfsO7olPtvLPpZu5JCeL+y7KxtSSwAcj9Le8b4zPL/ge4rvBSb8zunccSWGtc51idzHzNs7jlU2vUOWr4qTuJzF98HTG9Bgj4/SFaGMS9p3Agx9u4dFlP7Y+8OFAS/+Lh2D7p8aJ3OGXw+iZEbsat9JbyaubX+W/G/9LkbuI3om9mT54Ohf0uwCb2RaRMoUQB5Ow7wS01jz00Y/hC/w6e9bA108ZF2YF/dB/IuRcbfw0NWMUUBP5Aj6W7lzK3A1z2VCyga6urlw99Gou6n8RdnNkupSEEAYJ+06iYeBPOSGL+y/OblkffmMqCmDVC/Ddf6BqHyT1Mu6PO/KKiHTxaK1ZUbCC2d/PZnXhatKd6VzY70IuPu5iesT3CHt5QggJ+07n4Y+28PBHP3Jednce+vVwrC0ZpXM4AR9sWgLfPAs7vwRbghH4J1wJGceFr5wQrTUr965k7oa5fLH7C7TWnJR5Ehf2v5DxPcdLF48QYdTuYa+UegE4DyjUWh/flM/EctgDPPPZT/z93U2cMagLj182snkXXjXVntWw4klYv8Do4ulxgjGC5/iLI3JlbkFVAQu3LmTh1oXsrd5Lkj2JX/b5JVOOm0L/lP5hL0+IWNMRwn4sUAW8JGHfdHO/3smfFq1jdN9Unp6WQ5IrMmPnqdwHa18z5tIvXA9mGww41zipe+x4MFvCWlwgGGBlwUoWbl3Isl3L8AV9jOwykinHTWFCrwkyxbIQLdTuYR+qRG9giYR98yxavZv/e+N7eqa6mHPliRyT1oTZMltKa9j7gxH6a1+DmhJwpcGgSTD4Auh9atiDf3/tfhZvXczrW15nV+UuHGYHY7PGcnafszkt6zTp5hGiGTpN2CulrgOuA+jVq9cJO3fubJO6dXQrt5Xw25dzUcAzV+RwYu82mKLA74WtH8K6BbD5PfBVgzPVuFn6oMnQ57Swzq8f1EFy9+WydMdSPtz5IaW1pSTZkziv73lc2O9CBqQOCFtZQkSrThP2DUnL/mDbi6u56sVv2b3fzQNTsrlgRBuOaPG54ccPYePbxkVbngqwuqDv6cYQzmPHQ/IxoMIzcsgf9LOyYCWLti6q7+bpm9SXM3ufyVnHnEW/lH5hKUeIaCNhHyXKarz8dm4uK7eXMmt8P/5n4nGoMAVsk/m9sP0zI/R/XAplobnu47tBz1HQ+xQ47ixI6R2W4so95by3/T2W7lhK7r5cNJq+SX2ZeMxEzux9Jv2T+7f930CIDkrCPop4/UH+uHAtb+Tmc152dx6Yko3LFt5+9CbTGoo2w84vYNdKyPv6QPhnDILjzoR+E6HX6LBMzFZUU8RHuz7iw50fkrsvl6AO0iO+B2MyxzCmxxhGdRtFvC0yUz0L0Rm0e9grpeYDpwPpwD7gz1rr54/0GQn7w9NaM/vTbTywdBMDuiYwe9oJTbvNYVso+Qm2LIUt78HOFRD0GWP5+4yFY06GY06CbsNafaK32F3Mx7s+5vPdn/NNwTfU+GswKzND04cyOnM0YzLHkJ2RLfPziJjS7mHfEhL2R/fZliJmvbKaQFDz0CXDOWNw1/au0sE8lbDtU+NE77blsH+H8brVBd2HGeP6e4yErBON6Zlb2B3jC/hYU7SGFXtWsLJgJetK1hHUQdIcaZze83TGZo2VVr+ICRL2USyvtIbr5+WybncFV5/Sh9vOHoDdEoELsMKhogB2fWXMwb/7O2NmzoDHeC++K/TIgW5Dodvx0PV446Svqfkt83JPOV/u/pKP8z7mi91fUO2rxqIsZGdkMyR9CEm2JJLsSWQlZDGq2ygZ3imihoR9lKv1BfjHuxv5z4qdHN8jkUenjqBvRidoxQZ8sG895H8L+atg9yqjG4jQv0mLE9L7QfoA6DoYumUbO4GEbk0+CmjY6v9qz1dsK9+G2++uf99lcTE2ayzjeo5jdOZoufOW6NQk7GPEB+v3ctubP+D1B7n97IFMH31MeGbObEveaijcCPvWQdEWKN5inAQu33VgGVcadB0CXYcaO4EugyBjINiadt7CF/BR7i1nY8lGlu1axid5n1BaWwrAoNRBjM4czak9TmV4l+FYTRG6almICJCwjyEF5W5uf3Mtn20p4sTeKdx/cXbnaOUfjbvMOArYt8547F1n7BTqW+nKGO7ZJRT+Kb0hoTskdDXOBziTD7vqQDDA+pL1fF3wNV8XfM3qwtX4g37irfGM7j6akV1HMqLLCAakDpDwFx2ahH2M0Vrz5ne7ueft9dT6g8wc25eZpx/bfkM0IyUYME767lsPhRuM8C/cCCVbQQcOXjYuA9L6GbdsTO4FyT0hMRNc6RCXbrwfGh5a7avm64Kv+Tz/c1bsWcGe6j0AOMwOBqQOYFDqIAanDWZA6gD6JfeTPn/RYUjYx6jCilr+9s5G3vp+D92THPzh3EFMyu4e/Rch+T1QWQCVe42fZbuMHUDxVmPnUFlA/XmBOiYLpB4LXQYaXULJxxg7haQe7A16WVOxje+L17KxdCObSjdR7asGwKIsHJt8LMelHFf/6JfSjwxnRvT/nUWHI2Ef477ZXsrdb61nQ0EFQ3sk8X9nDeDU/umxG0Z+L1TsNkK/uhiqi6A83zg3ULghNES0kf8XjiRI608wfQB5SV3ZpPxs8pexqbaILdUFFHpK6xdNsCXQP7k//ZL70S+lH/2T+9MrsRfpznQZ+y8iRsJeEAhqFnyXz8Mf/cjuMje/6JPKrAn9OfnYtNgN/cPxe6Ei3zgiKN8NteXGfEDVRcYOoWgzVBf+7GNlJhNbbFa22u385Epiq83Kj6YglQTrl7EoE13tKfSKz+LY5P70Tx9M35T+9EnqQ5I9MjeFF7FDwl7U8/gDvPptHo9/vJXCSg9DeyRx/enHctaQbuG7BWIsqC2HmlLjZ22ZcQFZbYXxvLrQuEdA1V50dRH7asvZ6q9gt/Kz12Jmj8XCTquFn6xWahtcR5CmTRxjdpFlS6Knswu94jLpndSH3in9cSX1hMQeYJO5/sXhSdiLn6n1BVi4ejfPfLaN7cXV9EmP47dj+3LhyB4d96Kszs5TaVxYVrEbqosJ1BSzuyKP7dX5bK/ZxzZvGTuDbvJVgMJDbkWZ5g+QFgiQhpkMk51MZaEHNnpYXPRydqNLYk9UfIaxsA4dSTiSjWGqrjRjNJIj2fhpiw/bDKWiY5GwF4cVCGqWrt/Lk8u3sm53BV0T7Vz+i2O4JKcn3ZLCN1+9aJ5a9352Fa1lR8lmdpT/xJ7K3ZTUFlPiqaAw4KYQ30FnFZxBTQ+/j+7+AF39froFAvTw+cny+8ny+UkNBqnffZisxm0nnanGiWm0MamdxW5cq2CLA3vigWWcyWBPMB6OJGMEkysNnClgkZFIHYmEvTgqrTVfbC3m6U+38cXWYkwKxg3owq9yejJ+YBdsFjmp2JH4Aj72Vu8lryqPvIo8dlbsJK9iB/tqithXs49Sz/6DlrcqM10s8XQ1O8nATIaGdH+ALpjJMNnogpXEQACXz43DW42ptgLc+41zFUdiizeOGGxxoaMFZQxhdSQZD1ucMTrK7zGGw9oTjZ1E/ZFG6Hery1jW4gBT6MhSmYzXHMlGOS2YOiPWSNiLZtlZUs2r3+bxem4+RZUekl1WJmVnMnl4Jif0Sul8V+XGoFp/LXuq9pBflU9eZR6FNYXsq9nH3uq9FLuLKaoposZfc9jPJ1gTSLInkWJPJtHqItHsIMlkJwEzCTpIfMBPqj9AVgCyfB7i/B7j6ABtnOD2hM5feKuNALfYjfCuO8fhLqPREU+Ho0zGUUZ8F+O6CFu8ca9ks804OjGZjJ9mG1idxs7DbDN2HCbLgYfZatTHnmDseKwOCAYh6De6v0xmUGZjfcFg6HoNBfEZkJAZ1ruzRYKEvWgRfyDIF1uLWfDdbpau34vHHyQ93s6ZQ7oycVBXRvdNw2mT/v3OqsZXQ5G7iMKaQopqiqjyVVHjq6HaX02lt5L9tfsp85RR7imnwltBhbeCSm8lQR382bqS7clkuDLo4upCuiOdZHsyyY5kkuxJJNoSSbQlkuJIoUd8DxJsCUaQekJHD7Vlxt3QvDXgq6G+W0kHjZ1F3Q6ibphsVaGxfMBrTKQXDIQefuM1n/vABHvh5kw5sKOx2I0y/R5jnieLzZjO2xYHjkRjZ+JIAnu8sfOp2wlZXQd2Gt5qY7uD/tDOy2KsI/tXLaqehL1otcpaH8s3F/H++r18sqmQGm8Au8XEL/qmMbZ/OmP6pTOga4K0+qOc1hq3302Vr4oidxF5lXnkV+azp2oPRe4iimqKKHIXUe4px3OYwE2xp5AZn4nL6sJmsmEz20iwJZBgSyDeGl//M94Wb+w07MZOw2KyEAgGCOogVrMVp8WJw+zAbGqkwREMGMFftxMIBox7KwR84K81TpZ7Ko0dQ92RgTIZy+mg8VCh17SGqn1Quce4UM/nNtbh9xiftdiNIwa/NxTeDUZm1R3dNGfnE98Vbt3Sou9Hwl6EVa0vwDfbS/l0SxHLNxfyU5FxNWlanI3RfdM44ZgUTjgmhcGZiVjN0s8aq9x+94GjAk8F+z37ya/MZ1flLgqqCqgN1OINeKkN1FLtNY4mqnxV6OZ072DMXJpkN6atTnOmkRmXSWZ8Jl1cXUi0JZJkT8JlcWFSJszKXP9TKYVJmVCo+t/tZjs2sw272R7ei9+CAeOoxVcb+ukGtHGUYIszuo8CoSMTHYSklt1jWsJeRNSeMjdf/VTCl1uL+WZ7KbvLjMnJ7BYTx/dIYlhWMsN6JjEkM4k+6XEynl8cVlAHqfHVUOWrosJbQbmnnDJPGWWeMoLBICaTEdS+gA+3343b76bSV0m5p5xyTzlF7iIKqgrYf8gJ6uZSKJLsSaQ6Ukl1pNYfXSTbk3FZXcZRhcWBy+LCZXHhtDoxqwNHGA6zg3hbPPHWeFxW1+GPQMJMwl60qYJyN7k79/PdzjJ+yC9j3Z5yan1GP6/LZmZw90SGZCYyODORwd2T6JsRR5w9yiZpE+2qxldDibuEcm85FZ4Kavw1BLTRBRTQAbTW9T81uv65L+jDE/Dg9rvZX7uf0tpSYz2hnU65txx/0N+iOtnNdhwWBw6zo/6n0+LEaXFibXCP5gRbAvedel+LyjhS2Mv/MBF23ZOcnJft5LzsTMA40btlXxXr95Szfk8F63aX80ZuPtUrDsxM2S3RQd+MOHqmuOiZ6iQrxUVWivGzS4JdzgWIZnFZXbisLnrSM+zr9gV81Phr6o8savw1uH3u+hPXGo0n4DG6pbxVB5bxu6n111IbqK3/6fa7qfZX4/P46qctaenO5Ggk7EXEWcwmoxWfmUjdGINgULOztIaNBRVsK6piW3E124urWbapkOKqg09m2cwmuiU5yEx2kJnkpHuyg+5JTjKTHSS7bCQ6rCQ6LCS5rHL1r4g4q9lKkjmp081lJGEv2oXJpOiTHkef9J/fXcrtDbC7rIb8/W7y97vJ219DQVkte8rcfL2thH2VHgLBxrsfXTYzKS4bKXFWUuPspMXZSA096n5PibOR4rKR7LISb7fgsMoOQkQ/CXvR4ThtZvp1SaBfl4RG3w8ENUWVHvaUuymv8VFR66Oi1k+F20dptZf9NV72V3sprfayraiK0movNd5Ao+sC48gh3mHBZTMTZ7PgsJmxm01YLQqr2YTdYsJuMWO3GMsl2C3E2Y3lHVbjYbOYsFlM2M0m7FZjeZvFhMNixmEzGcuYTZhNCotJyUyjos1J2ItOx2xSdEtyNGvunlpfgJJqL6VVoZ1BjZdyt4/KWj8VtT6qav24vQFqvAFqfAF8/iAeX5AKtx+vP4g3EMTtDVDt8VPl9dPacQ1mk6oPfrNSKGW8ZlIKk0lhUmAxmXBYjR2F3WLCajZ2KGaTIqiNMe9BrY3rj7QxW4HNYuycbBYzVpPCYlZYzKGdTmhdigPXrtbVwRJat9NqLGc56ByJUT8FKKWoeyeoNf6gxhcw+qrrdopWswmTon6HVrdcIBjEFzCW9wcOvBbU4LCacFotxNnNuGxmXDZjZ2o1m0IPYwepFJiUCp1YNZiUsQ3W0M60OXTo7xcMrU9rQidsG1s29NdQdMqdtoS9iAkOq5keyU56JDtbva5gUFPjC+D2Bqj1GQ9PaIfg9RsPjz9Y/3rdMr6Axh8I4gtqgkEj7PwBI+yCoeAOBHV9kHsDxg6nbj2+QJBqj59AUIfGhR8IX6WMMKr2+PGEyq8LVV/AeO72BQ7b/RXNDt1RKUX93zkc6zaHdtBmpUI7bEI77APfkSm0XMOdg1JgMRmfVUBQG/VKcVlZfOMpra/cISTshWgmk0kRb7cQ3wmHi/oDQTQ0aJ2DP9Ti9vgDeHwH7xQatnQPbe0qhXHkEGpNe0I7Ol9Ah446jM9aTCbMJjCbjCMGm8VU3xKvO4qp9Rk7MrfPOLpye/3UeAP4AkG8AY3PHyQYqkBQ69CFUNQ/N3akun4ZCB29NNJi1xwIaIVxZHBgh3DgiKRho/3A8UxoxxzaWdftoAOh1wLBAzturSFQd+QQWqbh39AY7mmsB01ohwFJzsjc1L7z/WsVQrSYpZErmm31kx9HJmRExyDXsgshRAyQsBdCiBjQZmGvlDpbKbVZKbVVKXVHW5UrhBCijcJeKWUGngDOAQYDlyqlBrdF2UIIIdquZT8K2Kq13qa19gKvAOe3UdlCCBHz2irsewB5DZ7nh147iFLqOqXUKqXUqqKiojaqmhBCRL8OdYJWa/2M1jpHa52TkZHR3tURQoio0VZhvxsOmms0K/SaEEKINtAmNy9RSlmALcAEjJD/FrhMa73+CJ8pAna2sMh0oLiFn+2sYnGbITa3Oxa3GWJzu5u7zcdorRvtFmmTK2i11n6l1I3AUsAMvHCkoA99psX9OEqpVYe7W0u0isVthtjc7ljcZojN7Q7nNrfZdAla63eBd9uqPCGEEAd0qBO0QgghIiNaw/6Z9q5AO4jFbYbY3O5Y3GaIze0O2za3yQlaIYQQ7StaW/ZCCCEakLAXQogYEFVhHyszayqleiqlPlFKbVBKrVdK3RR6PVUp9aFS6sfQz5T2rmu4KaXMSqnVSqkloed9lFIrQ9/5q0opW3vXMdyUUslKqTeUUpuUUhuVUidF+3etlPqf0L/tdUqp+UopRzR+10qpF5RShUqpdQ1ea/S7VYZHQ9v/g1JqZHPKipqwj7GZNf3ALVrrwcBo4IbQtt4BLNNa9weWhZ5Hm5uAjQ2e3w88pLXuB+wHrm6XWkXWI8D7WuuBwDCM7Y/a71op1QOYBeRorY/HuDZnKtH5Xb8InH3Ia4f7bs8B+oce1wFPNaegqAl7YmhmTa11gdb6u9DvlRj/+XtgbO9/Qov9B7igXSoYIUqpLOCXwHOh5woYD7wRWiQatzkJGAs8D6C19mqty4jy7xrjGiBn6Op7F1BAFH7XWuvPgNJDXj7cd3s+8JI2fA0kK6W6N7WsaAr7Js2sGW2UUr2BEcBKoKvWuiD01l6ga3vVK0IeBm4DgqHnaUCZ1tofeh6N33kfoAiYE+q+ek4pFUcUf9da693Av4BdGCFfDuQS/d91ncN9t63KuGgK+5ijlIoH3gRu1lpXNHxPG2Nqo2ZcrVLqPKBQa53b3nVpYxZgJPCU1noEUM0hXTZR+F2nYLRi+wCZQBw/7+qICeH8bqMp7GNqZk2llBUj6OdprReEXt5Xd1gX+lnYXvWLgDHAZKXUDowuuvEYfdnJoUN9iM7vPB/I11qvDD1/AyP8o/m7PgPYrrUu0lr7gAUY33+0f9d1DvfdtirjoinsvwX6h87Y2zBO6LzVznWKiFBf9fPARq31gw3eeguYEfp9BrC4resWKVrrP2its7TWvTG+24+11pcDnwBTQotF1TYDaK33AnlKqQGhlyYAG4ji7xqj+2a0UsoV+rdet81R/V03cLjv9i3gitConNFAeYPunqPTWkfNAzgXYyrln4A727s+EdzOUzAO7X4A1oQe52L0YS8DfgQ+AlLbu64R2v7TgSWh3/sC3wBbgdcBe3vXLwLbOxxYFfq+FwEp0f5dA38BNgHrgLmAPRq/a2A+xnkJH8ZR3NWH+24BhTHi8CdgLcZopSaXJdMlCCFEDIimbhwhhBCHIWEvhBAxQMJeCCFigIS9EELEAAl7IYSIARL2QggRAyTsRdRQSi1XSnmUUlWHPIYqpV5USvlCzytC00PPPOTzJyml3ldKlSulqpVSuUqpGY2U010p9ZRSamdouV1KqdeUUieE3r9SKbW1kc8d9LpSKkMp9bxSaneoXgVKqfeaM7mVEE0lYS+izV+11vGHPNaG3vuP1joeSAb+CjyllBoPoJQ6E+MKzRUYF+9kYEyp+7BS6i91K1dKZWJcrd0T40K2RIwptd8GLmpmXV8GEoARoXoNw7jIRi5+EWFnOfoiQkQXrXUQmK+UegxjxtCPMa5MnK+1/kuDRV9TSrmA55RSc7TWO4B7MCYju1Ab87YAVGFc5dlcJwO/1loXhupVCLzUkm0S4mikZS9ijjLudnUZkAqsUkodB/TDaGkf6r8Yl6lPDD0/F3i9QdC3xmfAP5VS1ymlRoRuwCNEREjYi2hzp1KqrOGjwXvTQ88LgVuBq7XWn2J02UAjMwhq40Y4xUCX0EsZjS3XiD6N1OPJQ5b5NcYO5jfAV0CJUuphpZSjKRsqRHNI2Itoc6/WOrnho8F7c0OvpWmtR2qt54ReLwr9/NmNIEIzqKY3WKaoseUasb2Revyu4QJa6yqt9T+01icBScAVGMH/xyZuqxBNJmEvhDG74Dbgskbem4pxwvTD0PN3gSmh+wmEjTZuN/gWxiyHw8O5biFAwl4ItDH1643ANKXUXUqpVKWUUyk1BeNWiPdrrbeHFv8zEA+8oZQaFOr/j1NKXaqU+ltzylVKPaiUOlEp5VBKmZRSpwPjgM/DtW1C1JGwF9HmT42Msz/vaB/SWr+HcZOMscAOjH76O4FbtdZ3NlhuN3AixhzkHwAVGDd8vwDjzmHNYQLmYJxD2I/Rp/8v4N/NXI8QRyXz2QshRAyQlr0QQsQACXshhIgBEvZCCBEDJOyFECIGSNgLIUQMkLAXQogYIGEvhBAxQMJeCCFiwP8HdfJJduNnmpQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist1 = load_history(\"cp_history_1_1.npy\")\n",
    "hist2 = load_history(\"cp_history_1_2.npy\")\n",
    "hist3 = load_history(\"cp_history_1_3.npy\")\n",
    "for x in ['loss']:\n",
    "    plt.plot(hist1[x],label=\"Historic 1\")\n",
    "    plt.plot(hist2[x],label=\"Historic 2\")\n",
    "    plt.plot(hist3[x],label=\"Historic 3\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"EPOCHS\",fontsize=13)\n",
    "plt.ylabel(\"LOSS\",fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Historic 1 el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.78 GiB for an array with shape (239318640,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Camil\\Documents\\Ingeniería de Sistemas - UCB\\I - 2022\\Sistemas Inteligentes\\Practicas\\Cuarta - MachineTranslation\\MachineTranslation\\PROYECTO MACHINE TRANSLATION\\Var_Camila_1.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/Var_Camila_1.ipynb#ch0000011?line=12'>13</a>\u001b[0m spa_tokenizer,spa_vocab_size,spa_max_sentence_length \u001b[39m=\u001b[39m prepare_tokenizer(dataset,\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/Var_Camila_1.ipynb#ch0000011?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/Var_Camila_1.ipynb#ch0000011?line=15'>16</a>\u001b[0m trainX, trainY \u001b[39m=\u001b[39m  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/Var_Camila_1.ipynb#ch0000011?line=16'>17</a>\u001b[0m testX, testY \u001b[39m=\u001b[39m preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/Var_Camila_1.ipynb#ch0000011?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(trainX\u001b[39m.\u001b[39mshape, trainY\u001b[39m.\u001b[39mshape, testX\u001b[39m.\u001b[39mshape, testY\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Camil\\Documents\\Ingeniería de Sistemas - UCB\\I - 2022\\Sistemas Inteligentes\\Practicas\\Cuarta - MachineTranslation\\MachineTranslation\\PROYECTO MACHINE TRANSLATION\\fit_model_.py:60\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(origin_tok, origin_max_sent_length, target_tok, target_max_sent_length, target_vocab_size, data, one_hot)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=57'>58</a>\u001b[0m dataY \u001b[39m=\u001b[39m encode_sequences(target_tok, target_max_sent_length, data[:, \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=58'>59</a>\u001b[0m \u001b[39mif\u001b[39;00m one_hot:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=59'>60</a>\u001b[0m     dataY \u001b[39m=\u001b[39m encode_output(dataY, target_vocab_size)\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=60'>61</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dataX,dataY\n",
      "File \u001b[1;32mc:\\Users\\Camil\\Documents\\Ingeniería de Sistemas - UCB\\I - 2022\\Sistemas Inteligentes\\Practicas\\Cuarta - MachineTranslation\\MachineTranslation\\PROYECTO MACHINE TRANSLATION\\fit_model_.py:39\u001b[0m, in \u001b[0;36mencode_output\u001b[1;34m(sequences, vocab_size)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m sequence \u001b[39min\u001b[39;00m sequences:\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=37'>38</a>\u001b[0m \tencoded \u001b[39m=\u001b[39m to_categorical(sequence, num_classes\u001b[39m=\u001b[39mvocab_size,dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=38'>39</a>\u001b[0m \tylist\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mappend(ylist,encoded)\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=39'>40</a>\u001b[0m y \u001b[39m=\u001b[39m array(ylist)\n\u001b[0;32m     <a href='file:///c%3A/Users/Camil/Documents/Ingenier%C3%ADa%20de%20Sistemas%20-%20UCB/I%20-%202022/Sistemas%20Inteligentes/Practicas/Cuarta%20-%20MachineTranslation/MachineTranslation/PROYECTO%20MACHINE%20TRANSLATION/fit_model_.py?line=40'>41</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mreshape(sequences\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], sequences\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], vocab_size)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SistemasInteligentes\\lib\\site-packages\\numpy\\lib\\function_base.py:5392\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Camil/anaconda3/envs/SistemasInteligentes/lib/site-packages/numpy/lib/function_base.py?line=5389'>5390</a>\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[0;32m   <a href='file:///c%3A/Users/Camil/anaconda3/envs/SistemasInteligentes/lib/site-packages/numpy/lib/function_base.py?line=5390'>5391</a>\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Camil/anaconda3/envs/SistemasInteligentes/lib/site-packages/numpy/lib/function_base.py?line=5391'>5392</a>\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.78 GiB for an array with shape (239318640,) and data type float64"
     ]
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "learning_rate = 0.001\n",
    "loss_func='categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_ohe_1_1.h5'\n",
    "history_save_file_name=\"cp_model_ohe_1_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=True)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=True)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model1_1_ohe = define_model_embedding(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units)\n",
    "create_model(model1_1_ohe,loss_func,learning_rate)\n",
    "plot_model(model1_1_ohe, to_file='model_images/cp_model_ohe_1_1_m.png', show_shapes=True)\n",
    "#train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model, model_save_file_name, history_save_file_name)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model1_1_ohe, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model1_1_ohe.history, 'loss_vs_epochs_images_100/cp_model_ohe_1_1_le.png', 'Model 1 var 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86c6e36d9615b03cb5d5dfe45ab1ac2294409e71722603a93c9776274395c3a8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
