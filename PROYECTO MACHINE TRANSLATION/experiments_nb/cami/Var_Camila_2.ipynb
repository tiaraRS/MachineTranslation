{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78847adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_model_ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c33bd",
   "metadata": {},
   "source": [
    "### Model 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88e500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_embed_model(src_vocab,tar_vocab,src_timesteps,tar_timesteps, n_units, g_units,function=\"softmax\"):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # Implement\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    e = Embedding(src_vocab, n_units, input_length = src_timesteps,mask_zero=True)\n",
    "    g = GRU(g_units)\n",
    "    t = TimeDistributed(Dense(tar_vocab, activation=function))\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(e)\n",
    "    model.add(g)\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "   \n",
    "    model.add(GRU(g_units, return_sequences=True))\n",
    "    model.add(t) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa0eb3",
   "metadata": {},
   "source": [
    "### Variante 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8f28e",
   "metadata": {},
   "source": [
    "### English â†’ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1deaf5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 5, 256)            581632    \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 128)               148224    \n",
      "                                                                 \n",
      " repeat_vector_5 (RepeatVect  (None, 8, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, 8, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 8, 4510)          581790    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,410,718\n",
      "Trainable params: 1,410,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.70828, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 18s - loss: 3.7715 - acc: 0.6323 - val_loss: 2.7083 - val_acc: 0.6413 - 18s/epoch - 143ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.70828 to 2.59524, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.5843 - acc: 0.6479 - val_loss: 2.5952 - val_acc: 0.6507 - 13s/epoch - 106ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 2.59524 to 2.54614, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.4867 - acc: 0.6523 - val_loss: 2.5461 - val_acc: 0.6556 - 13s/epoch - 101ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.54614 to 2.52392, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 2.4137 - acc: 0.6568 - val_loss: 2.5239 - val_acc: 0.6564 - 14s/epoch - 115ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.52392 to 2.51368, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 2.3619 - acc: 0.6590 - val_loss: 2.5137 - val_acc: 0.6603 - 14s/epoch - 109ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.51368 to 2.48452, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.3143 - acc: 0.6622 - val_loss: 2.4845 - val_acc: 0.6611 - 13s/epoch - 102ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.48452 to 2.46266, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.2607 - acc: 0.6640 - val_loss: 2.4627 - val_acc: 0.6638 - 13s/epoch - 105ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.46266 to 2.43161, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 12s - loss: 2.2083 - acc: 0.6671 - val_loss: 2.4316 - val_acc: 0.6658 - 12s/epoch - 100ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.43161 to 2.39822, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.1515 - acc: 0.6700 - val_loss: 2.3982 - val_acc: 0.6704 - 13s/epoch - 106ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.39822 to 2.36572, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 2.0949 - acc: 0.6743 - val_loss: 2.3657 - val_acc: 0.6734 - 14s/epoch - 111ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.36572 to 2.33641, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 2.0353 - acc: 0.6802 - val_loss: 2.3364 - val_acc: 0.6762 - 13s/epoch - 107ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.33641 to 2.30229, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.9735 - acc: 0.6856 - val_loss: 2.3023 - val_acc: 0.6813 - 13s/epoch - 105ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.30229 to 2.27315, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 15s - loss: 1.9098 - acc: 0.6908 - val_loss: 2.2732 - val_acc: 0.6857 - 15s/epoch - 118ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.27315 to 2.24331, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 1.8462 - acc: 0.6976 - val_loss: 2.2433 - val_acc: 0.6902 - 14s/epoch - 114ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.24331 to 2.21706, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 1.7851 - acc: 0.7036 - val_loss: 2.2171 - val_acc: 0.6917 - 14s/epoch - 111ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 2.21706 to 2.18859, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 1.7251 - acc: 0.7100 - val_loss: 2.1886 - val_acc: 0.6982 - 14s/epoch - 113ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 2.18859 to 2.16708, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.6637 - acc: 0.7152 - val_loss: 2.1671 - val_acc: 0.6997 - 13s/epoch - 106ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 2.16708 to 2.14460, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.6068 - acc: 0.7193 - val_loss: 2.1446 - val_acc: 0.7023 - 13s/epoch - 103ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 2.14460 to 2.12591, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.5490 - acc: 0.7243 - val_loss: 2.1259 - val_acc: 0.7049 - 13s/epoch - 101ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 2.12591 to 2.11144, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 1.4925 - acc: 0.7282 - val_loss: 2.1114 - val_acc: 0.7071 - 14s/epoch - 110ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 2.11144 to 2.09352, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.4383 - acc: 0.7331 - val_loss: 2.0935 - val_acc: 0.7082 - 13s/epoch - 106ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 2.09352 to 2.07888, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.3833 - acc: 0.7384 - val_loss: 2.0789 - val_acc: 0.7111 - 13s/epoch - 105ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 2.07888 to 2.06806, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.3297 - acc: 0.7437 - val_loss: 2.0681 - val_acc: 0.7109 - 13s/epoch - 105ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 2.06806 to 2.05649, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.2781 - acc: 0.7487 - val_loss: 2.0565 - val_acc: 0.7144 - 13s/epoch - 102ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 2.05649 to 2.03861, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.2257 - acc: 0.7550 - val_loss: 2.0386 - val_acc: 0.7156 - 13s/epoch - 103ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 2.03861 to 2.03034, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.1748 - acc: 0.7610 - val_loss: 2.0303 - val_acc: 0.7172 - 13s/epoch - 108ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 2.03034 to 2.02008, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.1253 - acc: 0.7671 - val_loss: 2.0201 - val_acc: 0.7190 - 13s/epoch - 107ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 2.02008 to 2.00946, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 1.0776 - acc: 0.7729 - val_loss: 2.0095 - val_acc: 0.7178 - 13s/epoch - 103ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 2.00946 to 2.00464, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 1.0315 - acc: 0.7797 - val_loss: 2.0046 - val_acc: 0.7226 - 14s/epoch - 108ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 2.00464 to 1.99622, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 0.9867 - acc: 0.7860 - val_loss: 1.9962 - val_acc: 0.7231 - 13s/epoch - 105ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 1.99622 to 1.99106, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 13s - loss: 0.9441 - acc: 0.7925 - val_loss: 1.9911 - val_acc: 0.7237 - 13s/epoch - 107ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 1.99106 to 1.98712, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 0.9037 - acc: 0.7983 - val_loss: 1.9871 - val_acc: 0.7241 - 14s/epoch - 111ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.98712\n",
      "125/125 - 14s - loss: 0.8650 - acc: 0.8045 - val_loss: 1.9903 - val_acc: 0.7239 - 14s/epoch - 109ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 1.98712 to 1.98402, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 0.8275 - acc: 0.8104 - val_loss: 1.9840 - val_acc: 0.7266 - 14s/epoch - 115ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss improved from 1.98402 to 1.97790, saving model to Models100\\cp_model_2_1.h5\n",
      "125/125 - 14s - loss: 0.7925 - acc: 0.8178 - val_loss: 1.9779 - val_acc: 0.7259 - 14s/epoch - 111ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.7574 - acc: 0.8217 - val_loss: 1.9799 - val_acc: 0.7281 - 13s/epoch - 106ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.7261 - acc: 0.8296 - val_loss: 1.9791 - val_acc: 0.7269 - 14s/epoch - 109ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.6955 - acc: 0.8334 - val_loss: 1.9831 - val_acc: 0.7259 - 13s/epoch - 108ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.6666 - acc: 0.8404 - val_loss: 1.9863 - val_acc: 0.7272 - 14s/epoch - 110ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.6390 - acc: 0.8442 - val_loss: 1.9853 - val_acc: 0.7284 - 13s/epoch - 108ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.6122 - acc: 0.8499 - val_loss: 1.9885 - val_acc: 0.7284 - 13s/epoch - 107ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.5882 - acc: 0.8545 - val_loss: 1.9903 - val_acc: 0.7256 - 14s/epoch - 108ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.5655 - acc: 0.8578 - val_loss: 1.9983 - val_acc: 0.7258 - 14s/epoch - 109ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.5434 - acc: 0.8625 - val_loss: 1.9973 - val_acc: 0.7275 - 14s/epoch - 109ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.5237 - acc: 0.8653 - val_loss: 2.0011 - val_acc: 0.7279 - 13s/epoch - 107ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.5052 - acc: 0.8688 - val_loss: 2.0075 - val_acc: 0.7252 - 14s/epoch - 112ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4849 - acc: 0.8714 - val_loss: 2.0138 - val_acc: 0.7262 - 14s/epoch - 111ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4676 - acc: 0.8745 - val_loss: 2.0190 - val_acc: 0.7307 - 14s/epoch - 109ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4512 - acc: 0.8780 - val_loss: 2.0198 - val_acc: 0.7289 - 14s/epoch - 109ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4346 - acc: 0.8813 - val_loss: 2.0227 - val_acc: 0.7259 - 14s/epoch - 113ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4220 - acc: 0.8832 - val_loss: 2.0285 - val_acc: 0.7271 - 14s/epoch - 112ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.4081 - acc: 0.8846 - val_loss: 2.0362 - val_acc: 0.7294 - 14s/epoch - 113ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.3950 - acc: 0.8871 - val_loss: 2.0344 - val_acc: 0.7265 - 14s/epoch - 115ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.3831 - acc: 0.8887 - val_loss: 2.0467 - val_acc: 0.7282 - 14s/epoch - 108ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3722 - acc: 0.8903 - val_loss: 2.0533 - val_acc: 0.7272 - 13s/epoch - 107ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3605 - acc: 0.8925 - val_loss: 2.0551 - val_acc: 0.7279 - 13s/epoch - 106ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3512 - acc: 0.8932 - val_loss: 2.0595 - val_acc: 0.7286 - 13s/epoch - 106ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3416 - acc: 0.8954 - val_loss: 2.0684 - val_acc: 0.7258 - 13s/epoch - 106ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3317 - acc: 0.8964 - val_loss: 2.0765 - val_acc: 0.7268 - 13s/epoch - 107ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3251 - acc: 0.8964 - val_loss: 2.0798 - val_acc: 0.7258 - 13s/epoch - 106ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3171 - acc: 0.8983 - val_loss: 2.0863 - val_acc: 0.7283 - 13s/epoch - 107ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3090 - acc: 0.8989 - val_loss: 2.0874 - val_acc: 0.7259 - 13s/epoch - 107ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.3019 - acc: 0.9001 - val_loss: 2.1004 - val_acc: 0.7277 - 13s/epoch - 107ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2956 - acc: 0.9010 - val_loss: 2.1037 - val_acc: 0.7274 - 13s/epoch - 105ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2892 - acc: 0.9022 - val_loss: 2.1077 - val_acc: 0.7256 - 13s/epoch - 106ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2834 - acc: 0.9019 - val_loss: 2.1182 - val_acc: 0.7256 - 13s/epoch - 106ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2770 - acc: 0.9026 - val_loss: 2.1208 - val_acc: 0.7249 - 13s/epoch - 106ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2705 - acc: 0.9034 - val_loss: 2.1275 - val_acc: 0.7286 - 13s/epoch - 107ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2659 - acc: 0.9042 - val_loss: 2.1327 - val_acc: 0.7262 - 13s/epoch - 106ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2609 - acc: 0.9053 - val_loss: 2.1408 - val_acc: 0.7259 - 13s/epoch - 105ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2564 - acc: 0.9045 - val_loss: 2.1476 - val_acc: 0.7270 - 13s/epoch - 107ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2531 - acc: 0.9061 - val_loss: 2.1510 - val_acc: 0.7261 - 13s/epoch - 107ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.2485 - acc: 0.9055 - val_loss: 2.1574 - val_acc: 0.7259 - 14s/epoch - 110ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2455 - acc: 0.9061 - val_loss: 2.1665 - val_acc: 0.7261 - 13s/epoch - 106ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2417 - acc: 0.9068 - val_loss: 2.1668 - val_acc: 0.7267 - 13s/epoch - 106ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2387 - acc: 0.9071 - val_loss: 2.1804 - val_acc: 0.7258 - 13s/epoch - 107ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2349 - acc: 0.9072 - val_loss: 2.1788 - val_acc: 0.7261 - 13s/epoch - 107ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2312 - acc: 0.9070 - val_loss: 2.1903 - val_acc: 0.7253 - 13s/epoch - 107ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2274 - acc: 0.9080 - val_loss: 2.1936 - val_acc: 0.7266 - 13s/epoch - 106ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2254 - acc: 0.9078 - val_loss: 2.2012 - val_acc: 0.7252 - 13s/epoch - 106ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2232 - acc: 0.9079 - val_loss: 2.2012 - val_acc: 0.7263 - 13s/epoch - 108ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.2205 - acc: 0.9086 - val_loss: 2.2060 - val_acc: 0.7247 - 14s/epoch - 109ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2193 - acc: 0.9083 - val_loss: 2.2158 - val_acc: 0.7272 - 13s/epoch - 108ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2157 - acc: 0.9082 - val_loss: 2.2158 - val_acc: 0.7267 - 13s/epoch - 106ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2148 - acc: 0.9081 - val_loss: 2.2193 - val_acc: 0.7238 - 13s/epoch - 106ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2133 - acc: 0.9086 - val_loss: 2.2283 - val_acc: 0.7260 - 13s/epoch - 108ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2121 - acc: 0.9077 - val_loss: 2.2257 - val_acc: 0.7253 - 13s/epoch - 107ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2124 - acc: 0.9084 - val_loss: 2.2336 - val_acc: 0.7238 - 13s/epoch - 105ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2094 - acc: 0.9085 - val_loss: 2.2484 - val_acc: 0.7256 - 13s/epoch - 106ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2072 - acc: 0.9087 - val_loss: 2.2530 - val_acc: 0.7254 - 13s/epoch - 107ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2048 - acc: 0.9092 - val_loss: 2.2574 - val_acc: 0.7245 - 13s/epoch - 106ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2027 - acc: 0.9086 - val_loss: 2.2607 - val_acc: 0.7228 - 13s/epoch - 106ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.2004 - acc: 0.9099 - val_loss: 2.2638 - val_acc: 0.7231 - 14s/epoch - 108ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.2000 - acc: 0.9093 - val_loss: 2.2680 - val_acc: 0.7258 - 13s/epoch - 105ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.1979 - acc: 0.9093 - val_loss: 2.2782 - val_acc: 0.7246 - 13s/epoch - 107ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.1948 - acc: 0.9100 - val_loss: 2.2809 - val_acc: 0.7261 - 13s/epoch - 106ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.1931 - acc: 0.9094 - val_loss: 2.2855 - val_acc: 0.7234 - 13s/epoch - 107ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.1932 - acc: 0.9090 - val_loss: 2.2872 - val_acc: 0.7258 - 14s/epoch - 110ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.97790\n",
      "125/125 - 14s - loss: 0.1927 - acc: 0.9088 - val_loss: 2.2910 - val_acc: 0.7253 - 14s/epoch - 109ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.97790\n",
      "125/125 - 13s - loss: 0.1933 - acc: 0.9087 - val_loss: 2.2961 - val_acc: 0.7248 - 13s/epoch - 105ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "g_units = 128\n",
    "learning_rate = 0.001\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_2_1.h5'\n",
    "history_save_file_name=\"cp_history_2_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model = define_embed_model(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,g_units, \"softmax\")\n",
    "create_model(model,loss_func,learning_rate)\n",
    "plot_model(model, to_file='model_images/cp_model_2_1_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model.history, 'loss_vs_epochs_images_100/cp_model_2_1_m.png', 'Model 2 var 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e1754",
   "metadata": {},
   "source": [
    "### Spanish â†’ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc9342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 2272 8 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 8, 256)            1154560   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               148224    \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 5, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 5, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 5, 2272)          293088    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,694,944\n",
      "Trainable params: 1,694,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.07414, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 30s - loss: 2.9289 - acc: 0.9199 - val_loss: 1.0741 - val_acc: 0.9197 - 30s/epoch - 236ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 1.07414 to 0.82066, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 13s - loss: 0.9407 - acc: 0.9221 - val_loss: 0.8207 - val_acc: 0.9199 - 13s/epoch - 106ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.82066 to 0.45689, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 13s - loss: 0.6264 - acc: 0.9338 - val_loss: 0.4569 - val_acc: 0.9344 - 13s/epoch - 101ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45689 to 0.33421, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.3709 - acc: 0.9368 - val_loss: 0.3342 - val_acc: 0.9344 - 11s/epoch - 91ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.33421 to 0.31343, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.3146 - acc: 0.9368 - val_loss: 0.3134 - val_acc: 0.9344 - 11s/epoch - 85ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.31343 to 0.30572, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.3030 - acc: 0.9367 - val_loss: 0.3057 - val_acc: 0.9343 - 11s/epoch - 84ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.30572 to 0.30089, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2943 - acc: 0.9368 - val_loss: 0.3009 - val_acc: 0.9342 - 11s/epoch - 87ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.30089 to 0.29556, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 10s - loss: 0.2871 - acc: 0.9369 - val_loss: 0.2956 - val_acc: 0.9337 - 10s/epoch - 82ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.29556 to 0.29161, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2806 - acc: 0.9377 - val_loss: 0.2916 - val_acc: 0.9357 - 11s/epoch - 84ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.29161 to 0.28929, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2752 - acc: 0.9388 - val_loss: 0.2893 - val_acc: 0.9359 - 11s/epoch - 87ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.28929 to 0.28650, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2690 - acc: 0.9393 - val_loss: 0.2865 - val_acc: 0.9358 - 11s/epoch - 87ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.28650 to 0.28330, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2638 - acc: 0.9397 - val_loss: 0.2833 - val_acc: 0.9357 - 11s/epoch - 87ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.28330 to 0.28080, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2599 - acc: 0.9397 - val_loss: 0.2808 - val_acc: 0.9365 - 11s/epoch - 89ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.28080 to 0.27757, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2573 - acc: 0.9400 - val_loss: 0.2776 - val_acc: 0.9362 - 11s/epoch - 85ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.27757 to 0.27598, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2553 - acc: 0.9403 - val_loss: 0.2760 - val_acc: 0.9364 - 11s/epoch - 88ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.27598 to 0.27542, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 10s - loss: 0.2531 - acc: 0.9405 - val_loss: 0.2754 - val_acc: 0.9375 - 10s/epoch - 84ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.27542 to 0.27364, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2512 - acc: 0.9409 - val_loss: 0.2736 - val_acc: 0.9375 - 11s/epoch - 86ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.27364 to 0.27133, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2497 - acc: 0.9412 - val_loss: 0.2713 - val_acc: 0.9375 - 11s/epoch - 87ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.27133 to 0.27041, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 10s - loss: 0.2478 - acc: 0.9413 - val_loss: 0.2704 - val_acc: 0.9376 - 10s/epoch - 84ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.27041\n",
      "125/125 - 11s - loss: 0.2461 - acc: 0.9414 - val_loss: 0.2708 - val_acc: 0.9383 - 11s/epoch - 86ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.27041 to 0.27038, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2447 - acc: 0.9416 - val_loss: 0.2704 - val_acc: 0.9381 - 11s/epoch - 85ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.27038 to 0.27034, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2435 - acc: 0.9417 - val_loss: 0.2703 - val_acc: 0.9381 - 11s/epoch - 90ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.27034 to 0.26874, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 12s - loss: 0.2423 - acc: 0.9418 - val_loss: 0.2687 - val_acc: 0.9380 - 12s/epoch - 93ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.26874 to 0.26871, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 12s - loss: 0.2414 - acc: 0.9421 - val_loss: 0.2687 - val_acc: 0.9380 - 12s/epoch - 93ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.26871 to 0.26866, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2408 - acc: 0.9421 - val_loss: 0.2687 - val_acc: 0.9384 - 11s/epoch - 88ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.26866 to 0.26780, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2394 - acc: 0.9426 - val_loss: 0.2678 - val_acc: 0.9382 - 11s/epoch - 90ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.26780 to 0.26753, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 12s - loss: 0.2386 - acc: 0.9426 - val_loss: 0.2675 - val_acc: 0.9382 - 12s/epoch - 93ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.26753 to 0.26664, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 11s - loss: 0.2379 - acc: 0.9428 - val_loss: 0.2666 - val_acc: 0.9379 - 11s/epoch - 86ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.26664\n",
      "125/125 - 10s - loss: 0.2371 - acc: 0.9427 - val_loss: 0.2668 - val_acc: 0.9382 - 10s/epoch - 84ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 0.26664 to 0.26643, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 10s - loss: 0.2362 - acc: 0.9431 - val_loss: 0.2664 - val_acc: 0.9384 - 10s/epoch - 84ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.26643\n",
      "125/125 - 10s - loss: 0.2358 - acc: 0.9431 - val_loss: 0.2671 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.26643\n",
      "125/125 - 10s - loss: 0.2349 - acc: 0.9432 - val_loss: 0.2668 - val_acc: 0.9386 - 10s/epoch - 83ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.26643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 11s - loss: 0.2341 - acc: 0.9436 - val_loss: 0.2675 - val_acc: 0.9384 - 11s/epoch - 84ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 0.26643 to 0.26642, saving model to Models100\\cp_model_ei_2_1.h5\n",
      "125/125 - 10s - loss: 0.2335 - acc: 0.9435 - val_loss: 0.2664 - val_acc: 0.9382 - 10s/epoch - 84ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2331 - acc: 0.9436 - val_loss: 0.2678 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2330 - acc: 0.9437 - val_loss: 0.2680 - val_acc: 0.9382 - 10s/epoch - 84ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2321 - acc: 0.9437 - val_loss: 0.2671 - val_acc: 0.9386 - 11s/epoch - 88ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2318 - acc: 0.9439 - val_loss: 0.2677 - val_acc: 0.9385 - 10s/epoch - 84ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2313 - acc: 0.9441 - val_loss: 0.2678 - val_acc: 0.9387 - 10s/epoch - 83ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2309 - acc: 0.9441 - val_loss: 0.2675 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2307 - acc: 0.9440 - val_loss: 0.2673 - val_acc: 0.9385 - 11s/epoch - 88ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2304 - acc: 0.9439 - val_loss: 0.2667 - val_acc: 0.9387 - 11s/epoch - 84ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2305 - acc: 0.9441 - val_loss: 0.2677 - val_acc: 0.9385 - 11s/epoch - 86ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2299 - acc: 0.9443 - val_loss: 0.2674 - val_acc: 0.9385 - 11s/epoch - 87ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2298 - acc: 0.9442 - val_loss: 0.2682 - val_acc: 0.9388 - 11s/epoch - 84ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2295 - acc: 0.9442 - val_loss: 0.2678 - val_acc: 0.9388 - 11s/epoch - 90ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2292 - acc: 0.9440 - val_loss: 0.2673 - val_acc: 0.9387 - 11s/epoch - 88ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2291 - acc: 0.9442 - val_loss: 0.2682 - val_acc: 0.9388 - 11s/epoch - 86ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.26642\n",
      "125/125 - 12s - loss: 0.2293 - acc: 0.9441 - val_loss: 0.2675 - val_acc: 0.9385 - 12s/epoch - 92ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2289 - acc: 0.9441 - val_loss: 0.2675 - val_acc: 0.9387 - 11s/epoch - 91ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2691 - val_acc: 0.9386 - 10s/epoch - 82ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2285 - acc: 0.9443 - val_loss: 0.2689 - val_acc: 0.9390 - 11s/epoch - 86ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2686 - val_acc: 0.9388 - 11s/epoch - 85ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2691 - val_acc: 0.9386 - 10s/epoch - 83ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2287 - acc: 0.9441 - val_loss: 0.2680 - val_acc: 0.9385 - 11s/epoch - 85ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2282 - acc: 0.9441 - val_loss: 0.2691 - val_acc: 0.9386 - 11s/epoch - 84ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2282 - acc: 0.9441 - val_loss: 0.2687 - val_acc: 0.9387 - 11s/epoch - 84ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2280 - acc: 0.9442 - val_loss: 0.2700 - val_acc: 0.9386 - 11s/epoch - 88ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2284 - acc: 0.9441 - val_loss: 0.2691 - val_acc: 0.9388 - 11s/epoch - 87ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2282 - acc: 0.9442 - val_loss: 0.2684 - val_acc: 0.9385 - 11s/epoch - 85ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2281 - acc: 0.9442 - val_loss: 0.2683 - val_acc: 0.9390 - 11s/epoch - 84ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2280 - acc: 0.9441 - val_loss: 0.2689 - val_acc: 0.9386 - 11s/epoch - 90ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2279 - acc: 0.9441 - val_loss: 0.2688 - val_acc: 0.9384 - 10s/epoch - 84ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2279 - acc: 0.9443 - val_loss: 0.2690 - val_acc: 0.9385 - 11s/epoch - 86ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2281 - acc: 0.9439 - val_loss: 0.2696 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2694 - val_acc: 0.9384 - 11s/epoch - 86ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9443 - val_loss: 0.2682 - val_acc: 0.9384 - 10s/epoch - 82ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2278 - acc: 0.9442 - val_loss: 0.2696 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2279 - acc: 0.9442 - val_loss: 0.2696 - val_acc: 0.9385 - 11s/epoch - 86ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2278 - acc: 0.9442 - val_loss: 0.2695 - val_acc: 0.9385 - 10s/epoch - 82ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9442 - val_loss: 0.2700 - val_acc: 0.9382 - 10s/epoch - 84ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2273 - acc: 0.9442 - val_loss: 0.2699 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2275 - acc: 0.9443 - val_loss: 0.2706 - val_acc: 0.9383 - 11s/epoch - 85ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2276 - acc: 0.9442 - val_loss: 0.2706 - val_acc: 0.9385 - 11s/epoch - 85ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9443 - val_loss: 0.2699 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2276 - acc: 0.9442 - val_loss: 0.2692 - val_acc: 0.9384 - 11s/epoch - 85ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2283 - acc: 0.9440 - val_loss: 0.2698 - val_acc: 0.9383 - 10s/epoch - 82ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2282 - acc: 0.9439 - val_loss: 0.2696 - val_acc: 0.9383 - 11s/epoch - 84ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2281 - acc: 0.9440 - val_loss: 0.2705 - val_acc: 0.9385 - 10s/epoch - 84ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2278 - acc: 0.9442 - val_loss: 0.2704 - val_acc: 0.9383 - 10s/epoch - 81ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2278 - acc: 0.9443 - val_loss: 0.2705 - val_acc: 0.9383 - 10s/epoch - 82ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2277 - acc: 0.9443 - val_loss: 0.2713 - val_acc: 0.9383 - 10s/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2277 - acc: 0.9442 - val_loss: 0.2707 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2278 - acc: 0.9441 - val_loss: 0.2706 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2276 - acc: 0.9441 - val_loss: 0.2707 - val_acc: 0.9382 - 11s/epoch - 86ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2710 - val_acc: 0.9384 - 11s/epoch - 89ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2277 - acc: 0.9442 - val_loss: 0.2707 - val_acc: 0.9383 - 11s/epoch - 87ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2709 - val_acc: 0.9383 - 11s/epoch - 87ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9442 - val_loss: 0.2706 - val_acc: 0.9384 - 10s/epoch - 83ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2274 - acc: 0.9443 - val_loss: 0.2717 - val_acc: 0.9383 - 11s/epoch - 88ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2708 - val_acc: 0.9384 - 11s/epoch - 87ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2275 - acc: 0.9442 - val_loss: 0.2714 - val_acc: 0.9384 - 10s/epoch - 82ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2718 - val_acc: 0.9382 - 10s/epoch - 83ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9441 - val_loss: 0.2713 - val_acc: 0.9385 - 10s/epoch - 82ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2274 - acc: 0.9442 - val_loss: 0.2719 - val_acc: 0.9383 - 10s/epoch - 83ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2274 - acc: 0.9442 - val_loss: 0.2719 - val_acc: 0.9383 - 11s/epoch - 88ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2274 - acc: 0.9441 - val_loss: 0.2717 - val_acc: 0.9382 - 10s/epoch - 84ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2718 - val_acc: 0.9384 - 11s/epoch - 85ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26642\n",
      "125/125 - 10s - loss: 0.2276 - acc: 0.9441 - val_loss: 0.2719 - val_acc: 0.9383 - 10s/epoch - 82ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26642\n",
      "125/125 - 11s - loss: 0.2276 - acc: 0.9441 - val_loss: 0.2716 - val_acc: 0.9382 - 11s/epoch - 84ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "g_units = 128\n",
    "learning_rate = 0.001\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_ei_2_1.h5'\n",
    "history_save_file_name=\"cp_history_ei_2_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model_21 = define_embed_model(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,g_units, \"softmax\")\n",
    "#model_21 = define_embed_model(spa_vocab_size, eng_vocab_size, spa_max_sentence_length, eng_max_sentence_length, units,g_units, \"softmax\")\n",
    "create_model(model_21,loss_func,learning_rate)\n",
    "plot_model(model_21, to_file='model_images/cp_model_ei_2_1_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model_21, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model_21.history, 'loss_vs_epochs_images_100/cp_model_ei_2_1_le.png', 'Model 2 var 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196848d9",
   "metadata": {},
   "source": [
    "### Variante 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7146df4",
   "metadata": {},
   "source": [
    "### English â†’ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf81734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 5, 32)             72704     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 64)                18816     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 8, 64)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 8, 64)             24960     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 8, 4510)          293150    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,630\n",
      "Trainable params: 409,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.61479, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 18s - loss: 3.2832 - acc: 0.6377 - val_loss: 2.6148 - val_acc: 0.6508 - 18s/epoch - 145ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.61479 to 2.52658, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 2.4934 - acc: 0.6527 - val_loss: 2.5266 - val_acc: 0.6569 - 11s/epoch - 87ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 2.52658 to 2.48809, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 2.3963 - acc: 0.6562 - val_loss: 2.4881 - val_acc: 0.6565 - 11s/epoch - 91ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.48809 to 2.43390, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 2.3192 - acc: 0.6614 - val_loss: 2.4339 - val_acc: 0.6655 - 11s/epoch - 87ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.43390 to 2.38222, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 2.2157 - acc: 0.6700 - val_loss: 2.3822 - val_acc: 0.6706 - 11s/epoch - 89ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.38222 to 2.31891, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 2.1081 - acc: 0.6773 - val_loss: 2.3189 - val_acc: 0.6794 - 11s/epoch - 90ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.31891 to 2.25409, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 12s - loss: 1.9933 - acc: 0.6858 - val_loss: 2.2541 - val_acc: 0.6836 - 12s/epoch - 92ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.25409 to 2.21411, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 12s - loss: 1.8849 - acc: 0.6937 - val_loss: 2.2141 - val_acc: 0.6896 - 12s/epoch - 94ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.21411 to 2.16075, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 12s - loss: 1.7785 - acc: 0.7022 - val_loss: 2.1607 - val_acc: 0.6984 - 12s/epoch - 96ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.16075 to 2.13442, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.6790 - acc: 0.7114 - val_loss: 2.1344 - val_acc: 0.6999 - 11s/epoch - 91ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.13442 to 2.10558, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.5810 - acc: 0.7186 - val_loss: 2.1056 - val_acc: 0.7061 - 11s/epoch - 86ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.10558 to 2.08532, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 10s - loss: 1.4872 - acc: 0.7270 - val_loss: 2.0853 - val_acc: 0.7053 - 10s/epoch - 84ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.08532 to 2.06662, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.3980 - acc: 0.7341 - val_loss: 2.0666 - val_acc: 0.7094 - 11s/epoch - 87ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.06662 to 2.05547, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 12s - loss: 1.3151 - acc: 0.7425 - val_loss: 2.0555 - val_acc: 0.7096 - 12s/epoch - 94ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.05547 to 2.03236, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.2398 - acc: 0.7487 - val_loss: 2.0324 - val_acc: 0.7161 - 11s/epoch - 89ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 2.03236\n",
      "125/125 - 11s - loss: 1.1662 - acc: 0.7567 - val_loss: 2.0348 - val_acc: 0.7142 - 11s/epoch - 89ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 2.03236 to 2.02565, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.0978 - acc: 0.7623 - val_loss: 2.0256 - val_acc: 0.7182 - 11s/epoch - 89ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 2.02565 to 2.02291, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 11s - loss: 1.0387 - acc: 0.7695 - val_loss: 2.0229 - val_acc: 0.7195 - 11s/epoch - 91ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 2.02291 to 2.01791, saving model to Models100\\cp_model_2_2.h5\n",
      "125/125 - 12s - loss: 0.9803 - acc: 0.7774 - val_loss: 2.0179 - val_acc: 0.7177 - 12s/epoch - 98ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.9274 - acc: 0.7852 - val_loss: 2.0325 - val_acc: 0.7204 - 11s/epoch - 89ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.8785 - acc: 0.7919 - val_loss: 2.0279 - val_acc: 0.7204 - 11s/epoch - 92ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.8366 - acc: 0.8002 - val_loss: 2.0375 - val_acc: 0.7220 - 11s/epoch - 91ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 2.01791\n",
      "125/125 - 12s - loss: 0.7949 - acc: 0.8076 - val_loss: 2.0449 - val_acc: 0.7214 - 12s/epoch - 96ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.7569 - acc: 0.8113 - val_loss: 2.0519 - val_acc: 0.7192 - 11s/epoch - 86ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.7226 - acc: 0.8197 - val_loss: 2.0515 - val_acc: 0.7220 - 11s/epoch - 87ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.6882 - acc: 0.8248 - val_loss: 2.0666 - val_acc: 0.7229 - 11s/epoch - 87ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.6618 - acc: 0.8291 - val_loss: 2.0636 - val_acc: 0.7222 - 11s/epoch - 87ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.6347 - acc: 0.8349 - val_loss: 2.0848 - val_acc: 0.7207 - 11s/epoch - 88ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.6104 - acc: 0.8375 - val_loss: 2.0804 - val_acc: 0.7237 - 11s/epoch - 86ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.5881 - acc: 0.8422 - val_loss: 2.0999 - val_acc: 0.7202 - 11s/epoch - 87ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.5681 - acc: 0.8461 - val_loss: 2.0996 - val_acc: 0.7247 - 11s/epoch - 86ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.5492 - acc: 0.8500 - val_loss: 2.1090 - val_acc: 0.7203 - 10s/epoch - 83ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.5335 - acc: 0.8522 - val_loss: 2.1161 - val_acc: 0.7201 - 11s/epoch - 85ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.5154 - acc: 0.8562 - val_loss: 2.1339 - val_acc: 0.7213 - 11s/epoch - 91ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4993 - acc: 0.8590 - val_loss: 2.1475 - val_acc: 0.7210 - 11s/epoch - 86ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4866 - acc: 0.8608 - val_loss: 2.1448 - val_acc: 0.7198 - 11s/epoch - 84ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.4711 - acc: 0.8644 - val_loss: 2.1555 - val_acc: 0.7204 - 10s/epoch - 84ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4611 - acc: 0.8657 - val_loss: 2.1717 - val_acc: 0.7164 - 11s/epoch - 85ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4514 - acc: 0.8670 - val_loss: 2.1768 - val_acc: 0.7181 - 11s/epoch - 87ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4370 - acc: 0.8705 - val_loss: 2.1883 - val_acc: 0.7215 - 11s/epoch - 84ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.4320 - acc: 0.8715 - val_loss: 2.1963 - val_acc: 0.7181 - 10s/epoch - 84ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.4224 - acc: 0.8722 - val_loss: 2.1959 - val_acc: 0.7188 - 10s/epoch - 82ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4143 - acc: 0.8739 - val_loss: 2.2147 - val_acc: 0.7190 - 11s/epoch - 84ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.4061 - acc: 0.8754 - val_loss: 2.2232 - val_acc: 0.7180 - 11s/epoch - 85ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.4005 - acc: 0.8748 - val_loss: 2.2302 - val_acc: 0.7184 - 10s/epoch - 83ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3944 - acc: 0.8764 - val_loss: 2.2466 - val_acc: 0.7161 - 11s/epoch - 86ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3867 - acc: 0.8781 - val_loss: 2.2437 - val_acc: 0.7178 - 11s/epoch - 86ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3766 - acc: 0.8799 - val_loss: 2.2644 - val_acc: 0.7172 - 10s/epoch - 83ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3727 - acc: 0.8806 - val_loss: 2.2679 - val_acc: 0.7155 - 10s/epoch - 84ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3645 - acc: 0.8821 - val_loss: 2.2745 - val_acc: 0.7160 - 10s/epoch - 83ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3633 - acc: 0.8826 - val_loss: 2.2934 - val_acc: 0.7146 - 11s/epoch - 88ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3585 - acc: 0.8832 - val_loss: 2.2969 - val_acc: 0.7159 - 11s/epoch - 89ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3540 - acc: 0.8838 - val_loss: 2.3010 - val_acc: 0.7180 - 10s/epoch - 84ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3463 - acc: 0.8845 - val_loss: 2.3137 - val_acc: 0.7197 - 11s/epoch - 88ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3461 - acc: 0.8846 - val_loss: 2.3146 - val_acc: 0.7170 - 11s/epoch - 88ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3407 - acc: 0.8852 - val_loss: 2.3208 - val_acc: 0.7166 - 10s/epoch - 84ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3398 - acc: 0.8866 - val_loss: 2.3281 - val_acc: 0.7200 - 10s/epoch - 83ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3317 - acc: 0.8872 - val_loss: 2.3537 - val_acc: 0.7129 - 10s/epoch - 84ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3283 - acc: 0.8886 - val_loss: 2.3535 - val_acc: 0.7159 - 11s/epoch - 88ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3266 - acc: 0.8882 - val_loss: 2.3612 - val_acc: 0.7159 - 11s/epoch - 90ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3234 - acc: 0.8893 - val_loss: 2.3619 - val_acc: 0.7164 - 11s/epoch - 87ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3195 - acc: 0.8898 - val_loss: 2.3818 - val_acc: 0.7121 - 11s/epoch - 87ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3192 - acc: 0.8899 - val_loss: 2.3701 - val_acc: 0.7149 - 10s/epoch - 83ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.3147 - acc: 0.8902 - val_loss: 2.3878 - val_acc: 0.7150 - 10s/epoch - 83ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3139 - acc: 0.8893 - val_loss: 2.4023 - val_acc: 0.7093 - 11s/epoch - 87ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3155 - acc: 0.8899 - val_loss: 2.4087 - val_acc: 0.7131 - 11s/epoch - 84ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3149 - acc: 0.8893 - val_loss: 2.4036 - val_acc: 0.7134 - 11s/epoch - 89ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3116 - acc: 0.8893 - val_loss: 2.4146 - val_acc: 0.7171 - 11s/epoch - 91ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3079 - acc: 0.8922 - val_loss: 2.4305 - val_acc: 0.7156 - 11s/epoch - 86ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.3023 - acc: 0.8921 - val_loss: 2.4289 - val_acc: 0.7156 - 11s/epoch - 86ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2937 - acc: 0.8940 - val_loss: 2.4445 - val_acc: 0.7116 - 10s/epoch - 84ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2924 - acc: 0.8938 - val_loss: 2.4389 - val_acc: 0.7132 - 10s/epoch - 83ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2914 - acc: 0.8945 - val_loss: 2.4540 - val_acc: 0.7126 - 10s/epoch - 83ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2905 - acc: 0.8942 - val_loss: 2.4511 - val_acc: 0.7153 - 10s/epoch - 84ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2936 - acc: 0.8930 - val_loss: 2.4629 - val_acc: 0.7120 - 11s/epoch - 84ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2891 - acc: 0.8942 - val_loss: 2.4548 - val_acc: 0.7161 - 11s/epoch - 88ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2825 - acc: 0.8956 - val_loss: 2.4585 - val_acc: 0.7129 - 11s/epoch - 84ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2844 - acc: 0.8951 - val_loss: 2.4815 - val_acc: 0.7143 - 10s/epoch - 82ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2861 - acc: 0.8950 - val_loss: 2.4787 - val_acc: 0.7121 - 11s/epoch - 88ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2854 - acc: 0.8952 - val_loss: 2.4960 - val_acc: 0.7151 - 11s/epoch - 88ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.01791\n",
      "125/125 - 13s - loss: 0.2961 - acc: 0.8915 - val_loss: 2.4874 - val_acc: 0.7138 - 13s/epoch - 100ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 2.01791\n",
      "125/125 - 12s - loss: 0.2932 - acc: 0.8922 - val_loss: 2.4960 - val_acc: 0.7137 - 12s/epoch - 97ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2812 - acc: 0.8957 - val_loss: 2.5092 - val_acc: 0.7108 - 11s/epoch - 84ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.01791\n",
      "125/125 - 13s - loss: 0.2789 - acc: 0.8963 - val_loss: 2.5004 - val_acc: 0.7116 - 13s/epoch - 101ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.01791\n",
      "125/125 - 14s - loss: 0.2794 - acc: 0.8952 - val_loss: 2.5085 - val_acc: 0.7110 - 14s/epoch - 115ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 2.01791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 13s - loss: 0.2748 - acc: 0.8960 - val_loss: 2.5194 - val_acc: 0.7133 - 13s/epoch - 100ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 2.01791\n",
      "125/125 - 14s - loss: 0.2712 - acc: 0.8966 - val_loss: 2.5236 - val_acc: 0.7134 - 14s/epoch - 111ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.01791\n",
      "125/125 - 14s - loss: 0.2675 - acc: 0.8977 - val_loss: 2.5289 - val_acc: 0.7107 - 14s/epoch - 112ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2687 - acc: 0.8979 - val_loss: 2.5404 - val_acc: 0.7103 - 11s/epoch - 90ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2706 - acc: 0.8966 - val_loss: 2.5304 - val_acc: 0.7122 - 11s/epoch - 85ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2671 - acc: 0.8978 - val_loss: 2.5415 - val_acc: 0.7144 - 10s/epoch - 83ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2695 - acc: 0.8973 - val_loss: 2.5377 - val_acc: 0.7132 - 11s/epoch - 90ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2692 - acc: 0.8976 - val_loss: 2.5501 - val_acc: 0.7111 - 11s/epoch - 86ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2724 - acc: 0.8961 - val_loss: 2.5500 - val_acc: 0.7102 - 11s/epoch - 88ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2645 - acc: 0.8972 - val_loss: 2.5522 - val_acc: 0.7123 - 11s/epoch - 89ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2648 - acc: 0.8982 - val_loss: 2.5650 - val_acc: 0.7132 - 11s/epoch - 91ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2590 - acc: 0.8984 - val_loss: 2.5527 - val_acc: 0.7138 - 11s/epoch - 86ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2635 - acc: 0.8969 - val_loss: 2.5571 - val_acc: 0.7135 - 11s/epoch - 84ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 2.01791\n",
      "125/125 - 11s - loss: 0.2601 - acc: 0.8986 - val_loss: 2.5808 - val_acc: 0.7158 - 11s/epoch - 85ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.01791\n",
      "125/125 - 10s - loss: 0.2650 - acc: 0.8980 - val_loss: 2.5816 - val_acc: 0.7116 - 10s/epoch - 84ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 32\n",
    "g_units = 64\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_2_2.h5'\n",
    "history_save_file_name=\"cp_history_2_2.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model2_2 = define_embed_model(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,g_units,\"softmax\")\n",
    "create_model(model2_2,loss_func,learning_rate)\n",
    "plot_model(model2_2, to_file='model_images/cp_model_2_2_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model2_2, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model2_2.history, 'loss_vs_epochs_images_100/cp_model_2_2_le.png', 'Model 2 var 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb2577",
   "metadata": {},
   "source": [
    "### Spanish â†’ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b831b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 4510 5 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 8, 32)             144320    \n",
      "                                                                 \n",
      " gru_12 (GRU)                (None, 64)                18816     \n",
      "                                                                 \n",
      " repeat_vector_6 (RepeatVect  (None, 5, 64)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_13 (GRU)                (None, 5, 64)             24960     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 5, 2272)          147680    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335,776\n",
      "Trainable params: 335,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.36857, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 8s - loss: 1.4902 - acc: 0.9201 - val_loss: 0.3686 - val_acc: 0.9193 - 8s/epoch - 67ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.36857 to 0.30742, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.3242 - acc: 0.9323 - val_loss: 0.3074 - val_acc: 0.9333 - 4s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.30742 to 0.30081, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2958 - acc: 0.9366 - val_loss: 0.3008 - val_acc: 0.9344 - 4s/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.30081 to 0.29812, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2882 - acc: 0.9366 - val_loss: 0.2981 - val_acc: 0.9340 - 4s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.29812 to 0.28742, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2814 - acc: 0.9368 - val_loss: 0.2874 - val_acc: 0.9343 - 4s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.28742 to 0.28257, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2729 - acc: 0.9373 - val_loss: 0.2826 - val_acc: 0.9361 - 4s/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.28257\n",
      "125/125 - 4s - loss: 0.2693 - acc: 0.9383 - val_loss: 0.2845 - val_acc: 0.9345 - 4s/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.28257 to 0.28060, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2666 - acc: 0.9382 - val_loss: 0.2806 - val_acc: 0.9355 - 4s/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.28060 to 0.27761, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2635 - acc: 0.9388 - val_loss: 0.2776 - val_acc: 0.9357 - 4s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.27761\n",
      "125/125 - 4s - loss: 0.2612 - acc: 0.9394 - val_loss: 0.2786 - val_acc: 0.9353 - 4s/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.27761 to 0.27433, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2584 - acc: 0.9398 - val_loss: 0.2743 - val_acc: 0.9359 - 4s/epoch - 35ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.27433 to 0.27376, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 5s - loss: 0.2558 - acc: 0.9397 - val_loss: 0.2738 - val_acc: 0.9358 - 5s/epoch - 39ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.27376 to 0.27318, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2532 - acc: 0.9400 - val_loss: 0.2732 - val_acc: 0.9363 - 4s/epoch - 35ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.27318 to 0.26966, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2512 - acc: 0.9407 - val_loss: 0.2697 - val_acc: 0.9373 - 4s/epoch - 35ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.26966 to 0.26959, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2484 - acc: 0.9409 - val_loss: 0.2696 - val_acc: 0.9377 - 4s/epoch - 36ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.26959 to 0.26828, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2470 - acc: 0.9413 - val_loss: 0.2683 - val_acc: 0.9373 - 4s/epoch - 34ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.26828 to 0.26733, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2460 - acc: 0.9410 - val_loss: 0.2673 - val_acc: 0.9374 - 4s/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.26733\n",
      "125/125 - 4s - loss: 0.2446 - acc: 0.9413 - val_loss: 0.2688 - val_acc: 0.9377 - 4s/epoch - 34ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.26733 to 0.26521, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2423 - acc: 0.9418 - val_loss: 0.2652 - val_acc: 0.9374 - 4s/epoch - 34ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.26521\n",
      "125/125 - 4s - loss: 0.2415 - acc: 0.9420 - val_loss: 0.2677 - val_acc: 0.9372 - 4s/epoch - 33ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.26521 to 0.26514, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2413 - acc: 0.9420 - val_loss: 0.2651 - val_acc: 0.9380 - 4s/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.26514 to 0.26470, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2398 - acc: 0.9421 - val_loss: 0.2647 - val_acc: 0.9383 - 4s/epoch - 35ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.26470\n",
      "125/125 - 4s - loss: 0.2384 - acc: 0.9424 - val_loss: 0.2650 - val_acc: 0.9377 - 4s/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.26470 to 0.26421, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2381 - acc: 0.9423 - val_loss: 0.2642 - val_acc: 0.9382 - 4s/epoch - 34ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.26421\n",
      "125/125 - 4s - loss: 0.2368 - acc: 0.9427 - val_loss: 0.2650 - val_acc: 0.9387 - 4s/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.26421\n",
      "125/125 - 5s - loss: 0.2366 - acc: 0.9427 - val_loss: 0.2657 - val_acc: 0.9386 - 5s/epoch - 37ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.26421\n",
      "125/125 - 4s - loss: 0.2358 - acc: 0.9427 - val_loss: 0.2647 - val_acc: 0.9379 - 4s/epoch - 34ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.26421 to 0.26360, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 4s - loss: 0.2349 - acc: 0.9429 - val_loss: 0.2636 - val_acc: 0.9382 - 4s/epoch - 34ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 0.26360 to 0.26260, saving model to Models100\\cp_model_ei_2_2.h5\n",
      "125/125 - 5s - loss: 0.2347 - acc: 0.9431 - val_loss: 0.2626 - val_acc: 0.9385 - 5s/epoch - 37ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2335 - acc: 0.9431 - val_loss: 0.2644 - val_acc: 0.9383 - 4s/epoch - 34ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2332 - acc: 0.9430 - val_loss: 0.2664 - val_acc: 0.9380 - 4s/epoch - 34ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2327 - acc: 0.9434 - val_loss: 0.2674 - val_acc: 0.9382 - 4s/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2324 - acc: 0.9435 - val_loss: 0.2654 - val_acc: 0.9385 - 5s/epoch - 37ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2321 - acc: 0.9437 - val_loss: 0.2662 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2313 - acc: 0.9437 - val_loss: 0.2676 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2319 - acc: 0.9437 - val_loss: 0.2669 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2310 - acc: 0.9438 - val_loss: 0.2660 - val_acc: 0.9382 - 4s/epoch - 35ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2305 - acc: 0.9440 - val_loss: 0.2670 - val_acc: 0.9387 - 4s/epoch - 33ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2305 - acc: 0.9440 - val_loss: 0.2683 - val_acc: 0.9382 - 4s/epoch - 36ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2302 - acc: 0.9440 - val_loss: 0.2658 - val_acc: 0.9385 - 4s/epoch - 35ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2296 - acc: 0.9441 - val_loss: 0.2685 - val_acc: 0.9390 - 4s/epoch - 35ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2302 - acc: 0.9440 - val_loss: 0.2691 - val_acc: 0.9384 - 4s/epoch - 35ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2295 - acc: 0.9439 - val_loss: 0.2677 - val_acc: 0.9387 - 4s/epoch - 34ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2296 - acc: 0.9440 - val_loss: 0.2675 - val_acc: 0.9384 - 4s/epoch - 36ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2296 - acc: 0.9439 - val_loss: 0.2679 - val_acc: 0.9382 - 5s/epoch - 36ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2304 - acc: 0.9439 - val_loss: 0.2677 - val_acc: 0.9380 - 4s/epoch - 35ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2295 - acc: 0.9440 - val_loss: 0.2685 - val_acc: 0.9380 - 5s/epoch - 37ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2297 - acc: 0.9441 - val_loss: 0.2682 - val_acc: 0.9386 - 5s/epoch - 39ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2303 - acc: 0.9440 - val_loss: 0.2664 - val_acc: 0.9387 - 5s/epoch - 39ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2299 - acc: 0.9437 - val_loss: 0.2677 - val_acc: 0.9384 - 5s/epoch - 37ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2295 - acc: 0.9439 - val_loss: 0.2678 - val_acc: 0.9379 - 5s/epoch - 37ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2299 - acc: 0.9438 - val_loss: 0.2674 - val_acc: 0.9383 - 4s/epoch - 36ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2297 - acc: 0.9440 - val_loss: 0.2674 - val_acc: 0.9384 - 5s/epoch - 37ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2288 - acc: 0.9439 - val_loss: 0.2685 - val_acc: 0.9383 - 4s/epoch - 36ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2681 - val_acc: 0.9385 - 5s/epoch - 37ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2288 - acc: 0.9439 - val_loss: 0.2685 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2287 - acc: 0.9441 - val_loss: 0.2713 - val_acc: 0.9383 - 4s/epoch - 33ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2289 - acc: 0.9441 - val_loss: 0.2679 - val_acc: 0.9381 - 4s/epoch - 35ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2286 - acc: 0.9439 - val_loss: 0.2688 - val_acc: 0.9383 - 4s/epoch - 34ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2284 - acc: 0.9439 - val_loss: 0.2690 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2282 - acc: 0.9441 - val_loss: 0.2690 - val_acc: 0.9382 - 4s/epoch - 33ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2283 - acc: 0.9440 - val_loss: 0.2693 - val_acc: 0.9383 - 4s/epoch - 36ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2281 - acc: 0.9440 - val_loss: 0.2725 - val_acc: 0.9377 - 4s/epoch - 34ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2284 - acc: 0.9441 - val_loss: 0.2726 - val_acc: 0.9381 - 4s/epoch - 35ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2289 - acc: 0.9439 - val_loss: 0.2702 - val_acc: 0.9383 - 4s/epoch - 34ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2288 - acc: 0.9439 - val_loss: 0.2706 - val_acc: 0.9382 - 4s/epoch - 36ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2291 - acc: 0.9439 - val_loss: 0.2706 - val_acc: 0.9383 - 4s/epoch - 36ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2294 - acc: 0.9435 - val_loss: 0.2723 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2287 - acc: 0.9439 - val_loss: 0.2703 - val_acc: 0.9380 - 4s/epoch - 33ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2298 - acc: 0.9435 - val_loss: 0.2708 - val_acc: 0.9383 - 4s/epoch - 34ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2291 - acc: 0.9439 - val_loss: 0.2702 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2290 - acc: 0.9441 - val_loss: 0.2702 - val_acc: 0.9385 - 4s/epoch - 33ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2284 - acc: 0.9438 - val_loss: 0.2721 - val_acc: 0.9379 - 4s/epoch - 33ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2284 - acc: 0.9439 - val_loss: 0.2713 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2281 - acc: 0.9442 - val_loss: 0.2719 - val_acc: 0.9388 - 4s/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2281 - acc: 0.9441 - val_loss: 0.2724 - val_acc: 0.9382 - 4s/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2282 - acc: 0.9440 - val_loss: 0.2723 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2276 - acc: 0.9443 - val_loss: 0.2713 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2278 - acc: 0.9440 - val_loss: 0.2711 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2285 - acc: 0.9441 - val_loss: 0.2717 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2274 - acc: 0.9441 - val_loss: 0.2731 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2278 - acc: 0.9438 - val_loss: 0.2704 - val_acc: 0.9385 - 4s/epoch - 33ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2282 - acc: 0.9441 - val_loss: 0.2724 - val_acc: 0.9382 - 4s/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2737 - val_acc: 0.9380 - 4s/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2283 - acc: 0.9441 - val_loss: 0.2719 - val_acc: 0.9385 - 4s/epoch - 34ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2277 - acc: 0.9441 - val_loss: 0.2717 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2274 - acc: 0.9442 - val_loss: 0.2729 - val_acc: 0.9384 - 4s/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2278 - acc: 0.9440 - val_loss: 0.2727 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2282 - acc: 0.9442 - val_loss: 0.2722 - val_acc: 0.9384 - 4s/epoch - 34ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2281 - acc: 0.9441 - val_loss: 0.2718 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2276 - acc: 0.9442 - val_loss: 0.2713 - val_acc: 0.9384 - 4s/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2720 - val_acc: 0.9383 - 4s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26260\n",
      "125/125 - 5s - loss: 0.2283 - acc: 0.9442 - val_loss: 0.2736 - val_acc: 0.9384 - 5s/epoch - 38ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2279 - acc: 0.9441 - val_loss: 0.2720 - val_acc: 0.9383 - 4s/epoch - 33ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2741 - val_acc: 0.9383 - 4s/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2278 - acc: 0.9441 - val_loss: 0.2732 - val_acc: 0.9386 - 4s/epoch - 33ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2283 - acc: 0.9442 - val_loss: 0.2724 - val_acc: 0.9381 - 4s/epoch - 34ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2277 - acc: 0.9442 - val_loss: 0.2718 - val_acc: 0.9383 - 4s/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2276 - acc: 0.9441 - val_loss: 0.2727 - val_acc: 0.9385 - 4s/epoch - 35ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26260\n",
      "125/125 - 4s - loss: 0.2275 - acc: 0.9441 - val_loss: 0.2714 - val_acc: 0.9385 - 4s/epoch - 33ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 32\n",
    "g_units = 64\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=64\n",
    "model_save_file_name='Models100/cp_model_ei_2_2.h5'\n",
    "history_save_file_name=\"cp_history_ei_2_2.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "src_tokenizer,src_vocab_size,src_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "tar_tokenizer,tar_vocab_size,tar_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(src_vocab_size,src_vocab_size,tar_max_sentence_length,tar_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model2_2_ei = define_embed_model(src_vocab_size, tar_vocab_size, src_max_sentence_length, tar_max_sentence_length, units,g_units,\"softmax\")\n",
    "create_model(model2_2_ei,loss_func,learning_rate)\n",
    "plot_model(model2_2_ei, to_file='model_images/cp_model_ei_2_2_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model2_2_ei, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model2_3_ei.history, 'loss_vs_epochs_images_100/cp_model_ei_2_2_le.png', 'Model 2 var 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238c14a",
   "metadata": {},
   "source": [
    "### Variante 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2be2aa",
   "metadata": {},
   "source": [
    "### English â†’ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063a0ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n",
      "(8000, 5) (8000, 8) (2000, 5) (2000, 8)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 5, 64)             145408    \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 32)                9408      \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 8, 32)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 8, 32)             6336      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 8, 4510)          148830    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,982\n",
      "Trainable params: 309,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 4.56809, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 17s - loss: 6.1628 - acc: 0.6303 - val_loss: 4.5681 - val_acc: 0.6400 - 17s/epoch - 263ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 4.56809 to 3.07375, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 3.7094 - acc: 0.6405 - val_loss: 3.0737 - val_acc: 0.6417 - 9s/epoch - 140ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 3.07375 to 2.77676, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.8783 - acc: 0.6409 - val_loss: 2.7768 - val_acc: 0.6417 - 9s/epoch - 141ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 2.77676 to 2.66398, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.6644 - acc: 0.6411 - val_loss: 2.6640 - val_acc: 0.6417 - 9s/epoch - 149ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 2.66398 to 2.62492, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 2.5725 - acc: 0.6411 - val_loss: 2.6249 - val_acc: 0.6417 - 10s/epoch - 153ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 2.62492 to 2.58421, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.5174 - acc: 0.6411 - val_loss: 2.5842 - val_acc: 0.6417 - 9s/epoch - 149ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 2.58421 to 2.55925, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 2.4734 - acc: 0.6411 - val_loss: 2.5592 - val_acc: 0.6417 - 10s/epoch - 152ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 2.55925 to 2.52732, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.4272 - acc: 0.6436 - val_loss: 2.5273 - val_acc: 0.6459 - 9s/epoch - 147ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 2.52732 to 2.50008, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.3783 - acc: 0.6555 - val_loss: 2.5001 - val_acc: 0.6572 - 9s/epoch - 138ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 2.50008 to 2.48764, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 2.3377 - acc: 0.6588 - val_loss: 2.4876 - val_acc: 0.6577 - 10s/epoch - 151ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 2.48764 to 2.46859, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.3021 - acc: 0.6600 - val_loss: 2.4686 - val_acc: 0.6594 - 9s/epoch - 139ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 2.46859 to 2.45683, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.2688 - acc: 0.6615 - val_loss: 2.4568 - val_acc: 0.6603 - 9s/epoch - 145ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 2.45683 to 2.44809, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.2397 - acc: 0.6632 - val_loss: 2.4481 - val_acc: 0.6610 - 9s/epoch - 143ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 2.44809 to 2.44621, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.2112 - acc: 0.6642 - val_loss: 2.4462 - val_acc: 0.6613 - 9s/epoch - 141ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 2.44621 to 2.43543, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.1852 - acc: 0.6650 - val_loss: 2.4354 - val_acc: 0.6614 - 9s/epoch - 142ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 2.43543 to 2.42825, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.1587 - acc: 0.6661 - val_loss: 2.4282 - val_acc: 0.6609 - 9s/epoch - 139ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 2.42825 to 2.41286, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.1280 - acc: 0.6671 - val_loss: 2.4129 - val_acc: 0.6628 - 9s/epoch - 142ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 2.41286 to 2.40264, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.0934 - acc: 0.6688 - val_loss: 2.4026 - val_acc: 0.6649 - 9s/epoch - 137ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 2.40264 to 2.38716, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.0593 - acc: 0.6704 - val_loss: 2.3872 - val_acc: 0.6638 - 9s/epoch - 141ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 2.38716 to 2.37065, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 2.0259 - acc: 0.6715 - val_loss: 2.3706 - val_acc: 0.6656 - 9s/epoch - 141ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 2.37065 to 2.35586, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.9890 - acc: 0.6731 - val_loss: 2.3559 - val_acc: 0.6659 - 9s/epoch - 147ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 2.35586 to 2.34026, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.9525 - acc: 0.6742 - val_loss: 2.3403 - val_acc: 0.6674 - 9s/epoch - 139ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 2.34026 to 2.33254, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.9194 - acc: 0.6770 - val_loss: 2.3325 - val_acc: 0.6679 - 9s/epoch - 143ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 2.33254 to 2.32500, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.8848 - acc: 0.6803 - val_loss: 2.3250 - val_acc: 0.6704 - 9s/epoch - 150ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 2.32500 to 2.31429, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.8531 - acc: 0.6823 - val_loss: 2.3143 - val_acc: 0.6706 - 9s/epoch - 144ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 2.31429 to 2.30269, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.8200 - acc: 0.6851 - val_loss: 2.3027 - val_acc: 0.6741 - 11s/epoch - 172ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 2.30269 to 2.28956, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.7843 - acc: 0.6893 - val_loss: 2.2896 - val_acc: 0.6743 - 9s/epoch - 146ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 2.28956 to 2.28475, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.7558 - acc: 0.6920 - val_loss: 2.2848 - val_acc: 0.6771 - 10s/epoch - 157ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 2.28475 to 2.27330, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.7228 - acc: 0.6955 - val_loss: 2.2733 - val_acc: 0.6755 - 11s/epoch - 170ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 2.27330 to 2.25999, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.6898 - acc: 0.6977 - val_loss: 2.2600 - val_acc: 0.6808 - 9s/epoch - 149ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 2.25999 to 2.25463, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.6587 - acc: 0.7012 - val_loss: 2.2546 - val_acc: 0.6796 - 11s/epoch - 174ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 2.25463 to 2.23817, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.6303 - acc: 0.7040 - val_loss: 2.2382 - val_acc: 0.6834 - 11s/epoch - 178ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 2.23817 to 2.22962, saving model to Models100\\cp_model_2_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 12s - loss: 1.5971 - acc: 0.7079 - val_loss: 2.2296 - val_acc: 0.6846 - 12s/epoch - 189ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 2.22962 to 2.21130, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.5664 - acc: 0.7109 - val_loss: 2.2113 - val_acc: 0.6880 - 11s/epoch - 181ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 2.21130\n",
      "63/63 - 10s - loss: 1.5368 - acc: 0.7142 - val_loss: 2.2148 - val_acc: 0.6865 - 10s/epoch - 163ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 2.21130 to 2.20697, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.5095 - acc: 0.7154 - val_loss: 2.2070 - val_acc: 0.6881 - 10s/epoch - 153ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss improved from 2.20697 to 2.20294, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.4827 - acc: 0.7186 - val_loss: 2.2029 - val_acc: 0.6884 - 10s/epoch - 161ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss improved from 2.20294 to 2.19099, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.4611 - acc: 0.7209 - val_loss: 2.1910 - val_acc: 0.6932 - 10s/epoch - 153ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss improved from 2.19099 to 2.18787, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.4348 - acc: 0.7229 - val_loss: 2.1879 - val_acc: 0.6896 - 10s/epoch - 163ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 2.18787 to 2.18496, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.4089 - acc: 0.7265 - val_loss: 2.1850 - val_acc: 0.6911 - 11s/epoch - 167ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 2.18496 to 2.18224, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.3865 - acc: 0.7281 - val_loss: 2.1822 - val_acc: 0.6927 - 10s/epoch - 165ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 2.18224 to 2.18072, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.3643 - acc: 0.7302 - val_loss: 2.1807 - val_acc: 0.6933 - 10s/epoch - 163ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss improved from 2.18072 to 2.17564, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.3443 - acc: 0.7329 - val_loss: 2.1756 - val_acc: 0.6939 - 11s/epoch - 176ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss improved from 2.17564 to 2.17395, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 11s - loss: 1.3267 - acc: 0.7352 - val_loss: 2.1740 - val_acc: 0.6931 - 11s/epoch - 170ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss improved from 2.17395 to 2.17304, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 9s - loss: 1.3069 - acc: 0.7377 - val_loss: 2.1730 - val_acc: 0.6937 - 9s/epoch - 147ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 2.17304\n",
      "63/63 - 10s - loss: 1.2875 - acc: 0.7395 - val_loss: 2.1752 - val_acc: 0.6942 - 10s/epoch - 155ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss improved from 2.17304 to 2.17265, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.2690 - acc: 0.7413 - val_loss: 2.1727 - val_acc: 0.6964 - 10s/epoch - 161ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss improved from 2.17265 to 2.17110, saving model to Models100\\cp_model_2_3.h5\n",
      "63/63 - 10s - loss: 1.2523 - acc: 0.7435 - val_loss: 2.1711 - val_acc: 0.6960 - 10s/epoch - 156ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 1.2340 - acc: 0.7458 - val_loss: 2.1794 - val_acc: 0.6934 - 10s/epoch - 155ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 1.2197 - acc: 0.7477 - val_loss: 2.1813 - val_acc: 0.6961 - 10s/epoch - 152ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 1.2023 - acc: 0.7488 - val_loss: 2.1836 - val_acc: 0.6974 - 10s/epoch - 153ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 1.1856 - acc: 0.7511 - val_loss: 2.1782 - val_acc: 0.6957 - 10s/epoch - 153ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 1.1685 - acc: 0.7531 - val_loss: 2.1906 - val_acc: 0.6981 - 10s/epoch - 157ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.1556 - acc: 0.7557 - val_loss: 2.1862 - val_acc: 0.6936 - 9s/epoch - 147ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.1438 - acc: 0.7563 - val_loss: 2.1954 - val_acc: 0.6959 - 9s/epoch - 146ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.1295 - acc: 0.7592 - val_loss: 2.1857 - val_acc: 0.6994 - 9s/epoch - 147ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.1131 - acc: 0.7608 - val_loss: 2.1894 - val_acc: 0.6976 - 9s/epoch - 140ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.1018 - acc: 0.7623 - val_loss: 2.1896 - val_acc: 0.6994 - 9s/epoch - 142ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0905 - acc: 0.7640 - val_loss: 2.1822 - val_acc: 0.6968 - 9s/epoch - 139ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0770 - acc: 0.7659 - val_loss: 2.1814 - val_acc: 0.6997 - 9s/epoch - 140ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0661 - acc: 0.7664 - val_loss: 2.1926 - val_acc: 0.6963 - 9s/epoch - 140ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0527 - acc: 0.7696 - val_loss: 2.1948 - val_acc: 0.6982 - 9s/epoch - 138ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0419 - acc: 0.7702 - val_loss: 2.1936 - val_acc: 0.6989 - 9s/epoch - 143ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0335 - acc: 0.7720 - val_loss: 2.2014 - val_acc: 0.7001 - 9s/epoch - 139ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0236 - acc: 0.7737 - val_loss: 2.1989 - val_acc: 0.6988 - 9s/epoch - 144ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 1.0087 - acc: 0.7760 - val_loss: 2.1951 - val_acc: 0.7010 - 9s/epoch - 141ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9955 - acc: 0.7771 - val_loss: 2.1867 - val_acc: 0.6992 - 9s/epoch - 140ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9882 - acc: 0.7781 - val_loss: 2.1983 - val_acc: 0.6992 - 9s/epoch - 145ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9819 - acc: 0.7790 - val_loss: 2.2055 - val_acc: 0.7000 - 9s/epoch - 148ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9727 - acc: 0.7805 - val_loss: 2.1989 - val_acc: 0.7016 - 9s/epoch - 150ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9609 - acc: 0.7829 - val_loss: 2.2055 - val_acc: 0.7007 - 9s/epoch - 147ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 0.9482 - acc: 0.7846 - val_loss: 2.2072 - val_acc: 0.6986 - 10s/epoch - 157ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 2.17110\n",
      "63/63 - 11s - loss: 0.9418 - acc: 0.7849 - val_loss: 2.2026 - val_acc: 0.7008 - 11s/epoch - 177ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9353 - acc: 0.7866 - val_loss: 2.2074 - val_acc: 0.7011 - 9s/epoch - 147ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9244 - acc: 0.7883 - val_loss: 2.2056 - val_acc: 0.7014 - 9s/epoch - 140ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9167 - acc: 0.7904 - val_loss: 2.2195 - val_acc: 0.6973 - 9s/epoch - 147ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9098 - acc: 0.7916 - val_loss: 2.2059 - val_acc: 0.7008 - 9s/epoch - 145ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.9012 - acc: 0.7921 - val_loss: 2.2090 - val_acc: 0.6985 - 9s/epoch - 144ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 0.9009 - acc: 0.7916 - val_loss: 2.2142 - val_acc: 0.6985 - 10s/epoch - 160ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 0.8902 - acc: 0.7944 - val_loss: 2.2209 - val_acc: 0.6980 - 10s/epoch - 161ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8783 - acc: 0.7966 - val_loss: 2.2165 - val_acc: 0.7007 - 9s/epoch - 142ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8684 - acc: 0.7985 - val_loss: 2.2136 - val_acc: 0.7014 - 9s/epoch - 143ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8634 - acc: 0.7981 - val_loss: 2.2126 - val_acc: 0.7001 - 9s/epoch - 140ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8573 - acc: 0.7985 - val_loss: 2.2158 - val_acc: 0.7003 - 9s/epoch - 140ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8490 - acc: 0.7995 - val_loss: 2.2179 - val_acc: 0.7009 - 9s/epoch - 137ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8439 - acc: 0.8016 - val_loss: 2.2237 - val_acc: 0.7023 - 9s/epoch - 142ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8388 - acc: 0.8010 - val_loss: 2.2272 - val_acc: 0.6989 - 9s/epoch - 141ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.17110\n",
      "63/63 - 10s - loss: 0.8348 - acc: 0.8025 - val_loss: 2.2174 - val_acc: 0.7026 - 10s/epoch - 152ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8272 - acc: 0.8042 - val_loss: 2.2292 - val_acc: 0.6981 - 9s/epoch - 143ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8269 - acc: 0.8032 - val_loss: 2.2284 - val_acc: 0.6984 - 9s/epoch - 142ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8201 - acc: 0.8048 - val_loss: 2.2338 - val_acc: 0.6999 - 9s/epoch - 140ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8122 - acc: 0.8070 - val_loss: 2.2384 - val_acc: 0.6986 - 9s/epoch - 139ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8119 - acc: 0.8059 - val_loss: 2.2369 - val_acc: 0.7004 - 9s/epoch - 141ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.8004 - acc: 0.8080 - val_loss: 2.2316 - val_acc: 0.7004 - 9s/epoch - 144ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7981 - acc: 0.8085 - val_loss: 2.2380 - val_acc: 0.7011 - 9s/epoch - 146ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7957 - acc: 0.8095 - val_loss: 2.2299 - val_acc: 0.7029 - 9s/epoch - 139ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7880 - acc: 0.8097 - val_loss: 2.2369 - val_acc: 0.7024 - 9s/epoch - 147ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7845 - acc: 0.8102 - val_loss: 2.2373 - val_acc: 0.7024 - 9s/epoch - 146ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7788 - acc: 0.8116 - val_loss: 2.2351 - val_acc: 0.7020 - 9s/epoch - 147ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.17110\n",
      "63/63 - 9s - loss: 0.7699 - acc: 0.8129 - val_loss: 2.2438 - val_acc: 0.7003 - 9s/epoch - 149ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 64\n",
    "g_units=32\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "model_save_file_name='Models100/cp_model_2_3.h5'\n",
    "history_save_file_name=\"cp_history_2_3.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model2_3 = define_embed_model(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,g_units,\"sigmoid\")\n",
    "create_model(model2_3,loss_func,learning_rate)\n",
    "plot_model(model2_3, to_file='model_images/cp_model_2_3_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model2_3, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model2_3.history, 'loss_vs_epochs_images_100/cp_model_2_3_le.png', 'Model 2 var 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b7159",
   "metadata": {},
   "source": [
    "### Spanish â†’ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2200f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 4510 5 5\n",
      "(8000, 8) (8000, 5) (2000, 8) (2000, 5)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 8, 64)             288640    \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 32)                9408      \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 5, 32)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 5, 32)             6336      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 5, 2272)          74976     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379,360\n",
      "Trainable params: 379,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.14187, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 11s - loss: 4.6164 - acc: 0.8347 - val_loss: 2.1419 - val_acc: 0.0131 - 11s/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 2.14187 to 1.19396, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 1.5031 - acc: 0.0141 - val_loss: 1.1940 - val_acc: 0.0131 - 3s/epoch - 52ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 1.19396 to 1.03701, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 1.0879 - acc: 0.3255 - val_loss: 1.0370 - val_acc: 0.9197 - 3s/epoch - 54ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 1.03701 to 0.40840, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.5367 - acc: 0.9222 - val_loss: 0.4084 - val_acc: 0.9197 - 3s/epoch - 50ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.40840 to 0.35901, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.3707 - acc: 0.9222 - val_loss: 0.3590 - val_acc: 0.9197 - 3s/epoch - 48ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.35901 to 0.33906, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.3387 - acc: 0.9222 - val_loss: 0.3391 - val_acc: 0.9197 - 3s/epoch - 53ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.33906 to 0.33211, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3266 - acc: 0.9222 - val_loss: 0.3321 - val_acc: 0.9197 - 4s/epoch - 68ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.33211 to 0.32824, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3206 - acc: 0.9222 - val_loss: 0.3282 - val_acc: 0.9197 - 4s/epoch - 66ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.32824 to 0.32407, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3157 - acc: 0.9222 - val_loss: 0.3241 - val_acc: 0.9197 - 4s/epoch - 61ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.32407 to 0.32034, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3118 - acc: 0.9222 - val_loss: 0.3203 - val_acc: 0.9197 - 4s/epoch - 67ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.32034 to 0.31777, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3068 - acc: 0.9222 - val_loss: 0.3178 - val_acc: 0.9197 - 4s/epoch - 70ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.31777 to 0.31472, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3034 - acc: 0.9222 - val_loss: 0.3147 - val_acc: 0.9197 - 4s/epoch - 59ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.31472 to 0.31086, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.3002 - acc: 0.9222 - val_loss: 0.3109 - val_acc: 0.9197 - 4s/epoch - 56ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.31086 to 0.30756, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2958 - acc: 0.9222 - val_loss: 0.3076 - val_acc: 0.9196 - 4s/epoch - 62ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.30756 to 0.30343, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 5s - loss: 0.2912 - acc: 0.9222 - val_loss: 0.3034 - val_acc: 0.9197 - 5s/epoch - 73ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.30343 to 0.30184, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 5s - loss: 0.2873 - acc: 0.9222 - val_loss: 0.3018 - val_acc: 0.9196 - 5s/epoch - 78ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.30184 to 0.29834, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2836 - acc: 0.9222 - val_loss: 0.2983 - val_acc: 0.9197 - 4s/epoch - 63ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.29834 to 0.29602, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2804 - acc: 0.9222 - val_loss: 0.2960 - val_acc: 0.9196 - 4s/epoch - 59ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.29602 to 0.29429, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2777 - acc: 0.9222 - val_loss: 0.2943 - val_acc: 0.9196 - 4s/epoch - 65ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.29429 to 0.29190, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2757 - acc: 0.9221 - val_loss: 0.2919 - val_acc: 0.9196 - 4s/epoch - 58ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.29190 to 0.29088, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2725 - acc: 0.9222 - val_loss: 0.2909 - val_acc: 0.9196 - 4s/epoch - 61ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.29088 to 0.28803, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2712 - acc: 0.9226 - val_loss: 0.2880 - val_acc: 0.9205 - 4s/epoch - 60ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.28803 to 0.28754, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2696 - acc: 0.9269 - val_loss: 0.2875 - val_acc: 0.9332 - 4s/epoch - 59ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.28754 to 0.28624, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2674 - acc: 0.9364 - val_loss: 0.2862 - val_acc: 0.9343 - 4s/epoch - 57ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.28624 to 0.28329, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2650 - acc: 0.9367 - val_loss: 0.2833 - val_acc: 0.9344 - 4s/epoch - 60ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.28329 to 0.27859, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2593 - acc: 0.9369 - val_loss: 0.2786 - val_acc: 0.9352 - 3s/epoch - 55ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.27859 to 0.27808, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2567 - acc: 0.9377 - val_loss: 0.2781 - val_acc: 0.9354 - 4s/epoch - 60ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.27808 to 0.27634, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2550 - acc: 0.9382 - val_loss: 0.2763 - val_acc: 0.9354 - 4s/epoch - 58ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 0.27634 to 0.27437, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2539 - acc: 0.9383 - val_loss: 0.2744 - val_acc: 0.9354 - 3s/epoch - 54ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.27437\n",
      "63/63 - 4s - loss: 0.2526 - acc: 0.9385 - val_loss: 0.2753 - val_acc: 0.9350 - 4s/epoch - 58ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.27437\n",
      "63/63 - 3s - loss: 0.2515 - acc: 0.9383 - val_loss: 0.2747 - val_acc: 0.9351 - 3s/epoch - 54ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 0.27437 to 0.27412, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2502 - acc: 0.9385 - val_loss: 0.2741 - val_acc: 0.9350 - 4s/epoch - 56ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.27412 to 0.27390, saving model to Models100\\cp_model_ei_2_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 3s - loss: 0.2494 - acc: 0.9383 - val_loss: 0.2739 - val_acc: 0.9351 - 3s/epoch - 54ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.27390\n",
      "63/63 - 3s - loss: 0.2485 - acc: 0.9384 - val_loss: 0.2745 - val_acc: 0.9350 - 3s/epoch - 53ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss improved from 0.27390 to 0.27344, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2474 - acc: 0.9387 - val_loss: 0.2734 - val_acc: 0.9346 - 3s/epoch - 52ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.27344 to 0.27249, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2468 - acc: 0.9386 - val_loss: 0.2725 - val_acc: 0.9352 - 3s/epoch - 54ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss improved from 0.27249 to 0.27184, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2459 - acc: 0.9387 - val_loss: 0.2718 - val_acc: 0.9351 - 4s/epoch - 63ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.27184\n",
      "63/63 - 3s - loss: 0.2452 - acc: 0.9388 - val_loss: 0.2733 - val_acc: 0.9351 - 3s/epoch - 53ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.27184\n",
      "63/63 - 3s - loss: 0.2446 - acc: 0.9390 - val_loss: 0.2733 - val_acc: 0.9353 - 3s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.27184\n",
      "63/63 - 3s - loss: 0.2439 - acc: 0.9394 - val_loss: 0.2723 - val_acc: 0.9356 - 3s/epoch - 52ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 0.27184 to 0.27171, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2436 - acc: 0.9400 - val_loss: 0.2717 - val_acc: 0.9358 - 3s/epoch - 54ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.27171 to 0.27007, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2424 - acc: 0.9401 - val_loss: 0.2701 - val_acc: 0.9360 - 3s/epoch - 54ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.27007\n",
      "63/63 - 3s - loss: 0.2417 - acc: 0.9402 - val_loss: 0.2732 - val_acc: 0.9361 - 3s/epoch - 50ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.27007\n",
      "63/63 - 3s - loss: 0.2419 - acc: 0.9403 - val_loss: 0.2704 - val_acc: 0.9366 - 3s/epoch - 50ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss improved from 0.27007 to 0.26958, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2411 - acc: 0.9406 - val_loss: 0.2696 - val_acc: 0.9371 - 3s/epoch - 52ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss improved from 0.26958 to 0.26825, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2403 - acc: 0.9406 - val_loss: 0.2683 - val_acc: 0.9372 - 3s/epoch - 54ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.26825\n",
      "63/63 - 3s - loss: 0.2397 - acc: 0.9408 - val_loss: 0.2685 - val_acc: 0.9373 - 3s/epoch - 52ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss improved from 0.26825 to 0.26799, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2393 - acc: 0.9407 - val_loss: 0.2680 - val_acc: 0.9373 - 3s/epoch - 52ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.26799\n",
      "63/63 - 3s - loss: 0.2386 - acc: 0.9409 - val_loss: 0.2681 - val_acc: 0.9372 - 3s/epoch - 52ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.26799\n",
      "63/63 - 3s - loss: 0.2379 - acc: 0.9409 - val_loss: 0.2695 - val_acc: 0.9365 - 3s/epoch - 53ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss improved from 0.26799 to 0.26780, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2378 - acc: 0.9409 - val_loss: 0.2678 - val_acc: 0.9372 - 3s/epoch - 55ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.26780\n",
      "63/63 - 4s - loss: 0.2374 - acc: 0.9410 - val_loss: 0.2678 - val_acc: 0.9375 - 4s/epoch - 56ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss improved from 0.26780 to 0.26772, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2367 - acc: 0.9412 - val_loss: 0.2677 - val_acc: 0.9372 - 3s/epoch - 54ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss improved from 0.26772 to 0.26617, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2362 - acc: 0.9413 - val_loss: 0.2662 - val_acc: 0.9373 - 3s/epoch - 54ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss improved from 0.26617 to 0.26517, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 3s - loss: 0.2361 - acc: 0.9414 - val_loss: 0.2652 - val_acc: 0.9373 - 3s/epoch - 52ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.26517\n",
      "63/63 - 3s - loss: 0.2358 - acc: 0.9412 - val_loss: 0.2663 - val_acc: 0.9368 - 3s/epoch - 55ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.26517\n",
      "63/63 - 4s - loss: 0.2355 - acc: 0.9414 - val_loss: 0.2652 - val_acc: 0.9376 - 4s/epoch - 60ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.26517\n",
      "63/63 - 4s - loss: 0.2351 - acc: 0.9415 - val_loss: 0.2669 - val_acc: 0.9376 - 4s/epoch - 63ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.26517\n",
      "63/63 - 4s - loss: 0.2346 - acc: 0.9415 - val_loss: 0.2659 - val_acc: 0.9376 - 4s/epoch - 60ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss improved from 0.26517 to 0.26504, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2343 - acc: 0.9417 - val_loss: 0.2650 - val_acc: 0.9376 - 4s/epoch - 68ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.26504\n",
      "63/63 - 4s - loss: 0.2340 - acc: 0.9417 - val_loss: 0.2652 - val_acc: 0.9375 - 4s/epoch - 59ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss improved from 0.26504 to 0.26488, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2336 - acc: 0.9421 - val_loss: 0.2649 - val_acc: 0.9376 - 4s/epoch - 57ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.26488\n",
      "63/63 - 4s - loss: 0.2333 - acc: 0.9421 - val_loss: 0.2663 - val_acc: 0.9377 - 4s/epoch - 58ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss improved from 0.26488 to 0.26431, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2327 - acc: 0.9423 - val_loss: 0.2643 - val_acc: 0.9377 - 4s/epoch - 58ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss improved from 0.26431 to 0.26347, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2322 - acc: 0.9421 - val_loss: 0.2635 - val_acc: 0.9378 - 4s/epoch - 58ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.26347\n",
      "63/63 - 4s - loss: 0.2320 - acc: 0.9423 - val_loss: 0.2637 - val_acc: 0.9377 - 4s/epoch - 59ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss improved from 0.26347 to 0.26274, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2323 - acc: 0.9423 - val_loss: 0.2627 - val_acc: 0.9377 - 4s/epoch - 62ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2312 - acc: 0.9424 - val_loss: 0.2642 - val_acc: 0.9378 - 4s/epoch - 61ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2310 - acc: 0.9424 - val_loss: 0.2640 - val_acc: 0.9379 - 4s/epoch - 59ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2308 - acc: 0.9424 - val_loss: 0.2648 - val_acc: 0.9379 - 4s/epoch - 58ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2305 - acc: 0.9425 - val_loss: 0.2643 - val_acc: 0.9379 - 4s/epoch - 59ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.26274\n",
      "63/63 - 3s - loss: 0.2300 - acc: 0.9427 - val_loss: 0.2639 - val_acc: 0.9379 - 3s/epoch - 55ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2302 - acc: 0.9426 - val_loss: 0.2636 - val_acc: 0.9379 - 4s/epoch - 57ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.26274\n",
      "63/63 - 3s - loss: 0.2299 - acc: 0.9425 - val_loss: 0.2656 - val_acc: 0.9380 - 3s/epoch - 53ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.26274\n",
      "63/63 - 3s - loss: 0.2298 - acc: 0.9427 - val_loss: 0.2644 - val_acc: 0.9378 - 3s/epoch - 53ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.26274\n",
      "63/63 - 3s - loss: 0.2296 - acc: 0.9429 - val_loss: 0.2640 - val_acc: 0.9379 - 3s/epoch - 55ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.26274\n",
      "63/63 - 3s - loss: 0.2298 - acc: 0.9429 - val_loss: 0.2640 - val_acc: 0.9379 - 3s/epoch - 52ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2290 - acc: 0.9428 - val_loss: 0.2638 - val_acc: 0.9379 - 4s/epoch - 61ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2287 - acc: 0.9430 - val_loss: 0.2635 - val_acc: 0.9379 - 4s/epoch - 64ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2285 - acc: 0.9430 - val_loss: 0.2639 - val_acc: 0.9379 - 4s/epoch - 63ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2287 - acc: 0.9429 - val_loss: 0.2638 - val_acc: 0.9380 - 4s/epoch - 63ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2281 - acc: 0.9431 - val_loss: 0.2650 - val_acc: 0.9380 - 4s/epoch - 62ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2284 - acc: 0.9431 - val_loss: 0.2635 - val_acc: 0.9381 - 4s/epoch - 60ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.26274\n",
      "63/63 - 4s - loss: 0.2280 - acc: 0.9432 - val_loss: 0.2631 - val_acc: 0.9381 - 4s/epoch - 58ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss improved from 0.26274 to 0.26268, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2278 - acc: 0.9431 - val_loss: 0.2627 - val_acc: 0.9381 - 4s/epoch - 63ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2274 - acc: 0.9433 - val_loss: 0.2642 - val_acc: 0.9382 - 4s/epoch - 60ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2281 - acc: 0.9429 - val_loss: 0.2637 - val_acc: 0.9381 - 4s/epoch - 57ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.26268\n",
      "63/63 - 3s - loss: 0.2283 - acc: 0.9429 - val_loss: 0.2653 - val_acc: 0.9382 - 3s/epoch - 55ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.26268\n",
      "63/63 - 3s - loss: 0.2283 - acc: 0.9427 - val_loss: 0.2636 - val_acc: 0.9380 - 3s/epoch - 55ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2278 - acc: 0.9431 - val_loss: 0.2640 - val_acc: 0.9383 - 4s/epoch - 60ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2272 - acc: 0.9433 - val_loss: 0.2641 - val_acc: 0.9383 - 4s/epoch - 59ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2268 - acc: 0.9433 - val_loss: 0.2645 - val_acc: 0.9385 - 4s/epoch - 57ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2269 - acc: 0.9433 - val_loss: 0.2630 - val_acc: 0.9384 - 4s/epoch - 56ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2263 - acc: 0.9434 - val_loss: 0.2632 - val_acc: 0.9383 - 4s/epoch - 59ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.26268\n",
      "63/63 - 4s - loss: 0.2266 - acc: 0.9434 - val_loss: 0.2633 - val_acc: 0.9384 - 4s/epoch - 60ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.26268\n",
      "63/63 - 3s - loss: 0.2266 - acc: 0.9434 - val_loss: 0.2639 - val_acc: 0.9383 - 3s/epoch - 55ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss improved from 0.26268 to 0.26215, saving model to Models100\\cp_model_ei_2_3.h5\n",
      "63/63 - 4s - loss: 0.2262 - acc: 0.9435 - val_loss: 0.2622 - val_acc: 0.9385 - 4s/epoch - 59ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.26215\n",
      "63/63 - 4s - loss: 0.2261 - acc: 0.9434 - val_loss: 0.2622 - val_acc: 0.9383 - 4s/epoch - 60ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.26215\n",
      "63/63 - 4s - loss: 0.2261 - acc: 0.9435 - val_loss: 0.2627 - val_acc: 0.9385 - 4s/epoch - 62ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.26215\n",
      "63/63 - 4s - loss: 0.2263 - acc: 0.9435 - val_loss: 0.2628 - val_acc: 0.9384 - 4s/epoch - 62ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 64\n",
    "g_units=32\n",
    "learning_rate = 0.005\n",
    "loss_func='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "model_save_file_name='Models100/cp_model_ei_2_3.h5'\n",
    "history_save_file_name=\"cp_history_ei_2_3.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "src_tokenizer,src_vocab_size,src_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "tar_tokenizer,tar_vocab_size,tar_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "print(src_vocab_size,src_vocab_size,tar_max_sentence_length,tar_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, train, one_hot=False)\n",
    "testX, testY = preprocess_input(src_tokenizer, src_max_sentence_length, tar_tokenizer, tar_max_sentence_length,tar_vocab_size, test, one_hot=False)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model2_3_ei = define_embed_model(src_vocab_size, tar_vocab_size, src_max_sentence_length, tar_max_sentence_length, units,g_units,\"sigmoid\")\n",
    "create_model(model2_3_ei,loss_func,learning_rate)\n",
    "plot_model(model2_3_ei, to_file='model_images/cp_model_ei_2_3_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model2_3_ei, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model2_3_ei.history, 'loss_vs_epochs_images_100/cp_model_ei_2_3_le.png', 'Model 2 var 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d39c517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'LOSS')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist1 = load_history(\"cp_history_2_1.npy\")\n",
    "\"\"\"hist2 = load_history(\"cp_history_2_2.npy\")\n",
    "hist3 = load_history(\"cp_history_2_3.npy\")\n",
    "\n",
    "hist11 = load_history(\"cp_history_1_1.npy\")\n",
    "hist21 = load_history(\"cp_history_1_2.npy\")\n",
    "hist31 = load_history(\"cp_history_1_3.npy\")\n",
    "\n",
    "hist13 = load_history(\"cp_history_3_1.npy\")\n",
    "hist23 = load_history(\"cp_history_3_2.npy\")\n",
    "hist33 = load_history(\"cp_history_3_3.npy\")\"\"\"\n",
    "for x in ['loss']:\n",
    "    plt.plot(hist1[x],label=\"Historic 1 v2\")\n",
    "    #plt.plot(hist2[x],label=\"Historic 2 v2\")\n",
    "    #plt.plot(hist3[x],label=\"Historic 3 v2\")\n",
    "    \"\"\"plt.plot(hist11[x],label=\"Historic 1 v1\")\n",
    "    #plt.plot(hist21[x],label=\"Historic 2 v1\")\n",
    "    #plt.plot(hist31[x],label=\"Historic 3 v1\")\n",
    "    #plt.plot(hist13[x],label=\"Historic 1 v3\")\n",
    "    plt.plot(hist23[x],label=\"Historic 2 v3\")\"\"\"\n",
    "    #plt.plot(hist33[x],label=\"Historic 3 v3\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\",fontsize=13)\n",
    "plt.ylabel(\"Loss\",fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb9358",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb325bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 4510 5 8\n"
     ]
    }
   ],
   "source": [
    "### Historic 1 es el mejor\n",
    "ds_filename, train_ds_fn, test_ds_fn = 'dataset/english-spanish-both-10000.txt', 'dataset/english-spanish-train-10000.txt','dataset/english-spanish-test-10000.txt'\n",
    "units = 256\n",
    "g_units = 128\n",
    "learning_rate = 0.001\n",
    "loss_func='categorical_crossentropy'\n",
    "epochs=64\n",
    "batch_size=64\n",
    "model_save_file_name='Models/cp_model_ohe_2_1.h5'\n",
    "history_save_file_name=\"cp_history_ohe_2_1.npy\"\n",
    "\n",
    "dataset,train,test=load_data(ds_filename, train_ds_fn, test_ds_fn)\n",
    "\n",
    "eng_tokenizer,eng_vocab_size,eng_max_sentence_length = prepare_tokenizer(dataset,0)\n",
    "spa_tokenizer,spa_vocab_size,spa_max_sentence_length = prepare_tokenizer(dataset,1)\n",
    "print(eng_vocab_size,spa_vocab_size,eng_max_sentence_length,spa_max_sentence_length)\n",
    "\n",
    "trainX, trainY =  preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, train, one_hot=True)\n",
    "testX, testY = preprocess_input(eng_tokenizer, eng_max_sentence_length, spa_tokenizer, spa_max_sentence_length,spa_vocab_size, test, one_hot=True)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "model2_1_ohe = define_embed_model(eng_vocab_size, spa_vocab_size, eng_max_sentence_length, spa_max_sentence_length, units,g_units, \"softmax\")\n",
    "create_model(model2_1_ohe,loss_func,learning_rate)\n",
    "plot_model(model2_1_ohe, to_file='model_images/cp_model_ohe_2_1_m.png', show_shapes=True)\n",
    "train_evaluate_model(trainX, trainY, testX,testY, epochs, batch_size, model2_1_ohe, model_save_file_name,history_save_file_name)\n",
    "graph_loss_vs_epochs(model.history, 'loss_vs_epochs_images/cp_model_ohe_2_1_m.png', 'Model 2 var 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b6272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
